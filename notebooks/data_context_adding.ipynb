{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a88132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from typing import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from faiss import write_index, read_index\n",
    "import blingfire as bf\n",
    "import torch\n",
    "import faiss\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/clay/research/kaggle/kaggle_llm/data/kaggle-llm-science-exam/train.csv\", index_col=0)\n",
    "wiki_df = pd.read_csv(\"/home/clay/research/kaggle/kaggle_llm/data/physics_pages_list/physics_pages_formatted.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70866b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_per_page = wiki_df.groupby(\"page\")[[\"word_count\"]].sum().sort_values(\"word_count\", ascending=False)\n",
    "black_list = list(wc_per_page.loc[\n",
    "    (wc_per_page[\"word_count\"] > 10000)\n",
    "    | (wc_per_page.index.map(lambda x: \"list of equations\" in x.lower()))\n",
    "].index)\n",
    "print(json.dumps(black_list, indent=4))\n",
    "\n",
    "\n",
    "filtered_wiki_df = wiki_df.loc[~wiki_df[\"page\"].isin(black_list), :].copy()\n",
    "print(len(wiki_df), len(filtered_wiki_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c379eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = \"/home/clay/research/kaggle/kaggle_llm/data/sentence_transformer_model\"\n",
    "max_length = 384\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "model = SentenceTransformer(sentence_model, device=\"cuda\")\n",
    "model.max_seq_length = max_length\n",
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79c7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = []\n",
    "\n",
    "\n",
    "for _, row in tqdm(filtered_wiki_df.iterrows(), total=len(filtered_wiki_df)):\n",
    "    _, sentence_offsets = bf.text_to_sentences_and_offsets(row[\"text\"])\n",
    "    for i, (start_idx, end_idx) in enumerate(sentence_offsets):\n",
    "        if (end_idx - start_idx) > 3:\n",
    "            sentences_df.append({\n",
    "                \"page\": row[\"page\"],\n",
    "                \"i_sentence\": i,\n",
    "                \"text\": row[\"text\"][start_idx: end_idx],\n",
    "            })\n",
    "\n",
    "            \n",
    "sentences_df = pd.DataFrame.from_records(sentences_df)\n",
    "print(f\"extracted: {len(sentences_df)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae745c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d465d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def count_words(text):\n",
    "    return sum([1 for i in text.split() if len(i) > 0])\n",
    "\n",
    "\n",
    "_ = plt.hist(sentences_df[\"text\"].apply(count_words), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ccab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences_df[\"text\"].apply(count_words).describe()\n",
    "too_long_sentences = sentences_df.loc[sentences_df[\"text\"].apply(count_words) > 150, \"text\"]\n",
    "print(len(too_long_sentences) / len(sentences_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"prompt_and_answer\"] = (\n",
    "    train_df[\"prompt\"]\n",
    "    + \" \" + train_df[\"A\"]\n",
    "    + \" \" + train_df[\"B\"]\n",
    "    + \" \" + train_df[\"C\"]\n",
    "    + \" \" + train_df[\"D\"]\n",
    "    + \" \" + train_df[\"E\"]\n",
    ")\n",
    "\n",
    "\n",
    "choice_embeddings = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    question_embeddings = model.encode(\n",
    "        train_df[\"prompt_and_answer\"].values, \n",
    "        batch_size=batch_size, \n",
    "        device=0, \n",
    "        show_progress_bar=True, \n",
    "        convert_to_tensor=True, \n",
    "        normalize_embeddings=True,\n",
    "    ).half()\n",
    "    question_embeddings = question_embeddings.detach().cpu().numpy()\n",
    "    \n",
    "    for choice in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "        embeddings = model.encode(\n",
    "            train_df[choice].values, \n",
    "            batch_size=batch_size, \n",
    "            device=0, \n",
    "            show_progress_bar=True, \n",
    "            convert_to_tensor=True, \n",
    "            normalize_embeddings=True,\n",
    "        ).half()\n",
    "        choice_embeddings.append(embeddings.detach().cpu().numpy())\n",
    "    \n",
    "    sentence_embeddings = model.encode(\n",
    "        sentences_df[\"text\"].values, \n",
    "        batch_size=batch_size,\n",
    "        device=0, \n",
    "        show_progress_bar=True, \n",
    "        convert_to_tensor=True, \n",
    "        normalize_embeddings=True,\n",
    "    ).half()\n",
    "    sentence_embeddings = sentence_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec890f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd69321",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = faiss.IndexFlatL2(sentence_embeddings.shape[1])\n",
    "sentence_index.add(sentence_embeddings)\n",
    "print(f\"{sentence_index.ntotal = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ac85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "distance, indices = sentence_index.search(question_embeddings, k)\n",
    "\n",
    "for i in range(k):\n",
    "    train_df[f\"context_{i}_idx\"] = indices[:, i]\n",
    "    \n",
    "for i in range(k):\n",
    "    train_df[f\"context_{i}\"] = train_df.join(\n",
    "        sentences_df[\"text\"],\n",
    "        on=f\"context_{i}_idx\",\n",
    "        how=\"left\",\n",
    "    )[\"text\"]\n",
    "\n",
    "\n",
    "choice_k = 1\n",
    "for emb, choice in zip(choice_embeddings, [\"A\", \"B\", \"C\", \"D\", \"E\"]):\n",
    "    choice_distance, choice_indices = sentence_index.search(emb, choice_k)\n",
    "    for i in range(choice_k):\n",
    "        train_df[f\"context_{choice}_idx\"] = choice_indices[:, i]\n",
    "        train_df[f\"context_{choice}\"] = train_df.join(\n",
    "            sentences_df[\"text\"],\n",
    "            on=f\"context_{choice}_idx\",\n",
    "            how=\"left\",\n",
    "        )[\"text\"]\n",
    "\n",
    "    \n",
    "train_df = train_df.drop([f\"context_{i}_idx\" for i in range(k)], axis=1)\n",
    "train_df = train_df.drop([f\"context_{i}_idx\" for i in [\"A\", \"B\", \"C\", \"D\", \"E\"]], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    return sum([1 for i in text.split() if len(i) > 0])\n",
    "\n",
    "\n",
    "train_df[\"total_wc\"] = (\n",
    "    train_df[\"prompt\"] \n",
    "    + \" \" + train_df[\"A\"]\n",
    "    + \" \" + train_df[\"B\"]\n",
    "    + \" \" + train_df[\"C\"]\n",
    "    + \" \" + train_df[\"D\"]\n",
    "    + \" \" + train_df[\"E\"]\n",
    "    + \" \" + train_df[\"context_0\"]\n",
    "    + \" \" + train_df[\"context_1\"]\n",
    "    + \" \" + train_df[\"context_2\"]\n",
    "    + \" \" + train_df[\"context_A\"]\n",
    "    + \" \" + train_df[\"context_B\"]\n",
    "    + \" \" + train_df[\"context_C\"]\n",
    "    + \" \" + train_df[\"context_D\"]\n",
    "    + \" \" + train_df[\"context_E\"]\n",
    ").apply(count_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5811f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "_ = plt.hist(train_df[\"total_wc\"], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ffcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df.iloc[1]\n",
    "print(f\"question: {row['prompt']}\\n\")\n",
    "print(f\"context_0: {row['context_0']}\\n\")\n",
    "print(f\"context_1: {row['context_1']}\\n\")\n",
    "print(f\"context_2: {row['context_2']}\\n\")\n",
    "print(f\"A: {row['A']}\\n\")\n",
    "print(f\"context_A: {row['context_A']}\\n\")\n",
    "print(f\"B: {row['B']}\\n\")\n",
    "print(f\"context_B: {row['context_B']}\\n\")\n",
    "print(f\"C: {row['C']}\\n\")\n",
    "print(f\"context_C: {row['context_C']}\\n\")\n",
    "print(f\"D: {row['D']}\\n\")\n",
    "print(f\"context_D: {row['context_D']}\\n\")\n",
    "print(f\"E: {row['E']}\\n\")\n",
    "print(f\"context_E: {row['context_E']}\\n\")\n",
    "print(f\"answer: {row['answer']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
