{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b56eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "openai.api_key = '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' # os.environ[\"OPENAI_API_KEY\"]\n",
    "train_df = pd.read_csv(\"../data/kaggle-llm-science-exam/train.csv\", index_col=0)\n",
    "wiki_df = pd.read_csv(\"../data/physics_pages_list/physics_pages_formatted.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c092650",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_per_page = wiki_df.groupby(\"page\")[[\"word_count\"]].sum().sort_values(\"word_count\", ascending=False)\n",
    "wc_per_page[\"token_count\"] = (wc_per_page[\"word_count\"] / 0.75).astype(int)\n",
    "wc_per_page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list = list(wc_per_page.loc[\n",
    "    (wc_per_page[\"token_count\"] > 10000)\n",
    "    | (wc_per_page.index.map(lambda x: \"list of equations\" in x.lower()))\n",
    "].index)\n",
    "print(json.dumps(black_list, indent=4))\n",
    "\n",
    "filtered_wc_per_page = wc_per_page[~wc_per_page.index.isin(black_list)].copy()\n",
    "filtered_wc_per_page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294ce95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ea3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "\n",
    "\n",
    "pydantic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb701d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "\n",
    "class MultipleChoiceQuestion(BaseModel):\n",
    "    question: str\n",
    "    A: str\n",
    "    B: str\n",
    "    C: str\n",
    "    D: str\n",
    "    E: str\n",
    "    answer: Literal[\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "        \n",
    "class MultipleChoiceQuestionList(BaseModel):\n",
    "    questions: List[MultipleChoiceQuestion]\n",
    "\n",
    "        \n",
    "schema = MultipleChoiceQuestionList.model_json_schema()\n",
    "print(json.dumps(schema, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# out_file_name = \"raw_questions\"\n",
    "out_file_name = \"raw_questions_2\"\n",
    "\n",
    "\n",
    "out_dir = Path(f\"../data/data_dumps/{out_file_name}\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdccdb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page, row in tqdm(filtered_wc_per_page.iterrows(), total=len(filtered_wc_per_page)):\n",
    "    stem = page.lower()\\\n",
    "        .replace(\" \", \"_\")\\\n",
    "        .replace(\"/\", \"_\")\\\n",
    "        .replace(\"'\", \"_\")\\\n",
    "        .replace(\"(\", \"_\")\\\n",
    "        .replace(\")\", \"_\")\\\n",
    "        .replace(\":\", \"_\")\n",
    "    out_path = out_dir / (stem + \".txt\")\n",
    "    print(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5608c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_answers = []\n",
    "# formatted_answers = []\n",
    "num_questions_per_round = 20\n",
    "\n",
    "\n",
    "for page, row in tqdm(filtered_wc_per_page.iterrows(), total=len(filtered_wc_per_page)):\n",
    "    try:\n",
    "        stem = page.lower()\\\n",
    "            .replace(\" \", \"_\")\\\n",
    "            .replace(\"/\", \"_\")\\\n",
    "            .replace(\"'\", \"_\")\\\n",
    "            .replace(\"(\", \"_\")\\\n",
    "            .replace(\")\", \"_\")\\\n",
    "            .replace(\":\", \"_\")\n",
    "        out_path = out_dir / (stem + \".txt\")\n",
    "        if out_path.is_file():\n",
    "            print(f\"{page} already done\")\n",
    "            continue\n",
    "\n",
    "        # ==== prompt building ====\n",
    "        expected_token_count = row[\"token_count\"]\n",
    "        model_name = \"gpt-3.5-turbo-16k-0613\"\n",
    "        info_df = wiki_df[wiki_df[\"page\"] == page]\n",
    "        print(page, expected_token_count, model_name)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": (\n",
    "                    f\"You are a physics professor and \"\n",
    "                    + f\"you are about to design a multiple choice exam questions with 5 choices each. \"\n",
    "                    + f\"Your exam questions will be derived from a wikipedia page: \\\"{page}\\\". \"\n",
    "                    + f\"in the following system prompts, you'll receive a pair of section_title and text \"\n",
    "                    + f\"extracted from the wikipedia page\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "        for _, info_row in info_df.iterrows():\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": (\n",
    "                        f\"section_title: {info_row['section_title']}. text: {info_row['text']}\"\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"generate {num_questions_per_round} multiple choice questions, each with 5 possible answers on the given topic.\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # ==== running model ====\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            functions=[\n",
    "                {\n",
    "                    \"name\": \"create_multiple_choice_question\",\n",
    "                    \"description\": \"create a multiple choice question consisting of a question, and 5 choices: A, B, C, D, and E\",\n",
    "                    \"parameters\": schema,\n",
    "                }\n",
    "            ],\n",
    "            function_call={\"name\": \"create_multiple_choice_question\"},\n",
    "        )\n",
    "\n",
    "        # ==== parsing answers ====\n",
    "        assistant_msg = response[\"choices\"][0][\"message\"]\n",
    "        response_options = assistant_msg.to_dict()[\"function_call\"][\"arguments\"]\n",
    "        out_path.write_text(response_options)\n",
    "    #     formatted_answer = json.loads(response_options)\n",
    "    #     formatted_answers.append(formatted_answer)\n",
    "    except (\n",
    "        openai.error.Timeout,\n",
    "        openai.error.APIError,\n",
    "        openai.error.APIConnectionError,\n",
    "        openai.error.InvalidRequestError,\n",
    "        openai.error.AuthenticationError,\n",
    "        openai.error.PermissionError,\n",
    "        openai.error.RateLimitError,\n",
    "    ) as e:\n",
    "        print(f\"can't do {page}: {repr(e)}, skipping for now\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7901bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_answers = []\n",
    "\n",
    "\n",
    "answer_files = sorted(list(out_dir.glob(\"*.txt\")))\n",
    "for p in answer_files:\n",
    "    try:\n",
    "        parsed_file = json.loads(p.read_text())\n",
    "        for item in parsed_file[\"questions\"]:\n",
    "            item[\"topic\"] = p.stem\n",
    "        formatted_answers.append(parsed_file)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"cant decode: {p}, {e}\")\n",
    "\n",
    "print(f\"parsed {len(formatted_answers)} / {len(answer_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_questions = [\n",
    "    x\n",
    "    for qs in formatted_answers\n",
    "    for x in qs[\"questions\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa62edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame.from_records(flattened_questions)\n",
    "data_df = data_df.rename({\"question\": \"prompt\"}, axis=1)\n",
    "data_df.index.name = \"id\"\n",
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c71db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df[\"answer\"].isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "\n",
    "bad_idxs = []\n",
    "n_math_idxs = 0\n",
    "\n",
    "\n",
    "\n",
    "assert not data_df[\"prompt\"].isna().any()\n",
    "for c in choices:\n",
    "    assert not data_df[c].isna().any()\n",
    "assert not data_df[\"answer\"].isna().any()\n",
    "\n",
    "\n",
    "for i, row in data_df.iterrows():\n",
    "    found_empty_entry = False\n",
    "    for c in [\"prompt\", \"answer\"] + choices:\n",
    "        if (len(row[c]) == 0):\n",
    "            found_empty_entry = True\n",
    "            break\n",
    "    if found_empty_entry:\n",
    "        bad_idxs.append(i)\n",
    "        continue\n",
    "    if any(\n",
    "        math_char in x \n",
    "        for x in (row[\"prompt\"], row[\"A\"], row[\"B\"], row[\"C\"], row[\"D\"], row[\"E\"])\n",
    "        for math_char in (\"\\\\\", )\n",
    "    ):\n",
    "        bad_idxs.append(i)\n",
    "        n_math_idxs += 1\n",
    "        continue\n",
    "    \n",
    "    if row[\"answer\"] not in choices:\n",
    "        rv_idx = {\n",
    "            row[choice].lower(): choice\n",
    "            for choice in choices\n",
    "        }\n",
    "        # fixable as chatgpt puts answer instead of letters\n",
    "        if row[\"answer\"].lower() in rv_idx:\n",
    "            data_df.loc[i, \"answer\"] = rv_idx[row[\"answer\"].lower()]\n",
    "        else:\n",
    "            bad_idxs.append(i)\n",
    "        \n",
    "\n",
    "data_df.loc[bad_idxs, :]\n",
    "filtered_df = data_df.loc[~data_df.index.isin(bad_idxs), :]\n",
    "print(f\"{len(bad_idxs)=}, {n_math_idxs=}, bad rows {len(filtered_df)} / {len(data_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae252b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def count_words(text):\n",
    "#     return sum([1 for i in text.split() if len(i) > 0])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 200))\n",
    "# wc = filtered_df.copy()\n",
    "# wc[\"propmt_wc\"] = wc[\"prompt\"].apply(count_words)\n",
    "# wc[\"choice_wc\"] = (\n",
    "#     wc[\"A\"].apply(count_words)\n",
    "#     + wc[\"B\"].apply(count_words)\n",
    "#     + wc[\"C\"].apply(count_words)\n",
    "#     + wc[\"D\"].apply(count_words)\n",
    "#     + wc[\"E\"].apply(count_words)\n",
    "# )\n",
    "# wc.groupby(\"topic\")[\"choice_wc\"].max().sort_values(ascending=False)\n",
    "# sns.boxplot(\n",
    "#     data=wc,\n",
    "#     x=\"choice_wc\",\n",
    "#     y=\"topic\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924cd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"../data/data_dumps/more_questions/more_questions_{out_file_name}.csv\"\n",
    "filtered_df.to_csv(out_path)\n",
    "\n",
    "print(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb441dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09fc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab2807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e154f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6772c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
