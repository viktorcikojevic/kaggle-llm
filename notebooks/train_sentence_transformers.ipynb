{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhUklEQVR4nO3dfVCVdf7/8ReI3HhzDorLOVKQVG6YWnmThPrdm2Qio1Y3prKhxszRbrBEdjTZ1KYbg9zWXF2Takq3Wc3NmbTSonGwdC1EJTVNB23UlbEO7q7BUUu84fP7o1/XdpBusAvOB3w+Zq4Zz3V9znXe1wc8vObzuW4ijDFGAAAAFokMdwEAAACNEVAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANaJCncB56OhoUGff/65unbtqoiIiHCXAwAAfgJjjI4dO6akpCRFRv7wGEmbDCiff/65kpOTw10GAAA4D9XV1br44ot/sE2bDChdu3aV9M0BejyeMFcDAAB+imAwqOTkZOfv+A9pkwHl22kdj8dDQAEAoI35KadncJIsAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHWiwl0AgPPXa/qakNcHi7PDVAkAuIsRFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6zQ7oGzYsEG33HKLkpKSFBERoVWrVoVsN8Zo1qxZ6tmzp+Li4pSZmal9+/aFtDl69Khyc3Pl8XgUHx+v8ePH6/jx4z/rQAAAQPvR7IBy4sQJXX311Vq4cGGT2+fMmaP58+erpKREFRUV6ty5s7KysnTy5EmnTW5urj799FOtXbtWq1ev1oYNGzRx4sTzPwoAANCuRDX3DSNHjtTIkSOb3GaM0bx58zRjxgyNGjVKkvTqq6/K5/Np1apVGjNmjPbs2aPS0lJt2bJFgwcPliQtWLBAN910k5599lklJSX9jMMBAADtgavnoBw4cECBQECZmZnOOq/Xq/T0dJWXl0uSysvLFR8f74QTScrMzFRkZKQqKiqa3G99fb2CwWDIAgAA2i9XA0ogEJAk+Xy+kPU+n8/ZFggElJiYGLI9KipK3bt3d9o0VlRUJK/X6yzJyclulg0AACzTJq7iKSwsVF1dnbNUV1eHuyQAANCCXA0ofr9fklRTUxOyvqamxtnm9/t15MiRkO1nzpzR0aNHnTaNxcTEyOPxhCwAAKD9cjWgpKamyu/3q6yszFkXDAZVUVGhjIwMSVJGRoZqa2tVWVnptFm3bp0aGhqUnp7uZjkAAKCNavZVPMePH9dnn33mvD5w4IC2b9+u7t27KyUlRfn5+XrqqafUu3dvpaamaubMmUpKStLo0aMlSX369NGNN96oCRMmqKSkRKdPn9akSZM0ZswYruABAACSziOgbN26Vb/97W+d1wUFBZKksWPHasmSJZo2bZpOnDihiRMnqra2VsOHD1dpaaliY2Od9yxdulSTJk3SiBEjFBkZqZycHM2fP9+FwwEAAO1BhDHGhLuI5goGg/J6vaqrq+N8FFzQek1fE/L6YHF2mCoBgB/XnL/fbeIqHgAAcGEhoAAAAOsQUAAAgHWafZIsAHs1PidF4rwUAG0TIygAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA7P4gHaiKaeswMA7RUjKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDpR4S4AQNN6TV8T7hIAIGwYQQEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArMON2gALcFM2AAjFCAoAALCO6wHl7NmzmjlzplJTUxUXF6fLLrtMTz75pIwxThtjjGbNmqWePXsqLi5OmZmZ2rdvn9ulAACANsr1gPLMM89o0aJF+utf/6o9e/bomWee0Zw5c7RgwQKnzZw5czR//nyVlJSooqJCnTt3VlZWlk6ePOl2OQAAoA1y/RyUjz76SKNGjVJ2drYkqVevXnrttde0efNmSd+MnsybN08zZszQqFGjJEmvvvqqfD6fVq1apTFjxrhdEgAAaGNcH0EZOnSoysrKtHfvXknSjh07tHHjRo0cOVKSdODAAQUCAWVmZjrv8Xq9Sk9PV3l5udvlAACANsj1EZTp06crGAwqLS1NHTp00NmzZzV79mzl5uZKkgKBgCTJ5/OFvM/n8znbGquvr1d9fb3zOhgMul02AACwiOsB5fXXX9fSpUu1bNky9e3bV9u3b1d+fr6SkpI0duzY89pnUVGRHn/8cZcrBfBDGl/6fLA4O0yVALgQuT7FM3XqVE2fPl1jxoxR//79dffdd2vKlCkqKiqSJPn9fklSTU1NyPtqamqcbY0VFhaqrq7OWaqrq90uGwAAWMT1gPLVV18pMjJ0tx06dFBDQ4MkKTU1VX6/X2VlZc72YDCoiooKZWRkNLnPmJgYeTyekAUAALRfrk/x3HLLLZo9e7ZSUlLUt29fbdu2TXPnztW9994rSYqIiFB+fr6eeuop9e7dW6mpqZo5c6aSkpI0evRot8sBAABtkOsBZcGCBZo5c6YefPBBHTlyRElJSbrvvvs0a9Ysp820adN04sQJTZw4UbW1tRo+fLhKS0sVGxvrdjkAAKANijDfvcVrGxEMBuX1elVXV8d0D9qFlnwWz/me3MpJsgDc1py/3zwsEGjnmgo/hA0AtuNhgQAAwDoEFAAAYB2meACXce4GAPx8jKAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0eFgjgnAccAkC4MYICAACsQ0ABAADWYYoHCAOmVADghzGCAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYhxu1AT8DN1wDgJbBCAoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA53kgVaGHebBYDmYwQFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOvwsEAA563xgxAPFmeHqRIA7Q0jKAAAwDotElAOHz6su+66SwkJCYqLi1P//v21detWZ7sxRrNmzVLPnj0VFxenzMxM7du3ryVKAQAAbZDrAeXLL7/UsGHD1LFjR7377rvavXu3/vznP6tbt25Omzlz5mj+/PkqKSlRRUWFOnfurKysLJ08edLtcgAAQBvk+jkozzzzjJKTk7V48WJnXWpqqvNvY4zmzZunGTNmaNSoUZKkV199VT6fT6tWrdKYMWPcLgkAALQxro+gvPXWWxo8eLBuu+02JSYmasCAAXrppZec7QcOHFAgEFBmZqazzuv1Kj09XeXl5U3us76+XsFgMGQBAADtl+sjKPv379eiRYtUUFCgP/7xj9qyZYsefvhhRUdHa+zYsQoEApIkn88X8j6fz+dsa6yoqEiPP/6426UCaIbGV+wAQEtyfQSloaFBAwcO1NNPP60BAwZo4sSJmjBhgkpKSs57n4WFhaqrq3OW6upqFysGAAC2cT2g9OzZU1deeWXIuj59+ujQoUOSJL/fL0mqqakJaVNTU+NsaywmJkYejydkAQAA7ZfrAWXYsGGqqqoKWbd3715dcsklkr45Ydbv96usrMzZHgwGVVFRoYyMDLfLAQAAbZDr56BMmTJFQ4cO1dNPP63bb79dmzdv1osvvqgXX3xRkhQREaH8/Hw99dRT6t27t1JTUzVz5kwlJSVp9OjRbpcDAADaINcDyrXXXquVK1eqsLBQTzzxhFJTUzVv3jzl5uY6baZNm6YTJ05o4sSJqq2t1fDhw1VaWqrY2Fi3ywEAAG1QizyL5+abb9bNN9/8vdsjIiL0xBNP6IknnmiJjwcAAG0cz+IBAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWCcq3AUAaN96TV8T8vpgcXaYKgHQljCCAgAArENAAQAA1mGKB7gANZ52AQDbMIICAACsQ0ABAADWIaAAAADrcA4K0AycuwEArYMRFAAAYB0CCgAAsA5TPADaBO5IC1xYGEEBAADWIaAAAADrMMUDoFU1dSUU0zUAGmMEBQAAWIeAAgAArMMUDwDXcCM7AG5hBAUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHW4igdA2J3Pc3a44RvQvjGCAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsw51kge/R1J1KAQCtgxEUAABgHQIKAACwDgEFAABYh4ACAACs0+IBpbi4WBEREcrPz3fWnTx5Unl5eUpISFCXLl2Uk5Ojmpqali4FAAC0ES16Fc+WLVv0wgsv6KqrrgpZP2XKFK1Zs0YrVqyQ1+vVpEmTdOutt+rDDz9syXIAtBFcQQWgxUZQjh8/rtzcXL300kvq1q2bs76urk4vv/yy5s6dq+uvv16DBg3S4sWL9dFHH2nTpk0tVQ4AAGhDWiyg5OXlKTs7W5mZmSHrKysrdfr06ZD1aWlpSklJUXl5eZP7qq+vVzAYDFkAAED71SJTPMuXL9fHH3+sLVu2nLMtEAgoOjpa8fHxIet9Pp8CgUCT+ysqKtLjjz/eEqUCDqYVAMAero+gVFdXa/LkyVq6dKliY2Nd2WdhYaHq6uqcpbq62pX9AgAAO7keUCorK3XkyBENHDhQUVFRioqK0vr16zV//nxFRUXJ5/Pp1KlTqq2tDXlfTU2N/H5/k/uMiYmRx+MJWQAAQPvl+hTPiBEjtHPnzpB148aNU1pamh555BElJyerY8eOKisrU05OjiSpqqpKhw4dUkZGhtvlAACANsj1gNK1a1f169cvZF3nzp2VkJDgrB8/frwKCgrUvXt3eTwePfTQQ8rIyNB1113ndjkALiCNzyM6WJwdpkoA/FxheZrxc889p8jISOXk5Ki+vl5ZWVl6/vnnw1EKAACwUIQxxoS7iOYKBoPyer2qq6vjfBS4hqt42h9GUAC7NOfvN8/iAQAA1iGgAAAA6xBQAACAdcJykiwAtIamzivivBSgbWAEBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsE5UuAsAwqHX9DXhLgEA8AMYQQEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOjwsEMAFpfGDIg8WZ4epEgA/hBEUAABgHQIKAACwDlM8uCA0HtYHANiNERQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDquB5SioiJde+216tq1qxITEzV69GhVVVWFtDl58qTy8vKUkJCgLl26KCcnRzU1NW6XAgAA2ijXA8r69euVl5enTZs2ae3atTp9+rRuuOEGnThxwmkzZcoUvf3221qxYoXWr1+vzz//XLfeeqvbpQAAgDbK9Vvdl5aWhrxesmSJEhMTVVlZqV/96leqq6vTyy+/rGXLlun666+XJC1evFh9+vTRpk2bdN1117ldEgAAaGNa/ByUuro6SVL37t0lSZWVlTp9+rQyMzOdNmlpaUpJSVF5eXmT+6ivr1cwGAxZAABA+9WiAaWhoUH5+fkaNmyY+vXrJ0kKBAKKjo5WfHx8SFufz6dAINDkfoqKiuT1ep0lOTm5JcsGAABh1qIBJS8vT7t27dLy5ct/1n4KCwtVV1fnLNXV1S5VCAAAbOT6OSjfmjRpklavXq0NGzbo4osvdtb7/X6dOnVKtbW1IaMoNTU18vv9Te4rJiZGMTExLVUqAACwjOsBxRijhx56SCtXrtQHH3yg1NTUkO2DBg1Sx44dVVZWppycHElSVVWVDh06pIyMDLfLAYAW0Wv6mpDXB4uzw1QJ0D65HlDy8vK0bNkyvfnmm+ratatzXonX61VcXJy8Xq/Gjx+vgoICde/eXR6PRw899JAyMjK4ggcAAEhqgYCyaNEiSdJvfvObkPWLFy/WPffcI0l67rnnFBkZqZycHNXX1ysrK0vPP/+826UAAIA2qkWmeH5MbGysFi5cqIULF7r98QAAoB3gWTwAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANZpsVvdA0Bb0PiOsNL53RXWrf0A+AYjKAAAwDoEFAAAYB2meNDuNDXUDvwc/E4BrY8RFAAAYB0CCgAAsA5TPGjzGH6H2/idAsKPERQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdaLCXQDQHL2mrwl3CcBP1vj39WBxdpgqAdoeRlAAAIB1CCgAAMA6TPEAQCtpaoqSaR+gaYygAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADW4UZtABBGPK8HaBojKAAAwDoEFAAAYB0CCgAAsA7noMAaPEgNAPAtRlAAAIB1CCgAAMA6TPHAak1N+wDtWUv+zjeeMv0pn/VTplmZnkVLYAQFAABYh4ACAACswxQPAKDF/ZRpILemitrrlFN7Pa7vwwgKAACwTlgDysKFC9WrVy/FxsYqPT1dmzdvDmc5AADAEmGb4vnHP/6hgoIClZSUKD09XfPmzVNWVpaqqqqUmJgYrrLgEreuDgDgnvO5Quh8rypy62qk1rySz7bvrdbsQxu/j8M2gjJ37lxNmDBB48aN05VXXqmSkhJ16tRJr7zySrhKAgAAlgjLCMqpU6dUWVmpwsJCZ11kZKQyMzNVXl5+Tvv6+nrV19c7r+vq6iRJwWCw5YvFeWmo/+pH2zT++f2U9wBoP1rzO+Cn/L04n++tluRWPTYd17efY4z58cYmDA4fPmwkmY8++ihk/dSpU82QIUPOaf/YY48ZSSwsLCwsLCztYKmurv7RrNAmLjMuLCxUQUGB87qhoUFHjx5VQkKCIiIiXP2sYDCo5ORkVVdXy+PxuLpv/A/93Dro59ZBP7cO+rn1tFRfG2N07NgxJSUl/WjbsASUHj16qEOHDqqpqQlZX1NTI7/ff077mJgYxcTEhKyLj49vyRLl8Xj4D9AK6OfWQT+3Dvq5ddDPracl+trr9f6kdmE5STY6OlqDBg1SWVmZs66hoUFlZWXKyMgIR0kAAMAiYZviKSgo0NixYzV48GANGTJE8+bN04kTJzRu3LhwlQQAACwRtoByxx136N///rdmzZqlQCCga665RqWlpfL5fOEqSdI300mPPfbYOVNKcBf93Dro59ZBP7cO+rn12NDXEcb8lGt9AAAAWg/P4gEAANYhoAAAAOsQUAAAgHUIKAAAwDoElO9YuHChevXqpdjYWKWnp2vz5s3hLslaRUVFuvbaa9W1a1clJiZq9OjRqqqqCmlz8uRJ5eXlKSEhQV26dFFOTs45N+c7dOiQsrOz1alTJyUmJmrq1Kk6c+ZMSJsPPvhAAwcOVExMjC6//HItWbKkpQ/PWsXFxYqIiFB+fr6zjn52z+HDh3XXXXcpISFBcXFx6t+/v7Zu3epsN8Zo1qxZ6tmzp+Li4pSZmal9+/aF7OPo0aPKzc2Vx+NRfHy8xo8fr+PHj4e0+eSTT/R///d/io2NVXJysubMmdMqx2eDs2fPaubMmUpNTVVcXJwuu+wyPfnkkyHPZqGfm2/Dhg265ZZblJSUpIiICK1atSpke2v26YoVK5SWlqbY2Fj1799f77zzzvkd1M9/sk77sHz5chMdHW1eeeUV8+mnn5oJEyaY+Ph4U1NTE+7SrJSVlWUWL15sdu3aZbZv325uuukmk5KSYo4fP+60uf/++01ycrIpKyszW7duNdddd50ZOnSos/3MmTOmX79+JjMz02zbts288847pkePHqawsNBps3//ftOpUydTUFBgdu/ebRYsWGA6dOhgSktLW/V4bbB582bTq1cvc9VVV5nJkyc76+lndxw9etRccskl5p577jEVFRVm//795r333jOfffaZ06a4uNh4vV6zatUqs2PHDvO73/3OpKammq+//tppc+ONN5qrr77abNq0yfzzn/80l19+ubnzzjud7XV1dcbn85nc3Fyza9cu89prr5m4uDjzwgsvtOrxhsvs2bNNQkKCWb16tTlw4IBZsWKF6dKli/nLX/7itKGfm++dd94xjz76qHnjjTeMJLNy5cqQ7a3Vpx9++KHp0KGDmTNnjtm9e7eZMWOG6dixo9m5c2ezj4mA8v8NGTLE5OXlOa/Pnj1rkpKSTFFRURirajuOHDliJJn169cbY4ypra01HTt2NCtWrHDa7Nmzx0gy5eXlxphv/kNFRkaaQCDgtFm0aJHxeDymvr7eGGPMtGnTTN++fUM+64477jBZWVktfUhWOXbsmOndu7dZu3at+fWvf+0EFPrZPY888ogZPnz4925vaGgwfr/f/OlPf3LW1dbWmpiYGPPaa68ZY4zZvXu3kWS2bNnitHn33XdNRESEOXz4sDHGmOeff95069bN6ftvP/uKK65w+5CslJ2dbe69996QdbfeeqvJzc01xtDPbmgcUFqzT2+//XaTnZ0dUk96erq57777mn0cTPFIOnXqlCorK5WZmemsi4yMVGZmpsrLy8NYWdtRV1cnSerevbskqbKyUqdPnw7p07S0NKWkpDh9Wl5erv79+4fcnC8rK0vBYFCffvqp0+a7+/i2zYX2c8nLy1N2dvY5fUE/u+ett97S4MGDddtttykxMVEDBgzQSy+95Gw/cOCAAoFASD95vV6lp6eH9HV8fLwGDx7stMnMzFRkZKQqKiqcNr/61a8UHR3ttMnKylJVVZW+/PLLlj7MsBs6dKjKysq0d+9eSdKOHTu0ceNGjRw5UhL93BJas0/d/C4hoEj6z3/+o7Nnz55zF1ufz6dAIBCmqtqOhoYG5efna9iwYerXr58kKRAIKDo6+pyHOn63TwOBQJN9/u22H2oTDAb19ddft8ThWGf58uX6+OOPVVRUdM42+tk9+/fv16JFi9S7d2+99957euCBB/Twww/rb3/7m6T/9dUPfU8EAgElJiaGbI+KilL37t2b9fNoz6ZPn64xY8YoLS1NHTt21IABA5Sfn6/c3FxJ9HNLaM0+/b4259PnYbvVPdqPvLw87dq1Sxs3bgx3Ke1OdXW1Jk+erLVr1yo2Njbc5bRrDQ0NGjx4sJ5++mlJ0oABA7Rr1y6VlJRo7NixYa6u/Xj99de1dOlSLVu2TH379tX27duVn5+vpKQk+hkhGEGR1KNHD3Xo0OGcKx9qamrk9/vDVFXbMGnSJK1evVrvv/++Lr74Yme93+/XqVOnVFtbG9L+u33q9/ub7PNvt/1QG4/Ho7i4OLcPxzqVlZU6cuSIBg4cqKioKEVFRWn9+vWaP3++oqKi5PP56GeX9OzZU1deeWXIuj59+ujQoUOS/tdXP/Q94ff7deTIkZDtZ86c0dGjR5v182jPpk6d6oyi9O/fX3fffbemTJnijBDSz+5rzT79vjbn0+cEFEnR0dEaNGiQysrKnHUNDQ0qKytTRkZGGCuzlzFGkyZN0sqVK7Vu3TqlpqaGbB80aJA6duwY0qdVVVU6dOiQ06cZGRnauXNnyH+KtWvXyuPxOH8oMjIyQvbxbZsL5ecyYsQI7dy5U9u3b3eWwYMHKzc31/k3/eyOYcOGnXOp/N69e3XJJZdIklJTU+X3+0P6KRgMqqKiIqSva2trVVlZ6bRZt26dGhoalJ6e7rTZsGGDTp8+7bRZu3atrrjiCnXr1q3Fjs8WX331lSIjQ//0dOjQQQ0NDZLo55bQmn3q6ndJs0+rbaeWL19uYmJizJIlS8zu3bvNxIkTTXx8fMiVD/ifBx54wHi9XvPBBx+YL774wlm++uorp839999vUlJSzLp168zWrVtNRkaGycjIcLZ/e/nrDTfcYLZv325KS0vNL37xiyYvf506darZs2ePWbhw4QV3+Wtj372Kxxj62S2bN282UVFRZvbs2Wbfvn1m6dKlplOnTubvf/+706a4uNjEx8ebN99803zyySdm1KhRTV6qOWDAAFNRUWE2btxoevfuHXKpZm1trfH5fObuu+82u3btMsuXLzedOnVqt5e/NjZ27Fhz0UUXOZcZv/HGG6ZHjx5m2rRpThv6ufmOHTtmtm3bZrZt22Ykmblz55pt27aZf/3rX8aY1uvTDz/80ERFRZlnn33W7Nmzxzz22GNcZuyGBQsWmJSUFBMdHW2GDBliNm3aFO6SrCWpyWXx4sVOm6+//to8+OCDplu3bqZTp07m97//vfniiy9C9nPw4EEzcuRIExcXZ3r06GH+8Ic/mNOnT4e0ef/9980111xjoqOjzaWXXhryGReixgGFfnbP22+/bfr162diYmJMWlqaefHFF0O2NzQ0mJkzZxqfz2diYmLMiBEjTFVVVUib//73v+bOO+80Xbp0MR6Px4wbN84cO3YspM2OHTvM8OHDTUxMjLnoootMcXFxix+bLYLBoJk8ebJJSUkxsbGx5tJLLzWPPvpoyKWr9HPzvf/++01+J48dO9YY07p9+vrrr5tf/vKXJjo62vTt29esWbPmvI4pwpjv3L4PAADAApyDAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1/h+N5mh7mC8QxgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/reproduce-mgoksu-deotte/train_data_final/train_data_final.csv\")\n",
    "df = df.fillna('')\n",
    "\n",
    "df = df[:2000]\n",
    "\n",
    "df['context_len'] = df['context'].apply(lambda x: len(x))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df['context_len'], bins=100, range=(0, 10000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_df(df):\n",
    "    # Create a combined questions column\n",
    "    df['questions'] = df[['A', 'B', 'C', 'D', 'E']].apply(\n",
    "        lambda x: f'A) {x[\"A\"]}\\nB) {x[\"B\"]} \\nC) {x[\"C\"]} \\nD) {x[\"D\"]} \\nE) {x[\"E\"]}', axis=1)\n",
    "\n",
    "    def get_context_and_prompt_and_questions(row): \n",
    "        context = row['context']\n",
    "        question = row['prompt'] \n",
    "        questions = row['questions']\n",
    "        \n",
    "        x = f\"{context}. Given the context, try to answer this questions: \\n\\n{question}\\nThese are the possible answers\\n{questions}.\"\n",
    "        return x\n",
    "\n",
    "    df['context_and_prompt_and_questions'] = df.apply(lambda x: get_context_and_prompt_and_questions(x), axis=1)\n",
    "\n",
    "    def get_proposed_answer_and_labels(x):\n",
    "        options = \"ABCDE\"\n",
    "        \n",
    "        correct_answer_label = x['answer']\n",
    "        \n",
    "        # remove correct answer\n",
    "        options = options.replace(correct_answer_label, \"\")\n",
    "        \n",
    "        wrong_answers = [x[option] for option in options]\n",
    "        correct_answer = [x[correct_answer_label]]\n",
    "        \n",
    "        possible_answers = wrong_answers + correct_answer\n",
    "        labels = [-1] * len(wrong_answers) + [1]\n",
    "        return possible_answers, labels\n",
    "\n",
    "    # Use separate column names for the expanded output\n",
    "    df['proposed_answer'], df['is_answer_correct'] = zip(*df.apply(lambda x: get_proposed_answer_and_labels(x), axis=1))\n",
    "\n",
    "    # explore by proposed_answer and is_answer_correct simulatenously\n",
    "    df = df.explode(['proposed_answer', 'is_answer_correct'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = preprocess_df(train_df).reset_index(drop=True)\n",
    "test_df = preprocess_df(test_df).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 121\n",
      "CUDA SETUP: Loading binary /home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/viktor/miniconda3/envs/torch-env did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, LoggingHandler\n",
    "from transformers import ProgressCallback\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create InputExamples\n",
    "# Label examples with correct answer as 1\n",
    "train_examples = [InputExample(texts=[row['context_and_prompt_and_questions'], row['proposed_answer']], label=float(row['is_answer_correct'])) for _, row in train_df.iterrows()]\n",
    "test_examples = [InputExample(texts=[row['context_and_prompt_and_questions'], row['proposed_answer']], label=float(row['is_answer_correct'])) for _, row in test_df.iterrows()]\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)  # adjust batch_size as needed\n",
    "test_dataloader = DataLoader(test_examples, shuffle=True, batch_size=32)  # adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-16 20:01:20 - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2023-09-16 20:01:20 - Use pytorch device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ef833d53b147fe9c7383f2e5800945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf447253993d44baa0a7228809b6d1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">78</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">75 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">76 </span>train_eval_callback = TrainEvalCallback(train_df, test_df)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">77 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>78 model.fit(                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>train_objectives=[(train_dataloader, train_loss)],                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>epochs=num_epochs,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">81 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>warmup_steps=warmup_steps,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/sentence_transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Sentenc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eTransformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">721</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">718 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">719 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>skip_scheduler = scaler.get_scale() != scale_before_step           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">720 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>721 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>loss_value = loss_model(features, labels)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">722 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>loss_value.backward()                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">723 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">724 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>optimizer.step()                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">15</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">01</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/sentence_transformers/losses/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">MSELoss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, sentence_features: Iterable[Dict[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, Tensor]], labels: Tensor):      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>rep = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(sentence_features[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])[<span style=\"color: #808000; text-decoration-color: #808000\">'sentence_embedding'</span>]                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>24 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.loss_fct(rep, labels)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">15</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">01</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">536</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(size_average, reduce, reduction)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 535 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 536 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.mse_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 537 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 538 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 539 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">BCELoss</span>(_WeightedLoss):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3294</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mse_loss</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3291 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3292 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3293 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3294 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>expanded_input, expanded_target = torch.broadcast_tensors(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3295 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(re  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3296 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3297 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">74</span> in     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">broadcast_tensors</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># This wrapper exists to support variadic args.</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_torch_function(tensors):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> handle_torch_function(broadcast_tensors, tensors, *tensors)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  74 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _VF.broadcast_tensors(tensors)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[attr-defined]</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  75 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  76 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  77 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">broadcast_shapes</span>(*shapes):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>The size of tensor a <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span> must match the size of tensor b <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">)</span> at non-singleton dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m78\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m75 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m76 \u001b[0mtrain_eval_callback = TrainEvalCallback(train_df, test_df)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m77 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m78 model.fit(                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m79 \u001b[0m\u001b[2m│   \u001b[0mtrain_objectives=[(train_dataloader, train_loss)],                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m80 \u001b[0m\u001b[2m│   \u001b[0mepochs=num_epochs,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m81 \u001b[0m\u001b[2m│   \u001b[0mwarmup_steps=warmup_steps,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/sentence_transformers/\u001b[0m\u001b[1;33mSentenc\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33meTransformer.py\u001b[0m:\u001b[94m721\u001b[0m in \u001b[92mfit\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m718 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m719 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mskip_scheduler = scaler.get_scale() != scale_before_step           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m720 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m721 \u001b[2m│   │   │   │   │   │   \u001b[0mloss_value = loss_model(features, labels)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m722 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mloss_value.backward()                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m723 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtorch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m724 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0moptimizer.step()                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m15\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m01\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/sentence_transformers/losses/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mMSELoss.py\u001b[0m:\u001b[94m24\u001b[0m in \u001b[92mforward\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, sentence_features: Iterable[Dict[\u001b[96mstr\u001b[0m, Tensor]], labels: Tensor):      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   │   \u001b[0mrep = \u001b[96mself\u001b[0m.model(sentence_features[\u001b[94m0\u001b[0m])[\u001b[33m'\u001b[0m\u001b[33msentence_embedding\u001b[0m\u001b[33m'\u001b[0m]                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m24 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.loss_fct(rep, labels)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m15\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m01\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mloss.py\u001b[0m:\u001b[94m536\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(size_average, reduce, reduction)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 535 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 536 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.mse_loss(\u001b[96minput\u001b[0m, target, reduction=\u001b[96mself\u001b[0m.reduction)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 537 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 538 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 539 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mBCELoss\u001b[0m(_WeightedLoss):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m3294\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mmse_loss\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3291 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3292 \u001b[0m\u001b[2m│   │   \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3293 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3294 \u001b[2m│   \u001b[0mexpanded_input, expanded_target = torch.broadcast_tensors(\u001b[96minput\u001b[0m, target)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3295 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(re  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3296 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3297 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/torch/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m74\u001b[0m in     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbroadcast_tensors\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# This wrapper exists to support variadic args.\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m has_torch_function(tensors):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m handle_torch_function(broadcast_tensors, tensors, *tensors)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  74 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _VF.broadcast_tensors(tensors)  \u001b[2m# type: ignore[attr-defined]\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  75 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  76 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  77 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbroadcast_shapes\u001b[0m(*shapes):                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mThe size of tensor a \u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m must match the size of tensor b \u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1m)\u001b[0m at non-singleton dimension \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S', level=logging.INFO, handlers=[LoggingHandler()])\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model and loss\n",
    "# model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model[1].pooling_mode_max_tokens = True\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "# train_loss = CustomCosineSimilarityLoss()\n",
    "# train_loss = losses.MSELoss(model=model)\n",
    "\n",
    "\n",
    "# Training\n",
    "num_epochs = 10  # Adjust as needed\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_max_similarity_correct(group):\n",
    "    # 1) Find the index of the maximum cosine similarity\n",
    "    max_cosine_idx = group['cosine_similarity'].idxmax()\n",
    "    \n",
    "    # Retrieve the row\n",
    "    max_row = group.loc[[max_cosine_idx]]  # Using double brackets to ensure it remains as DataFrame\n",
    "    \n",
    "    # Check if the \"is_answer_correct\" value is 1 at that index\n",
    "    max_row['is_max_similarity_correct'] = max_row['is_answer_correct'] == 1\n",
    "    \n",
    "    return max_row\n",
    "\n",
    "\n",
    "def custom_evaluate(df):\n",
    "\n",
    "    # 1. Compute embeddings\n",
    "    context_embeddings = model.encode(df['context_and_prompt_and_questions'].tolist())\n",
    "    proposed_answer_embeddings = model.encode(df['proposed_answer'].tolist())\n",
    "\n",
    "    # 2. Calculate cosine similarity\n",
    "    # This computes the cosine similarity for each pair (context, proposed_answer)\n",
    "    cosine_similarities = np.sum(context_embeddings * proposed_answer_embeddings, axis=1) / (np.linalg.norm(context_embeddings, axis=1) * np.linalg.norm(proposed_answer_embeddings, axis=1))\n",
    "\n",
    "    # Add cosine similarities to the dataframe\n",
    "    df['cosine_similarity'] = cosine_similarities\n",
    "    \n",
    "    result_df = df.groupby('prompt').apply(check_max_similarity_correct).reset_index(drop=True)\n",
    "    \n",
    "    accuracy = result_df.is_max_similarity_correct.mean()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class TrainEvalCallback(SentenceEvaluator):\n",
    "    def __init__(self, train_df, test_df):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
    "        train_acc = custom_evaluate(self.train_df)\n",
    "        eval_acc = custom_evaluate(self.test_df)\n",
    "        logging.info(f\"Epoch {epoch}, Train Accuracy: {train_acc}, Eval Accuracy: {eval_acc}\")\n",
    "        # You can choose to return either the train_acc or eval_acc or an average of both.\n",
    "        return eval_acc  # or train_acc or (train_acc + eval_acc) / 2, depending on your preference\n",
    "\n",
    "train_eval_callback = TrainEvalCallback(train_df, test_df)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluator=train_eval_callback  # This should be evaluator, not callback\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
