{"cells":[{"cell_type":"markdown","metadata":{},"source":["# get context\n","\n","- context is obtained from the [https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles](https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles) notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T20:11:28.363863Z","iopub.status.busy":"2023-10-05T20:11:28.363487Z","iopub.status.idle":"2023-10-05T20:11:28.373667Z","shell.execute_reply":"2023-10-05T20:11:28.372615Z","shell.execute_reply.started":"2023-10-05T20:11:28.363835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting get_context.py\n"]}],"source":["\n","%%writefile get_context.py\n","\n","RUN_ON_KAGGLE = False\n","DEBUG = True\n","\n","import numpy as np\n","import pandas as pd \n","from datasets import load_dataset, load_from_disk\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch\n","from transformers import LongformerTokenizer, LongformerForMultipleChoice\n","import transformers\n","import pandas as pd\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import unicodedata\n","import gc\n","import os\n","\n","stop_words = ['each', 'you', 'the', 'use', 'used',\n","                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n","                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n","                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n","                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n","                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n","                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n","                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n","                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n","                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n","                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n","                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n","                  'did', 'theirs', 'can', 'those',\n","                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n","                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n","                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n","                  'yours', 'but', 'being', \"wasn't\", 'be']\n","\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import unicodedata\n","\n","\n","def SplitList(mylist, chunk_size):\n","    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n","\n","\n","def get_relevant_documents(df_valid):\n","    df_chunk_size=800\n","    if RUN_ON_KAGGLE:\n","        cohere_dataset_filtered = load_from_disk(\"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-datasets/wiki-stem-cohere\")\n","    else:\n","        cohere_dataset_filtered = load_from_disk(\"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-datasets/wiki-stem-cohere\")\n","    modified_texts = cohere_dataset_filtered.map(lambda example:\n","                                             {'temp_text':\n","                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"',\"\")},\n","                                             num_proc=2)[\"temp_text\"]\n","    \n","    all_articles_indices = []\n","    all_articles_values = []\n","    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n","        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n","    \n","        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n","        all_articles_indices.append(articles_indices)\n","        all_articles_values.append(merged_top_scores)\n","        \n","    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n","    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n","    \n","    top_per_query = article_indices_array.shape[1]\n","    articles_flatten = [(\n","                         articles_values_array[index],\n","                         cohere_dataset_filtered[idx.item()][\"title\"],\n","                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n","                        )\n","                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n","    retrieved_articles = SplitList(articles_flatten, top_per_query)\n","    return retrieved_articles\n","\n","\n","\n","def retrieval(df_valid, modified_texts):\n","    \n","    corpus_df_valid = df_valid.apply(lambda row:\n","                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n","                                     axis=1).values\n","    vectorizer1 = TfidfVectorizer(ngram_range=(1,2),\n","                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                                 stop_words=stop_words)\n","    vectorizer1.fit(corpus_df_valid)\n","    vocab_df_valid = vectorizer1.get_feature_names_out()\n","    vectorizer = TfidfVectorizer(ngram_range=(1,2),\n","                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                                 stop_words=stop_words,\n","                                 vocabulary=vocab_df_valid)\n","    vectorizer.fit(modified_texts[:500000])\n","    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n","    \n","    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n","\n","    chunk_size = 100000\n","    top_per_chunk = 30\n","    top_per_query = 30\n","\n","    all_chunk_top_indices = []\n","    all_chunk_top_values = []\n","\n","    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n","        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n","        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n","        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n","        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n","\n","        all_chunk_top_indices.append(chunk_top_indices + idx)\n","        all_chunk_top_values.append(chunk_top_values)\n","\n","    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n","    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n","    \n","    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n","    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n","    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n","    \n","    return articles_indices, merged_top_scores\n","\n","if RUN_ON_KAGGLE:\n","    if DEBUG:\n","        df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\", index_col=\"id\")\n","    else:\n","        df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\", index_col=\"id\")\n","else:\n","    df = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-llm-science-exam/train.csv\", index_col=\"id\")\n","    # df = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/data/data_dumps/more_questions/more_questions_raw_questions_wiki_sci_3.csv\", index_col=\"id\").sample(n=2048).reset_index(drop=True)\n","\n","\n","retrieved_articles = get_relevant_documents(df)\n","gc.collect()\n","\n","\n","contexts = []\n","\n","for index in tqdm(range(df.shape[0])):\n","    row = df.iloc[index]\n","    # question is 'prompt'\n","    question = row['prompt']\n","    options = [row['A'], row['B'], row['C'], row['D'], row['E']]\n","    context = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n","    contexts.append(context)\n","    \n","df['context'] = contexts\n","df.to_parquet(\"test_with_context.parquet\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T20:11:30.789190Z","iopub.status.busy":"2023-10-05T20:11:30.788557Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading cached processed dataset at /home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-datasets/wiki-stem-cohere/cache-e94d488c6798573e_*_of_00002.arrow\n","  0%|                                                     | 0/1 [00:00<?, ?it/s]/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'doesn', 'don', 'isn', 'll', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won'] not in stop_words.\n","  warnings.warn(\n","length of vectorizer vocab is 11222\n","\n","  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n","  4%|█▌                                          | 1/28 [00:03<01:31,  3.40s/it]\u001b[A\n","  7%|███▏                                        | 2/28 [00:06<01:28,  3.40s/it]\u001b[A\n"," 11%|████▋                                       | 3/28 [00:10<01:23,  3.34s/it]\u001b[A\n"," 14%|██████▎                                     | 4/28 [00:13<01:20,  3.35s/it]\u001b[A\n"," 18%|███████▊                                    | 5/28 [00:16<01:16,  3.32s/it]\u001b[A\n"," 21%|█████████▍                                  | 6/28 [00:19<01:12,  3.30s/it]\u001b[A\n"," 25%|███████████                                 | 7/28 [00:23<01:08,  3.26s/it]\u001b[A\n"," 29%|████████████▌                               | 8/28 [00:26<01:04,  3.23s/it]\u001b[A\n"," 32%|██████████████▏                             | 9/28 [00:29<01:00,  3.20s/it]\u001b[A\n"," 36%|███████████████▎                           | 10/28 [00:32<00:57,  3.18s/it]\u001b[A\n"," 39%|████████████████▉                          | 11/28 [00:35<00:54,  3.19s/it]\u001b[A\n"," 43%|██████████████████▍                        | 12/28 [00:38<00:49,  3.12s/it]\u001b[A\n"," 46%|███████████████████▉                       | 13/28 [00:41<00:46,  3.10s/it]\u001b[A\n"," 50%|█████████████████████▌                     | 14/28 [00:44<00:43,  3.07s/it]\u001b[A\n"," 54%|███████████████████████                    | 15/28 [00:47<00:40,  3.08s/it]\u001b[A\n"," 57%|████████████████████████▌                  | 16/28 [00:50<00:36,  3.04s/it]\u001b[A\n"," 61%|██████████████████████████                 | 17/28 [00:53<00:33,  3.04s/it]\u001b[A\n"," 64%|███████████████████████████▋               | 18/28 [00:56<00:30,  3.01s/it]\u001b[A\n"," 68%|█████████████████████████████▏             | 19/28 [00:59<00:27,  3.01s/it]\u001b[A\n"," 71%|██████████████████████████████▋            | 20/28 [01:02<00:23,  2.97s/it]\u001b[A\n"," 75%|████████████████████████████████▎          | 21/28 [01:05<00:20,  2.96s/it]\u001b[A\n"," 79%|█████████████████████████████████▊         | 22/28 [01:08<00:17,  2.94s/it]\u001b[A\n"," 82%|███████████████████████████████████▎       | 23/28 [01:11<00:14,  2.91s/it]\u001b[A\n"," 86%|████████████████████████████████████▊      | 24/28 [01:14<00:11,  2.88s/it]\u001b[A\n"," 89%|██████████████████████████████████████▍    | 25/28 [01:17<00:08,  2.86s/it]\u001b[A\n"," 93%|███████████████████████████████████████▉   | 26/28 [01:19<00:05,  2.84s/it]\u001b[A\n"," 96%|█████████████████████████████████████████▍ | 27/28 [01:22<00:02,  2.78s/it]\u001b[A\n","100%|███████████████████████████████████████████| 28/28 [01:24<00:00,  3.02s/it]\u001b[A\n","100%|█████████████████████████████████████████████| 1/1 [01:38<00:00, 98.03s/it]\n","100%|██████████████████████████████████████| 200/200 [00:00<00:00, 56435.74it/s]\n"]}],"source":["!python get_context.py"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["answer\n","B    48\n","C    44\n","D    38\n","A    37\n","E    33\n","Name: count, dtype: int64\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","df = pd.read_parquet(\"test_with_context.parquet\")\n","# remove rows for which answer is not either A, B, C, D or E. Make direct comparison\n","df = df[df['answer'].isin(['A', 'B', 'C', 'D', 'E'])]\n","print(df['answer'].value_counts())\n","\n","df['context_len'] = df['context'].apply(lambda x: len(x))\n","import matplotlib.pyplot as plt\n","\n","plt.hist(df['context_len'], bins=10);"]},{"cell_type":"markdown","metadata":{},"source":["# llm-science-run-context-2"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n","CUDA SETUP: Detected CUDA version 121\n","CUDA SETUP: Loading binary /home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"]},{"name":"stderr","output_type":"stream","text":["/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/viktor/miniconda3/envs/torch-env did not contain libcudart.so as expected! Searching further paths...\n","  warn(msg)\n","/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n","  warn(msg)\n","/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n","  warn(msg)\n"]}],"source":["import os, time\n","import gc\n","import pandas as pd\n","import numpy as np\n","import re\n","from tqdm.auto import tqdm\n","import blingfire as bf\n","from __future__ import annotations\n","\n","from collections.abc import Iterable\n","\n","import faiss\n","from faiss import write_index, read_index\n","\n","from sentence_transformers import SentenceTransformer\n","\n","import torch\n","import ctypes\n","libc = ctypes.CDLL(\"libc.so.6\")\n","\n","from dataclasses import dataclass\n","from typing import Optional, Union\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from torch.utils.data import DataLoader\n","\n","from scipy.special import softmax"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["DEVICE = 0\n","MAX_LENGTH = 384\n","BATCH_SIZE = 32\n","\n","DEBUG = True\n","# DEBUG = False if len(trn)!=200 else True # If you want to save GPU Quota, check off this comment-out. But cannot get accurate weight on saving notebook\n","FILTER_LEN = 1 if DEBUG else 9\n","IND_SEARCH = 1 if DEBUG else 7\n","NUM_SENTENCES_INCLUDE = 1 if DEBUG else 25\n","CONTEXT_LEN = 1000 if DEBUG else 2305\n","VAL_SIZE = 200 if DEBUG else 1500"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["answer\n","B    48\n","C    44\n","D    38\n","A    37\n","E    33\n","Name: count, dtype: int64\n"]}],"source":["\n","test_df = pd.read_parquet(\"test_with_context.parquet\")\n","test_df = test_df[test_df['answer'].isin(['A', 'B', 'C', 'D', 'E'])]\n","print(test_df['answer'].value_counts())\n","\n","test_df.index = list(range(len(test_df)))\n","test_df['id'] = list(range(len(test_df)))\n","if DEBUG:\n","    \n","    def split_prompt(prompt, max_size=400): \n","        \"\"\"\n","        Splits a given prompt into chunks of size max_size.\n","        \"\"\"\n","        return [prompt[i:i+max_size] for i in range(0, len(prompt), max_size)]\n","\n","    # Apply the split_prompt function to each row in the \"prompt\" column\n","    test_df[\"context\"] = test_df[\"context\"].apply(lambda x: split_prompt(x))\n","\n","    # Explode the \"prompt\" column\n","    test_df = test_df.explode(\"context\", ignore_index=True)\n","    \n","    \n","    test_df[\"prompt_and_context\"] = test_df[\"context\"].apply(lambda x: x[:CONTEXT_LEN]) + \" #### \" +  test_df[\"prompt\"]\n","    \n","else:\n","    test_df[\"prompt_and_context\"] = test_df[\"context\"].apply(lambda x: x[:CONTEXT_LEN]) + \" #### \" +  test_df[\"prompt\"]\n","    \n","    \n","if \"answer\" not in test_df.columns:\n","    test_df['answer'] = 'A'"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["\n","options = 'ABCDE'\n","indices = list(range(5))\n","\n","option_to_index = {option: index for option, index in zip(options, indices)}\n","index_to_option = {index: option for option, index in zip(options, indices)}\n","\n","def preprocess(example):\n","  \n","    first_sentence = [example['prompt_and_context']] * 5\n","    second_sentence = []\n","    for option in options:\n","        second_sentence.append(example[option])\n","    \n","    tokenized_example = tokenizer(first_sentence, second_sentence, truncation='only_first')\n","    tokenized_example['label'] = option_to_index[example['answer']]\n","    return tokenized_example"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","      <th>context</th>\n","      <th>id</th>\n","      <th>prompt_and_context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>There have been a number of attempts to solve ...</td>\n","      <td>0</td>\n","      <td>There have been a number of attempts to solve ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>n predicting the rotation curves of low-surfac...</td>\n","      <td>0</td>\n","      <td>n predicting the rotation curves of low-surfac...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>rom's original proposal, proponents of MOND ha...</td>\n","      <td>0</td>\n","      <td>rom's original proposal, proponents of MOND ha...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>vides the best current evidence for the nature...</td>\n","      <td>0</td>\n","      <td>vides the best current evidence for the nature...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>ravitational force law alone.\\nThe most seriou...</td>\n","      <td>0</td>\n","      <td>ravitational force law alone.\\nThe most seriou...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1005</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>r expressing (apparently for the first time) t...</td>\n","      <td>199</td>\n","      <td>r expressing (apparently for the first time) t...</td>\n","    </tr>\n","    <tr>\n","      <th>1006</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>artifacts of the coordinate system he used, an...</td>\n","      <td>199</td>\n","      <td>artifacts of the coordinate system he used, an...</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>an Rosen submitted a paper to \"Physical Review...</td>\n","      <td>199</td>\n","      <td>an Rosen submitted a paper to \"Physical Review...</td>\n","    </tr>\n","    <tr>\n","      <th>1008</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>ties of the employed cylindrical coordinates. ...</td>\n","      <td>199</td>\n","      <td>ties of the employed cylindrical coordinates. ...</td>\n","    </tr>\n","    <tr>\n","      <th>1009</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>. In 1956, Felix Pirani remedied the confusion...</td>\n","      <td>199</td>\n","      <td>. In 1956, Felix Pirani remedied the confusion...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1010 rows × 10 columns</p>\n","</div>"],"text/plain":["                                                 prompt   \n","0     Which of the following statements accurately d...  \\\n","1     Which of the following statements accurately d...   \n","2     Which of the following statements accurately d...   \n","3     Which of the following statements accurately d...   \n","4     Which of the following statements accurately d...   \n","...                                                 ...   \n","1005  What did Arthur Eddington discover about two o...   \n","1006  What did Arthur Eddington discover about two o...   \n","1007  What did Arthur Eddington discover about two o...   \n","1008  What did Arthur Eddington discover about two o...   \n","1009  What did Arthur Eddington discover about two o...   \n","\n","                                                      A   \n","0     MOND is a theory that reduces the observed mis...  \\\n","1     MOND is a theory that reduces the observed mis...   \n","2     MOND is a theory that reduces the observed mis...   \n","3     MOND is a theory that reduces the observed mis...   \n","4     MOND is a theory that reduces the observed mis...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      B   \n","0     MOND is a theory that increases the discrepanc...  \\\n","1     MOND is a theory that increases the discrepanc...   \n","2     MOND is a theory that increases the discrepanc...   \n","3     MOND is a theory that increases the discrepanc...   \n","4     MOND is a theory that increases the discrepanc...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      C   \n","0     MOND is a theory that explains the missing bar...  \\\n","1     MOND is a theory that explains the missing bar...   \n","2     MOND is a theory that explains the missing bar...   \n","3     MOND is a theory that explains the missing bar...   \n","4     MOND is a theory that explains the missing bar...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      D   \n","0     MOND is a theory that reduces the discrepancy ...  \\\n","1     MOND is a theory that reduces the discrepancy ...   \n","2     MOND is a theory that reduces the discrepancy ...   \n","3     MOND is a theory that reduces the discrepancy ...   \n","4     MOND is a theory that reduces the discrepancy ...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      E answer   \n","0     MOND is a theory that eliminates the observed ...      D  \\\n","1     MOND is a theory that eliminates the observed ...      D   \n","2     MOND is a theory that eliminates the observed ...      D   \n","3     MOND is a theory that eliminates the observed ...      D   \n","4     MOND is a theory that eliminates the observed ...      D   \n","...                                                 ...    ...   \n","1005  Arthur Eddington showed that two of Einstein's...      C   \n","1006  Arthur Eddington showed that two of Einstein's...      C   \n","1007  Arthur Eddington showed that two of Einstein's...      C   \n","1008  Arthur Eddington showed that two of Einstein's...      C   \n","1009  Arthur Eddington showed that two of Einstein's...      C   \n","\n","                                                context   id   \n","0     There have been a number of attempts to solve ...    0  \\\n","1     n predicting the rotation curves of low-surfac...    0   \n","2     rom's original proposal, proponents of MOND ha...    0   \n","3     vides the best current evidence for the nature...    0   \n","4     ravitational force law alone.\\nThe most seriou...    0   \n","...                                                 ...  ...   \n","1005  r expressing (apparently for the first time) t...  199   \n","1006  artifacts of the coordinate system he used, an...  199   \n","1007  an Rosen submitted a paper to \"Physical Review...  199   \n","1008  ties of the employed cylindrical coordinates. ...  199   \n","1009  . In 1956, Felix Pirani remedied the confusion...  199   \n","\n","                                     prompt_and_context  \n","0     There have been a number of attempts to solve ...  \n","1     n predicting the rotation curves of low-surfac...  \n","2     rom's original proposal, proponents of MOND ha...  \n","3     vides the best current evidence for the nature...  \n","4     ravitational force law alone.\\nThe most seriou...  \n","...                                                 ...  \n","1005  r expressing (apparently for the first time) t...  \n","1006  artifacts of the coordinate system he used, an...  \n","1007  an Rosen submitted a paper to \"Physical Review...  \n","1008  ties of the employed cylindrical coordinates. ...  \n","1009  . In 1956, Felix Pirani remedied the confusion...  \n","\n","[1010 rows x 10 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["@dataclass\n","class DataCollatorForMultipleChoice:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    \n","    def __call__(self, features):\n","        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n","        labels = [feature.pop(label_name) for feature in features]\n","        batch_size = len(features)\n","        num_choices = len(features[0]['input_ids'])\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","        \n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n","        return batch"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["DebertaV2ForMultipleChoice(\n","  (deberta): DebertaV2Model(\n","    (embeddings): DebertaV2Embeddings(\n","      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaV2Encoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(512, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","    )\n","  )\n","  (pooler): ContextPooler(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): StableDropout()\n","  )\n","  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n","  (dropout): StableDropout()\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# model_dir = \"/kaggle/input/how-to-train-open-book-model-part-1/model_v2\"\n","# model_dir = \"/kaggle/input/llm-submissions-viktor/work_dirs/deberta-v3-data-wiki_sci-with-wiki-sentence-context-eval-kaggle-all-folds-grad-accum-128-60k/deberta-v3-large-2023-09-05-07-35-55/checkpoint-3281\"\n","model_dir =\"/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-deberta/deberta-v3-large-2023-09-17-10-00-20/checkpoint-14400\"\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n","model.eval()"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1db0e728f68c4bf4bee53d66bc557207","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1010 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["tokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt_and_context', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt_and_context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n","# tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\n","data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n","test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)"]},{"cell_type":"markdown","metadata":{},"source":["# viktor"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T07:32:49.213925Z","iopub.status.busy":"2023-10-01T07:32:49.213355Z","iopub.status.idle":"2023-10-01T07:34:45.846723Z","shell.execute_reply":"2023-10-01T07:34:45.845718Z","shell.execute_reply.started":"2023-10-01T07:32:49.213892Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e1516899e9b48739751acf248a42d0b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1010 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]}],"source":["test_predictions_viktor = []\n","\n","\n","for batch in tqdm(test_dataloader):\n","    for k in batch.keys():\n","        batch[k] = batch[k].cuda()\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","    test_predictions_viktor.append(outputs.logits.cpu().detach())\n","    \n","test_predictions_viktor = torch.cat(test_predictions_viktor)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T07:34:45.851188Z","iopub.status.busy":"2023-10-01T07:34:45.850388Z","iopub.status.idle":"2023-10-01T07:34:45.86688Z","shell.execute_reply":"2023-10-01T07:34:45.865412Z","shell.execute_reply.started":"2023-10-01T07:34:45.851154Z"},"trusted":true},"outputs":[],"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","    \n","test_predictions_viktor = sigmoid(test_predictions_viktor).numpy()\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["(1010, 5)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["test_predictions_viktor.shape"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","      <th>context</th>\n","      <th>id</th>\n","      <th>prompt_and_context</th>\n","      <th>predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>There have been a number of attempts to solve ...</td>\n","      <td>0</td>\n","      <td>There have been a number of attempts to solve ...</td>\n","      <td>[0.09250783920288086, 0.8407570719718933, 0.64...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>n predicting the rotation curves of low-surfac...</td>\n","      <td>0</td>\n","      <td>n predicting the rotation curves of low-surfac...</td>\n","      <td>[0.5846375226974487, 0.8440539240837097, 0.816...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>rom's original proposal, proponents of MOND ha...</td>\n","      <td>0</td>\n","      <td>rom's original proposal, proponents of MOND ha...</td>\n","      <td>[0.3250439763069153, 0.8170468807220459, 0.749...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>vides the best current evidence for the nature...</td>\n","      <td>0</td>\n","      <td>vides the best current evidence for the nature...</td>\n","      <td>[0.32941102981567383, 0.8600099086761475, 0.58...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Which of the following statements accurately d...</td>\n","      <td>MOND is a theory that reduces the observed mis...</td>\n","      <td>MOND is a theory that increases the discrepanc...</td>\n","      <td>MOND is a theory that explains the missing bar...</td>\n","      <td>MOND is a theory that reduces the discrepancy ...</td>\n","      <td>MOND is a theory that eliminates the observed ...</td>\n","      <td>D</td>\n","      <td>ravitational force law alone.\\nThe most seriou...</td>\n","      <td>0</td>\n","      <td>ravitational force law alone.\\nThe most seriou...</td>\n","      <td>[0.44813472032546997, 0.7416130900382996, 0.84...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1005</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>r expressing (apparently for the first time) t...</td>\n","      <td>199</td>\n","      <td>r expressing (apparently for the first time) t...</td>\n","      <td>[0.9949422478675842, 0.9864272475242615, 0.996...</td>\n","    </tr>\n","    <tr>\n","      <th>1006</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>artifacts of the coordinate system he used, an...</td>\n","      <td>199</td>\n","      <td>artifacts of the coordinate system he used, an...</td>\n","      <td>[0.9671119451522827, 0.8518756628036499, 0.998...</td>\n","    </tr>\n","    <tr>\n","      <th>1007</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>an Rosen submitted a paper to \"Physical Review...</td>\n","      <td>199</td>\n","      <td>an Rosen submitted a paper to \"Physical Review...</td>\n","      <td>[0.988251268863678, 0.9735218286514282, 0.9913...</td>\n","    </tr>\n","    <tr>\n","      <th>1008</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>ties of the employed cylindrical coordinates. ...</td>\n","      <td>199</td>\n","      <td>ties of the employed cylindrical coordinates. ...</td>\n","      <td>[0.9894894957542419, 0.9728085398674011, 0.986...</td>\n","    </tr>\n","    <tr>\n","      <th>1009</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>. In 1956, Felix Pirani remedied the confusion...</td>\n","      <td>199</td>\n","      <td>. In 1956, Felix Pirani remedied the confusion...</td>\n","      <td>[0.986641526222229, 0.9659571051597595, 0.9873...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1010 rows × 11 columns</p>\n","</div>"],"text/plain":["                                                 prompt   \n","0     Which of the following statements accurately d...  \\\n","1     Which of the following statements accurately d...   \n","2     Which of the following statements accurately d...   \n","3     Which of the following statements accurately d...   \n","4     Which of the following statements accurately d...   \n","...                                                 ...   \n","1005  What did Arthur Eddington discover about two o...   \n","1006  What did Arthur Eddington discover about two o...   \n","1007  What did Arthur Eddington discover about two o...   \n","1008  What did Arthur Eddington discover about two o...   \n","1009  What did Arthur Eddington discover about two o...   \n","\n","                                                      A   \n","0     MOND is a theory that reduces the observed mis...  \\\n","1     MOND is a theory that reduces the observed mis...   \n","2     MOND is a theory that reduces the observed mis...   \n","3     MOND is a theory that reduces the observed mis...   \n","4     MOND is a theory that reduces the observed mis...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      B   \n","0     MOND is a theory that increases the discrepanc...  \\\n","1     MOND is a theory that increases the discrepanc...   \n","2     MOND is a theory that increases the discrepanc...   \n","3     MOND is a theory that increases the discrepanc...   \n","4     MOND is a theory that increases the discrepanc...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      C   \n","0     MOND is a theory that explains the missing bar...  \\\n","1     MOND is a theory that explains the missing bar...   \n","2     MOND is a theory that explains the missing bar...   \n","3     MOND is a theory that explains the missing bar...   \n","4     MOND is a theory that explains the missing bar...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      D   \n","0     MOND is a theory that reduces the discrepancy ...  \\\n","1     MOND is a theory that reduces the discrepancy ...   \n","2     MOND is a theory that reduces the discrepancy ...   \n","3     MOND is a theory that reduces the discrepancy ...   \n","4     MOND is a theory that reduces the discrepancy ...   \n","...                                                 ...   \n","1005  Arthur Eddington showed that two of Einstein's...   \n","1006  Arthur Eddington showed that two of Einstein's...   \n","1007  Arthur Eddington showed that two of Einstein's...   \n","1008  Arthur Eddington showed that two of Einstein's...   \n","1009  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      E answer   \n","0     MOND is a theory that eliminates the observed ...      D  \\\n","1     MOND is a theory that eliminates the observed ...      D   \n","2     MOND is a theory that eliminates the observed ...      D   \n","3     MOND is a theory that eliminates the observed ...      D   \n","4     MOND is a theory that eliminates the observed ...      D   \n","...                                                 ...    ...   \n","1005  Arthur Eddington showed that two of Einstein's...      C   \n","1006  Arthur Eddington showed that two of Einstein's...      C   \n","1007  Arthur Eddington showed that two of Einstein's...      C   \n","1008  Arthur Eddington showed that two of Einstein's...      C   \n","1009  Arthur Eddington showed that two of Einstein's...      C   \n","\n","                                                context   id   \n","0     There have been a number of attempts to solve ...    0  \\\n","1     n predicting the rotation curves of low-surfac...    0   \n","2     rom's original proposal, proponents of MOND ha...    0   \n","3     vides the best current evidence for the nature...    0   \n","4     ravitational force law alone.\\nThe most seriou...    0   \n","...                                                 ...  ...   \n","1005  r expressing (apparently for the first time) t...  199   \n","1006  artifacts of the coordinate system he used, an...  199   \n","1007  an Rosen submitted a paper to \"Physical Review...  199   \n","1008  ties of the employed cylindrical coordinates. ...  199   \n","1009  . In 1956, Felix Pirani remedied the confusion...  199   \n","\n","                                     prompt_and_context   \n","0     There have been a number of attempts to solve ...  \\\n","1     n predicting the rotation curves of low-surfac...   \n","2     rom's original proposal, proponents of MOND ha...   \n","3     vides the best current evidence for the nature...   \n","4     ravitational force law alone.\\nThe most seriou...   \n","...                                                 ...   \n","1005  r expressing (apparently for the first time) t...   \n","1006  artifacts of the coordinate system he used, an...   \n","1007  an Rosen submitted a paper to \"Physical Review...   \n","1008  ties of the employed cylindrical coordinates. ...   \n","1009  . In 1956, Felix Pirani remedied the confusion...   \n","\n","                                            predictions  \n","0     [0.09250783920288086, 0.8407570719718933, 0.64...  \n","1     [0.5846375226974487, 0.8440539240837097, 0.816...  \n","2     [0.3250439763069153, 0.8170468807220459, 0.749...  \n","3     [0.32941102981567383, 0.8600099086761475, 0.58...  \n","4     [0.44813472032546997, 0.7416130900382996, 0.84...  \n","...                                                 ...  \n","1005  [0.9949422478675842, 0.9864272475242615, 0.996...  \n","1006  [0.9671119451522827, 0.8518756628036499, 0.998...  \n","1007  [0.988251268863678, 0.9735218286514282, 0.9913...  \n","1008  [0.9894894957542419, 0.9728085398674011, 0.986...  \n","1009  [0.986641526222229, 0.9659571051597595, 0.9873...  \n","\n","[1010 rows x 11 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["test_df['predictions'] = test_predictions_viktor.tolist()\n","test_df"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# save test_df as rag_2.parquet\n","test_df.to_parquet(\"train_rag_2.parquet\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import pandas as pd\n","test_df = pd.read_parquet(\"train_rag_2.parquet\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["ids = sorted(list(set(test_df['id'].values)))\n","\n","avgs = []\n","maxes  = []\n","answers = []\n","diffs_maxes = []\n","\n","for id in ids:\n","    df_id = test_df[test_df['id']==id].reset_index(drop=True)\n","    answer = df_id['answer'].values[0]\n","    answers.append(answer)\n","    \n","    predictions = np.vstack(df_id['predictions'].values)\n","    \n","    predictions_avg = np.mean(predictions, axis=0)\n","    predictions_max = np.max(predictions, axis=0)\n","    \n","    predictions_diff = predictions - predictions_avg\n","    predictions_diff_max = np.max(predictions_diff, axis=0)\n","    \n","    \n","    avgs.append(predictions_avg)\n","    maxes.append(predictions_max)\n","    diffs_maxes.append(predictions_diff_max)\n","    \n","    diffs_maxes_argmax = np.argmax(diffs_maxes, axis=1)\n","    \n","    "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.36632032479558674, 0.8219037311417716, 0.77...</td>\n","      <td>[0.5846375226974487, 0.8600099086761475, 0.909...</td>\n","      <td>[0.218317197901862, 0.03810617753437584, 0.131...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>[0.9635155200958252, 0.8921937048435211, 0.880...</td>\n","      <td>[0.9724846482276917, 0.9437506794929504, 0.927...</td>\n","      <td>[0.008969128131866455, 0.05155697464942932, 0....</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.9761407375335693, 0.7615485986073812, 0.904...</td>\n","      <td>[0.983102023601532, 0.8800554871559143, 0.9512...</td>\n","      <td>[0.0069612860679626465, 0.11850688854853308, 0...</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>C</td>\n","      <td>[0.9578394293785095, 0.9418489813804627, 0.947...</td>\n","      <td>[0.9696210622787476, 0.9673298597335815, 0.964...</td>\n","      <td>[0.011781632900238037, 0.025480878353118852, 0...</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>D</td>\n","      <td>[0.893030027548472, 0.8335470954577128, 0.8401...</td>\n","      <td>[0.8934891819953918, 0.8412802219390869, 0.875...</td>\n","      <td>[0.0004591544469197961, 0.007733126481374142, ...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>C</td>\n","      <td>[0.5495106503367424, 0.257383830845356, 0.9865...</td>\n","      <td>[0.6994795799255371, 0.4151361584663391, 0.993...</td>\n","      <td>[0.1499689295887947, 0.15775232762098312, 0.00...</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>B</td>\n","      <td>[0.9707178771495819, 0.988326738278071, 0.9866...</td>\n","      <td>[0.9866365790367126, 0.9972278475761414, 0.994...</td>\n","      <td>[0.015918701887130737, 0.008901109298070309, 0...</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>B</td>\n","      <td>[0.9921469688415527, 0.9933213442564011, 0.969...</td>\n","      <td>[0.996393620967865, 0.9971568584442139, 0.9812...</td>\n","      <td>[0.004246652126312256, 0.003835514187812805, 0...</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>D</td>\n","      <td>[0.7776605188846588, 0.7577532902359962, 0.808...</td>\n","      <td>[0.835703432559967, 0.9376516938209534, 0.9388...</td>\n","      <td>[0.05804291367530823, 0.17989840358495712, 0.1...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>C</td>\n","      <td>[0.9831094912120274, 0.9479345168386187, 0.984...</td>\n","      <td>[0.9949422478675842, 0.9864272475242615, 0.998...</td>\n","      <td>[0.011832756655556831, 0.03849273068564274, 0....</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 6 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.36632032479558674, 0.8219037311417716, 0.77...  \\\n","1      1      A  [0.9635155200958252, 0.8921937048435211, 0.880...   \n","2      2      A  [0.9761407375335693, 0.7615485986073812, 0.904...   \n","3      3      C  [0.9578394293785095, 0.9418489813804627, 0.947...   \n","4      4      D  [0.893030027548472, 0.8335470954577128, 0.8401...   \n","..   ...    ...                                                ...   \n","195  195      C  [0.5495106503367424, 0.257383830845356, 0.9865...   \n","196  196      B  [0.9707178771495819, 0.988326738278071, 0.9866...   \n","197  197      B  [0.9921469688415527, 0.9933213442564011, 0.969...   \n","198  198      D  [0.7776605188846588, 0.7577532902359962, 0.808...   \n","199  199      C  [0.9831094912120274, 0.9479345168386187, 0.984...   \n","\n","                                                   max   \n","0    [0.5846375226974487, 0.8600099086761475, 0.909...  \\\n","1    [0.9724846482276917, 0.9437506794929504, 0.927...   \n","2    [0.983102023601532, 0.8800554871559143, 0.9512...   \n","3    [0.9696210622787476, 0.9673298597335815, 0.964...   \n","4    [0.8934891819953918, 0.8412802219390869, 0.875...   \n","..                                                 ...   \n","195  [0.6994795799255371, 0.4151361584663391, 0.993...   \n","196  [0.9866365790367126, 0.9972278475761414, 0.994...   \n","197  [0.996393620967865, 0.9971568584442139, 0.9812...   \n","198  [0.835703432559967, 0.9376516938209534, 0.9388...   \n","199  [0.9949422478675842, 0.9864272475242615, 0.998...   \n","\n","                                              diff_max answers  \n","0    [0.218317197901862, 0.03810617753437584, 0.131...       D  \n","1    [0.008969128131866455, 0.05155697464942932, 0....       A  \n","2    [0.0069612860679626465, 0.11850688854853308, 0...       A  \n","3    [0.011781632900238037, 0.025480878353118852, 0...       C  \n","4    [0.0004591544469197961, 0.007733126481374142, ...       D  \n","..                                                 ...     ...  \n","195  [0.1499689295887947, 0.15775232762098312, 0.00...       C  \n","196  [0.015918701887130737, 0.008901109298070309, 0...       B  \n","197  [0.004246652126312256, 0.003835514187812805, 0...       B  \n","198  [0.05804291367530823, 0.17989840358495712, 0.1...       D  \n","199  [0.011832756655556831, 0.03849273068564274, 0....       C  \n","\n","[200 rows x 6 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_agg = pd.DataFrame({'id': ids, 'answer': answers, 'avg': avgs, 'max': maxes, 'diff_max': diffs_maxes, 'answers': answers})\n","df_agg"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.36632032479558674, 0.8219037311417716, 0.77...</td>\n","      <td>[0.5846375226974487, 0.8600099086761475, 0.909...</td>\n","      <td>[0.218317197901862, 0.03810617753437584, 0.131...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>[0.9635155200958252, 0.8921937048435211, 0.880...</td>\n","      <td>[0.9724846482276917, 0.9437506794929504, 0.927...</td>\n","      <td>[0.008969128131866455, 0.05155697464942932, 0....</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.9761407375335693, 0.7615485986073812, 0.904...</td>\n","      <td>[0.983102023601532, 0.8800554871559143, 0.9512...</td>\n","      <td>[0.0069612860679626465, 0.11850688854853308, 0...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>C</td>\n","      <td>[0.9578394293785095, 0.9418489813804627, 0.947...</td>\n","      <td>[0.9696210622787476, 0.9673298597335815, 0.964...</td>\n","      <td>[0.011781632900238037, 0.025480878353118852, 0...</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>D</td>\n","      <td>[0.893030027548472, 0.8335470954577128, 0.8401...</td>\n","      <td>[0.8934891819953918, 0.8412802219390869, 0.875...</td>\n","      <td>[0.0004591544469197961, 0.007733126481374142, ...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>C</td>\n","      <td>[0.5495106503367424, 0.257383830845356, 0.9865...</td>\n","      <td>[0.6994795799255371, 0.4151361584663391, 0.993...</td>\n","      <td>[0.1499689295887947, 0.15775232762098312, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>B</td>\n","      <td>[0.9707178771495819, 0.988326738278071, 0.9866...</td>\n","      <td>[0.9866365790367126, 0.9972278475761414, 0.994...</td>\n","      <td>[0.015918701887130737, 0.008901109298070309, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>B</td>\n","      <td>[0.9921469688415527, 0.9933213442564011, 0.969...</td>\n","      <td>[0.996393620967865, 0.9971568584442139, 0.9812...</td>\n","      <td>[0.004246652126312256, 0.003835514187812805, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>D</td>\n","      <td>[0.7776605188846588, 0.7577532902359962, 0.808...</td>\n","      <td>[0.835703432559967, 0.9376516938209534, 0.9388...</td>\n","      <td>[0.05804291367530823, 0.17989840358495712, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>C</td>\n","      <td>[0.9831094912120274, 0.9479345168386187, 0.984...</td>\n","      <td>[0.9949422478675842, 0.9864272475242615, 0.998...</td>\n","      <td>[0.011832756655556831, 0.03849273068564274, 0....</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>E</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 15 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.36632032479558674, 0.8219037311417716, 0.77...  \\\n","1      1      A  [0.9635155200958252, 0.8921937048435211, 0.880...   \n","2      2      A  [0.9761407375335693, 0.7615485986073812, 0.904...   \n","3      3      C  [0.9578394293785095, 0.9418489813804627, 0.947...   \n","4      4      D  [0.893030027548472, 0.8335470954577128, 0.8401...   \n","..   ...    ...                                                ...   \n","195  195      C  [0.5495106503367424, 0.257383830845356, 0.9865...   \n","196  196      B  [0.9707178771495819, 0.988326738278071, 0.9866...   \n","197  197      B  [0.9921469688415527, 0.9933213442564011, 0.969...   \n","198  198      D  [0.7776605188846588, 0.7577532902359962, 0.808...   \n","199  199      C  [0.9831094912120274, 0.9479345168386187, 0.984...   \n","\n","                                                   max   \n","0    [0.5846375226974487, 0.8600099086761475, 0.909...  \\\n","1    [0.9724846482276917, 0.9437506794929504, 0.927...   \n","2    [0.983102023601532, 0.8800554871559143, 0.9512...   \n","3    [0.9696210622787476, 0.9673298597335815, 0.964...   \n","4    [0.8934891819953918, 0.8412802219390869, 0.875...   \n","..                                                 ...   \n","195  [0.6994795799255371, 0.4151361584663391, 0.993...   \n","196  [0.9866365790367126, 0.9972278475761414, 0.994...   \n","197  [0.996393620967865, 0.9971568584442139, 0.9812...   \n","198  [0.835703432559967, 0.9376516938209534, 0.9388...   \n","199  [0.9949422478675842, 0.9864272475242615, 0.998...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.218317197901862, 0.03810617753437584, 0.131...       D        D  \\\n","1    [0.008969128131866455, 0.05155697464942932, 0....       A        A   \n","2    [0.0069612860679626465, 0.11850688854853308, 0...       A        A   \n","3    [0.011781632900238037, 0.025480878353118852, 0...       C        A   \n","4    [0.0004591544469197961, 0.007733126481374142, ...       D        D   \n","..                                                 ...     ...      ...   \n","195  [0.1499689295887947, 0.15775232762098312, 0.00...       C        C   \n","196  [0.015918701887130737, 0.008901109298070309, 0...       B        B   \n","197  [0.004246652126312256, 0.003835514187812805, 0...       B        B   \n","198  [0.05804291367530823, 0.17989840358495712, 0.1...       D        D   \n","199  [0.011832756655556831, 0.03849273068564274, 0....       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          D             A          B          E               C          E  \\\n","1          A             D          E          E               B          B   \n","2          D             B          D          A               C          E   \n","3          A             E          D          B               B          C   \n","4          D             C          A          A               E          C   \n","..       ...           ...        ...        ...             ...        ...   \n","195        C             B          A          A               A          E   \n","196        B             E          C          C               D          A   \n","197        B             E          A          D               D          D   \n","198        D             B          C          C               E          A   \n","199        C             B          A          D               D          D   \n","\n","    pred_max_3 pred_diff_max_3  \n","0            C               E  \n","1            B               C  \n","2            E               E  \n","3            D               C  \n","4            C               D  \n","..         ...             ...  \n","195          E               E  \n","196          A               A  \n","197          A               C  \n","198          B               C  \n","199          A               E  \n","\n","[200 rows x 15 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["\n","df_agg['pred_avg'] = df_agg['avg'].apply(lambda x: index_to_option[np.argmax(x)])\n","df_agg['pred_max'] = df_agg['max'].apply(lambda x: index_to_option[np.argmax(x)])\n","df_agg['pred_diff_max'] = df_agg['diff_max'].apply(lambda x: index_to_option[np.argmax(x)])\n","\n","# 2nd to argmax\n","df_agg['pred_avg_2'] = df_agg['avg'].apply(lambda x: index_to_option[np.argsort(x)[-2]])\n","df_agg['pred_max_2'] = df_agg['max'].apply(lambda x: index_to_option[np.argsort(x)[-2]])\n","df_agg['pred_diff_max_2'] = df_agg['diff_max'].apply(lambda x: index_to_option[np.argsort(x)[-2]])\n","\n","# 3nd to argmax\n","df_agg['pred_avg_3'] = df_agg['avg'].apply(lambda x: index_to_option[np.argsort(x)[-3]])\n","df_agg['pred_max_3'] = df_agg['max'].apply(lambda x: index_to_option[np.argsort(x)[-3]])\n","df_agg['pred_diff_max_3'] = df_agg['diff_max'].apply(lambda x: index_to_option[np.argsort(x)[-3]])\n","\n","df_agg  "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(0.86, 0.925, 0.05)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["np.average(df_agg['pred_avg'] == df_agg['answer']), np.average(df_agg['pred_max'] == df_agg['answer']), np.average(df_agg['pred_diff_max'] == df_agg['answer'])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["(0.08, 0.05, 0.035)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["np.average(df_agg['pred_avg_2'] == df_agg['answer']), np.average(df_agg['pred_max_2'] == df_agg['answer']), np.average(df_agg['pred_diff_max_2'] == df_agg['answer'])"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(0.035, 0.01, 0.06)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["np.average(df_agg['pred_avg_3'] == df_agg['answer']), np.average(df_agg['pred_max_3'] == df_agg['answer']), np.average(df_agg['pred_diff_max_3'] == df_agg['answer'])"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>diff_max_max_el</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.36632032479558674, 0.8219037311417716, 0.77...</td>\n","      <td>[0.5846375226974487, 0.8600099086761475, 0.909...</td>\n","      <td>[0.218317197901862, 0.03810617753437584, 0.131...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>0.218317</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>[0.9635155200958252, 0.8921937048435211, 0.880...</td>\n","      <td>[0.9724846482276917, 0.9437506794929504, 0.927...</td>\n","      <td>[0.008969128131866455, 0.05155697464942932, 0....</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>0.085512</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.9761407375335693, 0.7615485986073812, 0.904...</td>\n","      <td>[0.983102023601532, 0.8800554871559143, 0.9512...</td>\n","      <td>[0.0069612860679626465, 0.11850688854853308, 0...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>0.118507</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>C</td>\n","      <td>[0.9578394293785095, 0.9418489813804627, 0.947...</td>\n","      <td>[0.9696210622787476, 0.9673298597335815, 0.964...</td>\n","      <td>[0.011781632900238037, 0.025480878353118852, 0...</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>0.035758</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>D</td>\n","      <td>[0.893030027548472, 0.8335470954577128, 0.8401...</td>\n","      <td>[0.8934891819953918, 0.8412802219390869, 0.875...</td>\n","      <td>[0.0004591544469197961, 0.007733126481374142, ...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>0.035204</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>C</td>\n","      <td>[0.5495106503367424, 0.257383830845356, 0.9865...</td>\n","      <td>[0.6994795799255371, 0.4151361584663391, 0.993...</td>\n","      <td>[0.1499689295887947, 0.15775232762098312, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>0.157752</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>B</td>\n","      <td>[0.9707178771495819, 0.988326738278071, 0.9866...</td>\n","      <td>[0.9866365790367126, 0.9972278475761414, 0.994...</td>\n","      <td>[0.015918701887130737, 0.008901109298070309, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>0.145047</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>B</td>\n","      <td>[0.9921469688415527, 0.9933213442564011, 0.969...</td>\n","      <td>[0.996393620967865, 0.9971568584442139, 0.9812...</td>\n","      <td>[0.004246652126312256, 0.003835514187812805, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>0.014870</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>D</td>\n","      <td>[0.7776605188846588, 0.7577532902359962, 0.808...</td>\n","      <td>[0.835703432559967, 0.9376516938209534, 0.9388...</td>\n","      <td>[0.05804291367530823, 0.17989840358495712, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>0.179898</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>C</td>\n","      <td>[0.9831094912120274, 0.9479345168386187, 0.984...</td>\n","      <td>[0.9949422478675842, 0.9864272475242615, 0.998...</td>\n","      <td>[0.011832756655556831, 0.03849273068564274, 0....</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>0.038493</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 16 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.36632032479558674, 0.8219037311417716, 0.77...  \\\n","1      1      A  [0.9635155200958252, 0.8921937048435211, 0.880...   \n","2      2      A  [0.9761407375335693, 0.7615485986073812, 0.904...   \n","3      3      C  [0.9578394293785095, 0.9418489813804627, 0.947...   \n","4      4      D  [0.893030027548472, 0.8335470954577128, 0.8401...   \n","..   ...    ...                                                ...   \n","195  195      C  [0.5495106503367424, 0.257383830845356, 0.9865...   \n","196  196      B  [0.9707178771495819, 0.988326738278071, 0.9866...   \n","197  197      B  [0.9921469688415527, 0.9933213442564011, 0.969...   \n","198  198      D  [0.7776605188846588, 0.7577532902359962, 0.808...   \n","199  199      C  [0.9831094912120274, 0.9479345168386187, 0.984...   \n","\n","                                                   max   \n","0    [0.5846375226974487, 0.8600099086761475, 0.909...  \\\n","1    [0.9724846482276917, 0.9437506794929504, 0.927...   \n","2    [0.983102023601532, 0.8800554871559143, 0.9512...   \n","3    [0.9696210622787476, 0.9673298597335815, 0.964...   \n","4    [0.8934891819953918, 0.8412802219390869, 0.875...   \n","..                                                 ...   \n","195  [0.6994795799255371, 0.4151361584663391, 0.993...   \n","196  [0.9866365790367126, 0.9972278475761414, 0.994...   \n","197  [0.996393620967865, 0.9971568584442139, 0.9812...   \n","198  [0.835703432559967, 0.9376516938209534, 0.9388...   \n","199  [0.9949422478675842, 0.9864272475242615, 0.998...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.218317197901862, 0.03810617753437584, 0.131...       D        D  \\\n","1    [0.008969128131866455, 0.05155697464942932, 0....       A        A   \n","2    [0.0069612860679626465, 0.11850688854853308, 0...       A        A   \n","3    [0.011781632900238037, 0.025480878353118852, 0...       C        A   \n","4    [0.0004591544469197961, 0.007733126481374142, ...       D        D   \n","..                                                 ...     ...      ...   \n","195  [0.1499689295887947, 0.15775232762098312, 0.00...       C        C   \n","196  [0.015918701887130737, 0.008901109298070309, 0...       B        B   \n","197  [0.004246652126312256, 0.003835514187812805, 0...       B        B   \n","198  [0.05804291367530823, 0.17989840358495712, 0.1...       D        D   \n","199  [0.011832756655556831, 0.03849273068564274, 0....       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          D             A          B          E               C          E  \\\n","1          A             D          E          E               B          B   \n","2          D             B          D          A               C          E   \n","3          A             E          D          B               B          C   \n","4          D             C          A          A               E          C   \n","..       ...           ...        ...        ...             ...        ...   \n","195        C             B          A          A               A          E   \n","196        B             E          C          C               D          A   \n","197        B             E          A          D               D          D   \n","198        D             B          C          C               E          A   \n","199        C             B          A          D               D          D   \n","\n","    pred_max_3 pred_diff_max_3  diff_max_max_el  \n","0            C               E         0.218317  \n","1            B               C         0.085512  \n","2            E               E         0.118507  \n","3            D               C         0.035758  \n","4            C               D         0.035204  \n","..         ...             ...              ...  \n","195          E               E         0.157752  \n","196          A               A         0.145047  \n","197          A               C         0.014870  \n","198          B               C         0.179898  \n","199          A               E         0.038493  \n","\n","[200 rows x 16 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_agg['diff_max_max_el'] = df_agg['diff_max'].apply(lambda x: np.max(x))\n","df_agg"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["df_agg['max_max_el'] = df_agg['max'].apply(lambda x: np.max(x))\n","\n","# plt.hist(df_agg['max_max_el'], bins=10, density=True, alpha=0.4, label=\"correct\");\n","\n","plt.hist(df_agg[df_agg['pred_max']==df_agg['answer']]['max_max_el'], bins=30, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[df_agg['pred_max']!=df_agg['answer']]['max_max_el'], bins=30, density=True, alpha=0.4, label=\"incorrect\");\n","\n","plt.legend();"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["0.934010152284264"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df_2 = df_agg[df_agg['max_max_el'] > 0.9]\n","np.average(df_2['pred_max']==df_2['answer'])"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["0.0"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df_2 = df_agg[df_agg['max_max_el'] < 0.9]\n","np.average(df_2['pred_avg_2']==df_2['answer'])"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["0.92"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# create \"combined_prediction\" as follows: where df_agg['max_max_el'] > 0.9, take pred_max, otherwise take pred_avg_2\n","df_agg['combined_prediction'] = df_agg.apply(lambda row: row['pred_max'] if row['max_max_el'] > 0.9 else row['pred_avg_2'], axis=1)\n","\n","np.average(df_agg['combined_prediction']==df_agg['answer'])"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.hist(df_agg[(df_agg['pred_diff_max']==df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[(df_agg['pred_diff_max']!=df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"incorrect\");\n","plt.legend();"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.hist(df_agg[(df_agg['pred_diff_max']==df_agg['answer']) & (df_agg['pred_max']==df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[(df_agg['pred_diff_max']!=df_agg['answer']) & (df_agg['pred_diff_max']!=df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"incorrect\");\n","plt.legend();"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>diff_max_max_el</th>\n","      <th>max_max_el</th>\n","      <th>combined_prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.36632032479558674, 0.8219037311417716, 0.77...</td>\n","      <td>[0.5846375226974487, 0.8600099086761475, 0.909...</td>\n","      <td>[0.218317197901862, 0.03810617753437584, 0.131...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>0.218317</td>\n","      <td>0.990507</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>[0.9635155200958252, 0.8921937048435211, 0.880...</td>\n","      <td>[0.9724846482276917, 0.9437506794929504, 0.927...</td>\n","      <td>[0.008969128131866455, 0.05155697464942932, 0....</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>0.085512</td>\n","      <td>0.972485</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.9761407375335693, 0.7615485986073812, 0.904...</td>\n","      <td>[0.983102023601532, 0.8800554871559143, 0.9512...</td>\n","      <td>[0.0069612860679626465, 0.11850688854853308, 0...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>0.118507</td>\n","      <td>0.988126</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>C</td>\n","      <td>[0.9578394293785095, 0.9418489813804627, 0.947...</td>\n","      <td>[0.9696210622787476, 0.9673298597335815, 0.964...</td>\n","      <td>[0.011781632900238037, 0.025480878353118852, 0...</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>0.035758</td>\n","      <td>0.969621</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>D</td>\n","      <td>[0.893030027548472, 0.8335470954577128, 0.8401...</td>\n","      <td>[0.8934891819953918, 0.8412802219390869, 0.875...</td>\n","      <td>[0.0004591544469197961, 0.007733126481374142, ...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>0.035204</td>\n","      <td>0.918054</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>195</td>\n","      <td>C</td>\n","      <td>[0.5495106503367424, 0.257383830845356, 0.9865...</td>\n","      <td>[0.6994795799255371, 0.4151361584663391, 0.993...</td>\n","      <td>[0.1499689295887947, 0.15775232762098312, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>0.157752</td>\n","      <td>0.993598</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>196</td>\n","      <td>B</td>\n","      <td>[0.9707178771495819, 0.988326738278071, 0.9866...</td>\n","      <td>[0.9866365790367126, 0.9972278475761414, 0.994...</td>\n","      <td>[0.015918701887130737, 0.008901109298070309, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>0.145047</td>\n","      <td>0.997228</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>197</td>\n","      <td>B</td>\n","      <td>[0.9921469688415527, 0.9933213442564011, 0.969...</td>\n","      <td>[0.996393620967865, 0.9971568584442139, 0.9812...</td>\n","      <td>[0.004246652126312256, 0.003835514187812805, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>0.014870</td>\n","      <td>0.997157</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>198</td>\n","      <td>D</td>\n","      <td>[0.7776605188846588, 0.7577532902359962, 0.808...</td>\n","      <td>[0.835703432559967, 0.9376516938209534, 0.9388...</td>\n","      <td>[0.05804291367530823, 0.17989840358495712, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>0.179898</td>\n","      <td>0.956320</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>199</td>\n","      <td>C</td>\n","      <td>[0.9831094912120274, 0.9479345168386187, 0.984...</td>\n","      <td>[0.9949422478675842, 0.9864272475242615, 0.998...</td>\n","      <td>[0.011832756655556831, 0.03849273068564274, 0....</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>0.038493</td>\n","      <td>0.998189</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 18 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.36632032479558674, 0.8219037311417716, 0.77...  \\\n","1      1      A  [0.9635155200958252, 0.8921937048435211, 0.880...   \n","2      2      A  [0.9761407375335693, 0.7615485986073812, 0.904...   \n","3      3      C  [0.9578394293785095, 0.9418489813804627, 0.947...   \n","4      4      D  [0.893030027548472, 0.8335470954577128, 0.8401...   \n","..   ...    ...                                                ...   \n","195  195      C  [0.5495106503367424, 0.257383830845356, 0.9865...   \n","196  196      B  [0.9707178771495819, 0.988326738278071, 0.9866...   \n","197  197      B  [0.9921469688415527, 0.9933213442564011, 0.969...   \n","198  198      D  [0.7776605188846588, 0.7577532902359962, 0.808...   \n","199  199      C  [0.9831094912120274, 0.9479345168386187, 0.984...   \n","\n","                                                   max   \n","0    [0.5846375226974487, 0.8600099086761475, 0.909...  \\\n","1    [0.9724846482276917, 0.9437506794929504, 0.927...   \n","2    [0.983102023601532, 0.8800554871559143, 0.9512...   \n","3    [0.9696210622787476, 0.9673298597335815, 0.964...   \n","4    [0.8934891819953918, 0.8412802219390869, 0.875...   \n","..                                                 ...   \n","195  [0.6994795799255371, 0.4151361584663391, 0.993...   \n","196  [0.9866365790367126, 0.9972278475761414, 0.994...   \n","197  [0.996393620967865, 0.9971568584442139, 0.9812...   \n","198  [0.835703432559967, 0.9376516938209534, 0.9388...   \n","199  [0.9949422478675842, 0.9864272475242615, 0.998...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.218317197901862, 0.03810617753437584, 0.131...       D        D  \\\n","1    [0.008969128131866455, 0.05155697464942932, 0....       A        A   \n","2    [0.0069612860679626465, 0.11850688854853308, 0...       A        A   \n","3    [0.011781632900238037, 0.025480878353118852, 0...       C        A   \n","4    [0.0004591544469197961, 0.007733126481374142, ...       D        D   \n","..                                                 ...     ...      ...   \n","195  [0.1499689295887947, 0.15775232762098312, 0.00...       C        C   \n","196  [0.015918701887130737, 0.008901109298070309, 0...       B        B   \n","197  [0.004246652126312256, 0.003835514187812805, 0...       B        B   \n","198  [0.05804291367530823, 0.17989840358495712, 0.1...       D        D   \n","199  [0.011832756655556831, 0.03849273068564274, 0....       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          D             A          B          E               C          E  \\\n","1          A             D          E          E               B          B   \n","2          D             B          D          A               C          E   \n","3          A             E          D          B               B          C   \n","4          D             C          A          A               E          C   \n","..       ...           ...        ...        ...             ...        ...   \n","195        C             B          A          A               A          E   \n","196        B             E          C          C               D          A   \n","197        B             E          A          D               D          D   \n","198        D             B          C          C               E          A   \n","199        C             B          A          D               D          D   \n","\n","    pred_max_3 pred_diff_max_3  diff_max_max_el  max_max_el   \n","0            C               E         0.218317    0.990507  \\\n","1            B               C         0.085512    0.972485   \n","2            E               E         0.118507    0.988126   \n","3            D               C         0.035758    0.969621   \n","4            C               D         0.035204    0.918054   \n","..         ...             ...              ...         ...   \n","195          E               E         0.157752    0.993598   \n","196          A               A         0.145047    0.997228   \n","197          A               C         0.014870    0.997157   \n","198          B               C         0.179898    0.956320   \n","199          A               E         0.038493    0.998189   \n","\n","    combined_prediction  \n","0                     D  \n","1                     A  \n","2                     D  \n","3                     A  \n","4                     D  \n","..                  ...  \n","195                   C  \n","196                   B  \n","197                   B  \n","198                   D  \n","199                   C  \n","\n","[200 rows x 18 columns]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df_agg"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2987965/1884921065.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2987965/1884921065.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>answer</th>\n","      <th>avg_0</th>\n","      <th>max_0</th>\n","      <th>diff_max_0</th>\n","      <th>avg_1</th>\n","      <th>max_1</th>\n","      <th>diff_max_1</th>\n","      <th>avg_2</th>\n","      <th>max_2</th>\n","      <th>diff_max_2</th>\n","      <th>avg_3</th>\n","      <th>max_3</th>\n","      <th>diff_max_3</th>\n","      <th>avg_4</th>\n","      <th>max_4</th>\n","      <th>diff_max_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>0.366320</td>\n","      <td>0.584638</td>\n","      <td>0.218317</td>\n","      <td>0.821904</td>\n","      <td>0.860010</td>\n","      <td>0.038106</td>\n","      <td>0.777894</td>\n","      <td>0.909080</td>\n","      <td>0.131186</td>\n","      <td>0.982649</td>\n","      <td>0.990507</td>\n","      <td>0.007858</td>\n","      <td>0.812478</td>\n","      <td>0.933549</td>\n","      <td>0.121071</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.963516</td>\n","      <td>0.972485</td>\n","      <td>0.008969</td>\n","      <td>0.892194</td>\n","      <td>0.943751</td>\n","      <td>0.051557</td>\n","      <td>0.880171</td>\n","      <td>0.927696</td>\n","      <td>0.047525</td>\n","      <td>0.825989</td>\n","      <td>0.911502</td>\n","      <td>0.085512</td>\n","      <td>0.931132</td>\n","      <td>0.951647</td>\n","      <td>0.020515</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.976141</td>\n","      <td>0.983102</td>\n","      <td>0.006961</td>\n","      <td>0.761549</td>\n","      <td>0.880055</td>\n","      <td>0.118507</td>\n","      <td>0.904230</td>\n","      <td>0.951240</td>\n","      <td>0.047010</td>\n","      <td>0.966260</td>\n","      <td>0.988126</td>\n","      <td>0.021866</td>\n","      <td>0.930902</td>\n","      <td>0.972149</td>\n","      <td>0.041247</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>0.957839</td>\n","      <td>0.969621</td>\n","      <td>0.011782</td>\n","      <td>0.941849</td>\n","      <td>0.967330</td>\n","      <td>0.025481</td>\n","      <td>0.947808</td>\n","      <td>0.964271</td>\n","      <td>0.016463</td>\n","      <td>0.951524</td>\n","      <td>0.964710</td>\n","      <td>0.013186</td>\n","      <td>0.911235</td>\n","      <td>0.946994</td>\n","      <td>0.035758</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>0.893030</td>\n","      <td>0.893489</td>\n","      <td>0.000459</td>\n","      <td>0.833547</td>\n","      <td>0.841280</td>\n","      <td>0.007733</td>\n","      <td>0.840133</td>\n","      <td>0.875337</td>\n","      <td>0.035204</td>\n","      <td>0.905346</td>\n","      <td>0.918054</td>\n","      <td>0.012709</td>\n","      <td>0.644154</td>\n","      <td>0.671055</td>\n","      <td>0.026901</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>2</td>\n","      <td>0.549511</td>\n","      <td>0.699480</td>\n","      <td>0.149969</td>\n","      <td>0.257384</td>\n","      <td>0.415136</td>\n","      <td>0.157752</td>\n","      <td>0.986552</td>\n","      <td>0.993598</td>\n","      <td>0.007046</td>\n","      <td>0.237923</td>\n","      <td>0.330299</td>\n","      <td>0.092376</td>\n","      <td>0.392266</td>\n","      <td>0.505310</td>\n","      <td>0.113044</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>1</td>\n","      <td>0.970718</td>\n","      <td>0.986637</td>\n","      <td>0.015919</td>\n","      <td>0.988327</td>\n","      <td>0.997228</td>\n","      <td>0.008901</td>\n","      <td>0.986613</td>\n","      <td>0.994565</td>\n","      <td>0.007952</td>\n","      <td>0.867780</td>\n","      <td>0.944320</td>\n","      <td>0.076540</td>\n","      <td>0.553370</td>\n","      <td>0.698417</td>\n","      <td>0.145047</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>1</td>\n","      <td>0.992147</td>\n","      <td>0.996394</td>\n","      <td>0.004247</td>\n","      <td>0.993321</td>\n","      <td>0.997157</td>\n","      <td>0.003836</td>\n","      <td>0.969176</td>\n","      <td>0.981238</td>\n","      <td>0.012062</td>\n","      <td>0.983010</td>\n","      <td>0.997027</td>\n","      <td>0.014016</td>\n","      <td>0.965946</td>\n","      <td>0.980816</td>\n","      <td>0.014870</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>3</td>\n","      <td>0.777661</td>\n","      <td>0.835703</td>\n","      <td>0.058043</td>\n","      <td>0.757753</td>\n","      <td>0.937652</td>\n","      <td>0.179898</td>\n","      <td>0.808531</td>\n","      <td>0.938862</td>\n","      <td>0.130331</td>\n","      <td>0.946293</td>\n","      <td>0.956320</td>\n","      <td>0.010028</td>\n","      <td>0.247790</td>\n","      <td>0.412025</td>\n","      <td>0.164235</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>2</td>\n","      <td>0.983109</td>\n","      <td>0.994942</td>\n","      <td>0.011833</td>\n","      <td>0.947935</td>\n","      <td>0.986427</td>\n","      <td>0.038493</td>\n","      <td>0.984980</td>\n","      <td>0.998189</td>\n","      <td>0.013210</td>\n","      <td>0.974702</td>\n","      <td>0.996053</td>\n","      <td>0.021351</td>\n","      <td>0.970570</td>\n","      <td>0.990725</td>\n","      <td>0.020155</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 16 columns</p>\n","</div>"],"text/plain":["     answer     avg_0     max_0  diff_max_0     avg_1     max_1  diff_max_1   \n","0         3  0.366320  0.584638    0.218317  0.821904  0.860010    0.038106  \\\n","1         0  0.963516  0.972485    0.008969  0.892194  0.943751    0.051557   \n","2         0  0.976141  0.983102    0.006961  0.761549  0.880055    0.118507   \n","3         2  0.957839  0.969621    0.011782  0.941849  0.967330    0.025481   \n","4         3  0.893030  0.893489    0.000459  0.833547  0.841280    0.007733   \n","..      ...       ...       ...         ...       ...       ...         ...   \n","195       2  0.549511  0.699480    0.149969  0.257384  0.415136    0.157752   \n","196       1  0.970718  0.986637    0.015919  0.988327  0.997228    0.008901   \n","197       1  0.992147  0.996394    0.004247  0.993321  0.997157    0.003836   \n","198       3  0.777661  0.835703    0.058043  0.757753  0.937652    0.179898   \n","199       2  0.983109  0.994942    0.011833  0.947935  0.986427    0.038493   \n","\n","        avg_2     max_2  diff_max_2     avg_3     max_3  diff_max_3     avg_4   \n","0    0.777894  0.909080    0.131186  0.982649  0.990507    0.007858  0.812478  \\\n","1    0.880171  0.927696    0.047525  0.825989  0.911502    0.085512  0.931132   \n","2    0.904230  0.951240    0.047010  0.966260  0.988126    0.021866  0.930902   \n","3    0.947808  0.964271    0.016463  0.951524  0.964710    0.013186  0.911235   \n","4    0.840133  0.875337    0.035204  0.905346  0.918054    0.012709  0.644154   \n","..        ...       ...         ...       ...       ...         ...       ...   \n","195  0.986552  0.993598    0.007046  0.237923  0.330299    0.092376  0.392266   \n","196  0.986613  0.994565    0.007952  0.867780  0.944320    0.076540  0.553370   \n","197  0.969176  0.981238    0.012062  0.983010  0.997027    0.014016  0.965946   \n","198  0.808531  0.938862    0.130331  0.946293  0.956320    0.010028  0.247790   \n","199  0.984980  0.998189    0.013210  0.974702  0.996053    0.021351  0.970570   \n","\n","        max_4  diff_max_4  \n","0    0.933549    0.121071  \n","1    0.951647    0.020515  \n","2    0.972149    0.041247  \n","3    0.946994    0.035758  \n","4    0.671055    0.026901  \n","..        ...         ...  \n","195  0.505310    0.113044  \n","196  0.698417    0.145047  \n","197  0.980816    0.014870  \n","198  0.412025    0.164235  \n","199  0.990725    0.020155  \n","\n","[200 rows x 16 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df_xgboost = df_agg[['answer', 'avg', 'max', 'diff_max']]\n","# avg, max and diff_max are arrays. Create avg_0, avg_1, ..., diff_max_0, diff_max_1, ...\n","for i in range(5):\n","    df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","    df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","    df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","    \n","df_xgboost = df_xgboost.drop(columns=['avg', 'max', 'diff_max'])\n","\n","# convert answer to 0, 1, 2, 3, 4\n","df_xgboost['answer'] = df_xgboost['answer'].apply(lambda x: option_to_index[x])\n","\n","df_xgboost"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.675\n"]}],"source":["import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Split the data into training and testing sets\n","X = df_xgboost.drop(columns=\"answer\")\n","y = df_xgboost[\"answer\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert the datasets into DMatrix instances, which is the data structure XGBoost uses\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","# Define the parameters for the XGBoost model\n","param = {\n","    'max_depth': 3,\n","    'eta': 0.3,\n","    'objective': 'multi:softprob',  # for multiclass classification problems\n","    'num_class': 5  # you mentioned 5 possible values for the answer column\n","}\n","num_round =20\n","\n","# Train the model\n","bst = xgb.train(param, dtrain, num_round)\n","\n","# Make predictions\n","preds_prob = bst.predict(dtest)\n","preds = preds_prob.argmax(axis=1)\n","\n","# Evaluate the model\n","acc = accuracy_score(y_test, preds)\n","print(f\"Accuracy: {acc}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
