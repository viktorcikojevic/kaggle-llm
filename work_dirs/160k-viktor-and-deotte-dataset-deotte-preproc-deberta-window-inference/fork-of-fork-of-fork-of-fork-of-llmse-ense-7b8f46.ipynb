{"cells":[{"cell_type":"markdown","metadata":{},"source":["# get context\n","\n","- context is obtained from the [https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles](https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles) notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T20:11:28.363863Z","iopub.status.busy":"2023-10-05T20:11:28.363487Z","iopub.status.idle":"2023-10-05T20:11:28.373667Z","shell.execute_reply":"2023-10-05T20:11:28.372615Z","shell.execute_reply.started":"2023-10-05T20:11:28.363835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting get_context.py\n"]}],"source":["\n","%%writefile get_context.py\n","\n","RUN_ON_KAGGLE = False\n","DEBUG = True\n","\n","import numpy as np\n","import pandas as pd \n","from datasets import load_dataset, load_from_disk\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch\n","from transformers import LongformerTokenizer, LongformerForMultipleChoice\n","import transformers\n","import pandas as pd\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import unicodedata\n","import gc\n","import os\n","\n","stop_words = ['each', 'you', 'the', 'use', 'used',\n","                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n","                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n","                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n","                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n","                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n","                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n","                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n","                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n","                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n","                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n","                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n","                  'did', 'theirs', 'can', 'those',\n","                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n","                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n","                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n","                  'yours', 'but', 'being', \"wasn't\", 'be']\n","\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import unicodedata\n","\n","\n","def SplitList(mylist, chunk_size):\n","    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n","\n","\n","def get_relevant_documents(df_valid):\n","    df_chunk_size=800\n","    if RUN_ON_KAGGLE:\n","        cohere_dataset_filtered = load_from_disk(\"/kaggle/working/stem-wiki-cohere-no-emb\")\n","    else:\n","        cohere_dataset_filtered = load_from_disk(\"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-datasets/wiki-stem-cohere\")\n","    modified_texts = cohere_dataset_filtered.map(lambda example:\n","                                             {'temp_text':\n","                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"',\"\")},\n","                                             num_proc=2)[\"temp_text\"]\n","    \n","    all_articles_indices = []\n","    all_articles_values = []\n","    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n","        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n","    \n","        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n","        all_articles_indices.append(articles_indices)\n","        all_articles_values.append(merged_top_scores)\n","        \n","    article_indices_array =  np.concatenate(all_articles_indices, axis=0)\n","    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n","    \n","    top_per_query = article_indices_array.shape[1]\n","    articles_flatten = [(\n","                         articles_values_array[index],\n","                         cohere_dataset_filtered[idx.item()][\"title\"],\n","                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n","                        )\n","                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n","    retrieved_articles = SplitList(articles_flatten, top_per_query)\n","    return retrieved_articles\n","\n","\n","\n","def retrieval(df_valid, modified_texts):\n","    \n","    corpus_df_valid = df_valid.apply(lambda row:\n","                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n","                                     axis=1).values\n","    vectorizer1 = TfidfVectorizer(ngram_range=(1,2),\n","                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                                 stop_words=stop_words)\n","    vectorizer1.fit(corpus_df_valid)\n","    vocab_df_valid = vectorizer1.get_feature_names_out()\n","    vectorizer = TfidfVectorizer(ngram_range=(1,2),\n","                                 token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                                 stop_words=stop_words,\n","                                 vocabulary=vocab_df_valid)\n","    vectorizer.fit(modified_texts[:500000])\n","    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n","    \n","    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n","\n","    chunk_size = 100000\n","    top_per_chunk = 30\n","    top_per_query = 30\n","\n","    all_chunk_top_indices = []\n","    all_chunk_top_values = []\n","\n","    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n","        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n","        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n","        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n","        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n","\n","        all_chunk_top_indices.append(chunk_top_indices + idx)\n","        all_chunk_top_values.append(chunk_top_values)\n","\n","    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n","    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n","    \n","    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n","    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n","    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n","    \n","    return articles_indices, merged_top_scores\n","\n","if RUN_ON_KAGGLE:\n","    if DEBUG:\n","        df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\", index_col=\"id\")\n","    else:\n","        df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\", index_col=\"id\")\n","else:\n","    \n","    df_1 = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-llm-science-exam/train.csv\", index_col=\"id\")\n","    df = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-datasets/dataset_wiki_new_1/dataset_wiki_new_1_balanced.csv\")\n","    df['id'] = np.arange(0, len(df))\n","    df = pd.concat([df, df_1], axis=0)\n","    df['id'] = np.arange(0, len(df))\n","    # df = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/data/data_dumps/more_questions/more_questions_raw_questions_wiki_sci_3.csv\", index_col=\"id\").sample(n=2048).reset_index(drop=True)\n","\n","\n","retrieved_articles = get_relevant_documents(df)\n","gc.collect()\n","\n","\n","contexts = []\n","\n","for index in tqdm(range(df.shape[0])):\n","    row = df.iloc[index]\n","    # question is 'prompt'\n","    question = row['prompt']\n","    options = [row['A'], row['B'], row['C'], row['D'], row['E']]\n","    context = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n","    contexts.append(context)\n","    \n","df['context'] = contexts\n","df.to_parquet(\"test_with_context.parquet\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_parquet(\"test_with_context.parquet\")\n","\n","# save as csv\n","df.to_csv(\"test_with_context.csv\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T20:11:30.789190Z","iopub.status.busy":"2023-10-05T20:11:30.788557Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading cached processed dataset at /home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-datasets/wiki-stem-cohere/cache-e94d488c6798573e_*_of_00002.arrow\n","  0%|                                                     | 0/1 [00:00<?, ?it/s]/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'doesn', 'don', 'isn', 'll', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won'] not in stop_words.\n","  warnings.warn(\n","length of vectorizer vocab is 28413\n","\n","  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n","  4%|█▌                                          | 1/28 [00:04<01:57,  4.34s/it]\u001b[A\n","  7%|███▏                                        | 2/28 [00:08<01:54,  4.40s/it]\u001b[A\n"," 11%|████▋                                       | 3/28 [00:13<01:50,  4.44s/it]\u001b[A\n"," 14%|██████▎                                     | 4/28 [00:17<01:45,  4.39s/it]\u001b[A\n"," 18%|███████▊                                    | 5/28 [00:21<01:41,  4.40s/it]\u001b[A\n"," 21%|█████████▍                                  | 6/28 [00:26<01:35,  4.34s/it]\u001b[A\n"," 25%|███████████                                 | 7/28 [00:30<01:32,  4.40s/it]\u001b[A\n"," 29%|████████████▌                               | 8/28 [00:35<01:27,  4.38s/it]\u001b[A\n"," 32%|██████████████▏                             | 9/28 [00:39<01:23,  4.37s/it]\u001b[A\n"," 36%|███████████████▎                           | 10/28 [00:43<01:17,  4.32s/it]\u001b[A\n"," 39%|████████████████▉                          | 11/28 [00:48<01:14,  4.41s/it]\u001b[A\n"," 43%|██████████████████▍                        | 12/28 [00:52<01:09,  4.35s/it]\u001b[A\n"," 46%|███████████████████▉                       | 13/28 [00:56<01:05,  4.35s/it]\u001b[A\n"," 50%|█████████████████████▌                     | 14/28 [01:01<01:00,  4.33s/it]\u001b[A\n"," 54%|███████████████████████                    | 15/28 [01:05<00:56,  4.34s/it]\u001b[A\n"," 57%|████████████████████████▌                  | 16/28 [01:09<00:52,  4.34s/it]\u001b[A\n"," 61%|██████████████████████████                 | 17/28 [01:14<00:47,  4.34s/it]\u001b[A\n"," 64%|███████████████████████████▋               | 18/28 [01:18<00:42,  4.28s/it]\u001b[A\n"," 68%|█████████████████████████████▏             | 19/28 [01:22<00:38,  4.30s/it]\u001b[A\n"," 71%|██████████████████████████████▋            | 20/28 [01:26<00:34,  4.28s/it]\u001b[A\n"," 75%|████████████████████████████████▎          | 21/28 [01:31<00:30,  4.30s/it]\u001b[A\n"," 79%|█████████████████████████████████▊         | 22/28 [01:35<00:25,  4.25s/it]\u001b[A\n"," 82%|███████████████████████████████████▎       | 23/28 [01:39<00:21,  4.26s/it]\u001b[A\n"," 86%|████████████████████████████████████▊      | 24/28 [01:43<00:16,  4.22s/it]\u001b[A\n"," 89%|██████████████████████████████████████▍    | 25/28 [01:47<00:12,  4.20s/it]\u001b[A\n"," 93%|███████████████████████████████████████▉   | 26/28 [01:51<00:08,  4.15s/it]\u001b[A\n"," 96%|█████████████████████████████████████████▍ | 27/28 [01:55<00:04,  4.10s/it]\u001b[A\n","100%|███████████████████████████████████████████| 28/28 [01:59<00:00,  4.25s/it]\u001b[A\n","100%|████████████████████████████████████████████| 1/1 [02:13<00:00, 133.26s/it]\n","100%|██████████████████████████████████████| 500/500 [00:00<00:00, 29622.88it/s]\n"]}],"source":["!python get_context.py"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["answer\n","A    109\n","B    108\n","D    103\n","C    100\n","E     80\n","Name: count, dtype: int64\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","df = pd.read_parquet(\"test_with_context.parquet\")\n","# remove rows for which answer is not either A, B, C, D or E. Make direct comparison\n","df = df[df['answer'].isin(['A', 'B', 'C', 'D', 'E'])]\n","print(df['answer'].value_counts())\n","\n","df['context_len'] = df['context'].apply(lambda x: len(x))\n","import matplotlib.pyplot as plt\n","\n","plt.hist(df['context_len'], bins=10);"]},{"cell_type":"markdown","metadata":{},"source":["# llm-science-run-context-2"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n","CUDA SETUP: Detected CUDA version 121\n","CUDA SETUP: Loading binary /home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"]},{"name":"stderr","output_type":"stream","text":["/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/viktor/miniconda3/envs/torch-env did not contain libcudart.so as expected! Searching further paths...\n","  warn(msg)\n","/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n","  warn(msg)\n","/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n","  warn(msg)\n"]}],"source":["import os, time\n","import gc\n","import pandas as pd\n","import numpy as np\n","import re\n","from tqdm.auto import tqdm\n","import blingfire as bf\n","from __future__ import annotations\n","\n","from collections.abc import Iterable\n","\n","import faiss\n","from faiss import write_index, read_index\n","\n","from sentence_transformers import SentenceTransformer\n","\n","import torch\n","import ctypes\n","libc = ctypes.CDLL(\"libc.so.6\")\n","\n","from dataclasses import dataclass\n","from typing import Optional, Union\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from torch.utils.data import DataLoader\n","\n","from scipy.special import softmax"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["DEVICE = 0\n","MAX_LENGTH = 384\n","BATCH_SIZE = 32\n","\n","DEBUG = True\n","# DEBUG = False if len(trn)!=200 else True # If you want to save GPU Quota, check off this comment-out. But cannot get accurate weight on saving notebook\n","FILTER_LEN = 1 if DEBUG else 9\n","IND_SEARCH = 1 if DEBUG else 7\n","NUM_SENTENCES_INCLUDE = 1 if DEBUG else 25\n","CONTEXT_LEN = 1000 if DEBUG else 2305\n","VAL_SIZE = 200 if DEBUG else 1500"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["answer\n","A    109\n","B    108\n","D    103\n","C    100\n","E     80\n","Name: count, dtype: int64\n"]}],"source":["\n","test_df = pd.read_parquet(\"test_with_context.parquet\")\n","if 'answer' in test_df.columns:\n","    test_df = test_df[test_df['answer'].isin(['A', 'B', 'C', 'D', 'E'])]\n","    print(test_df['answer'].value_counts())\n","\n","test_df.index = list(range(len(test_df)))\n","test_df['id'] = list(range(len(test_df)))\n","if DEBUG:\n","    \n","    def split_prompt(prompt, max_size=400, stride=200): \n","        \"\"\"\n","        Splits a given prompt into chunks of size max_size with a given stride.\n","        \"\"\"\n","        chunks = []\n","        for i in range(0, len(prompt) - max_size + 1, stride):\n","            chunks.append(prompt[i:i+max_size])\n","        if len(prompt) % max_size != 0:\n","            chunks.append(prompt[-max_size:])\n","        return chunks\n","\n","    # Apply the split_prompt function to each row in the \"prompt\" column\n","    test_df[\"context\"] = test_df[\"context\"].apply(lambda x: split_prompt(x))\n","\n","    # Explode the \"prompt\" column\n","    test_df = test_df.explode(\"context\", ignore_index=True)\n","    \n","    \n","    test_df['answer_all'] = test_df.apply(lambda x: \" \".join([\n","        f\"a) {x['A']}\",\n","        f\"b) {x['B']}\",\n","        f\"c) {x['C']}\",\n","        f\"d) {x['D']}\",\n","        f\"e) {x['E']}\"\n","    ]), axis=1)\n","    test_df[\"prompt_and_context\"] = test_df[\"context\"].apply(lambda x: x[:CONTEXT_LEN]) + \" #### \" +  test_df[\"prompt\"] # + \" Possible answers: \" +  test_df[\"answer_all\"]\n","    \n","else:\n","    test_df['answer_all'] = test_df.apply(lambda x: \" \".join([\n","        f\"a) {x['A']}\",\n","        f\"b) {x['B']}\",\n","        f\"c) {x['C']}\",\n","        f\"d) {x['D']}\",\n","        f\"e) {x['E']}\"\n","    ]), axis=1)\n","    test_df[\"prompt_and_context\"] = test_df[\"context\"].apply(lambda x: x[:CONTEXT_LEN]) + \" #### \" +  test_df[\"prompt\"] # + \" Possible answers: \" # +  test_df[\"answer_all\"]\n","    \n","    \n","if \"answer\" not in test_df.columns:\n","    test_df['answer'] = 'A'"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["\n","options = 'ABCDE'\n","indices = list(range(5))\n","\n","option_to_index = {option: index for option, index in zip(options, indices)}\n","index_to_option = {index: option for option, index in zip(options, indices)}\n","\n","def preprocess(example):\n","  \n","    first_sentence = [example['prompt_and_context']] * 5\n","    second_sentence = []\n","    for option in options:\n","        second_sentence.append(example[option])\n","    \n","    tokenized_example = tokenizer(first_sentence, second_sentence, truncation='only_first')\n","    tokenized_example['label'] = option_to_index[example['answer']]\n","    return tokenized_example"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>answer_all</th>\n","      <th>prompt_and_context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What is the method of transcription in the lif...</td>\n","      <td>RNA-templated transcription is the method of t...</td>\n","      <td>Transcription occurs through a unique mechanis...</td>\n","      <td>Reverse transcription is the method of transcr...</td>\n","      <td>DNA-templated transcription is the method of t...</td>\n","      <td>Transcription does not occur in the life cycle...</td>\n","      <td>D</td>\n","      <td>0</td>\n","      <td>The given phonetic transcription is how the pr...</td>\n","      <td>a) RNA-templated transcription is the method o...</td>\n","      <td>The given phonetic transcription is how the pr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What is the method of transcription in the lif...</td>\n","      <td>RNA-templated transcription is the method of t...</td>\n","      <td>Transcription occurs through a unique mechanis...</td>\n","      <td>Reverse transcription is the method of transcr...</td>\n","      <td>DNA-templated transcription is the method of t...</td>\n","      <td>Transcription does not occur in the life cycle...</td>\n","      <td>D</td>\n","      <td>0</td>\n","      <td>rd because it does not have a one-to-one corre...</td>\n","      <td>a) RNA-templated transcription is the method o...</td>\n","      <td>rd because it does not have a one-to-one corre...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What is the method of transcription in the lif...</td>\n","      <td>RNA-templated transcription is the method of t...</td>\n","      <td>Transcription occurs through a unique mechanis...</td>\n","      <td>Reverse transcription is the method of transcr...</td>\n","      <td>DNA-templated transcription is the method of t...</td>\n","      <td>Transcription does not occur in the life cycle...</td>\n","      <td>D</td>\n","      <td>0</td>\n","      <td>here it is more commonly termed \"captioning.\"\\...</td>\n","      <td>a) RNA-templated transcription is the method o...</td>\n","      <td>here it is more commonly termed \"captioning.\"\\...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What is the role of the viral fiber glycoprote...</td>\n","      <td>The viral fiber glycoproteins are involved in ...</td>\n","      <td>The viral fiber glycoproteins code for 40 prot...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>The viral fiber glycoproteins mediate endocyto...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>D</td>\n","      <td>1</td>\n","      <td>Viral glycoprotein-receptor interactions are r...</td>\n","      <td>a) The viral fiber glycoproteins are involved ...</td>\n","      <td>Viral glycoprotein-receptor interactions are r...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What is the role of the viral fiber glycoprote...</td>\n","      <td>The viral fiber glycoproteins are involved in ...</td>\n","      <td>The viral fiber glycoproteins code for 40 prot...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>The viral fiber glycoproteins mediate endocyto...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>D</td>\n","      <td>1</td>\n","      <td>hile the transmembrane (TM) glycoproteins anch...</td>\n","      <td>a) The viral fiber glycoproteins are involved ...</td>\n","      <td>hile the transmembrane (TM) glycoproteins anch...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4205</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>ropagate at the speed of light regardless of c...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>ropagate at the speed of light regardless of c...</td>\n","    </tr>\n","    <tr>\n","      <th>4206</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>he full general theory of relativity because a...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>he full general theory of relativity because a...</td>\n","    </tr>\n","    <tr>\n","      <th>4207</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>reported that the singularities in question w...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>reported that the singularities in question w...</td>\n","    </tr>\n","    <tr>\n","      <th>4208</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>grily withdrew the manuscript, never to publis...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>grily withdrew the manuscript, never to publis...</td>\n","    </tr>\n","    <tr>\n","      <th>4209</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>s, his assistant Leopold Infeld, who had been ...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>s, his assistant Leopold Infeld, who had been ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4210 rows × 11 columns</p>\n","</div>"],"text/plain":["                                                 prompt   \n","0     What is the method of transcription in the lif...  \\\n","1     What is the method of transcription in the lif...   \n","2     What is the method of transcription in the lif...   \n","3     What is the role of the viral fiber glycoprote...   \n","4     What is the role of the viral fiber glycoprote...   \n","...                                                 ...   \n","4205  What did Arthur Eddington discover about two o...   \n","4206  What did Arthur Eddington discover about two o...   \n","4207  What did Arthur Eddington discover about two o...   \n","4208  What did Arthur Eddington discover about two o...   \n","4209  What did Arthur Eddington discover about two o...   \n","\n","                                                      A   \n","0     RNA-templated transcription is the method of t...  \\\n","1     RNA-templated transcription is the method of t...   \n","2     RNA-templated transcription is the method of t...   \n","3     The viral fiber glycoproteins are involved in ...   \n","4     The viral fiber glycoproteins are involved in ...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      B   \n","0     Transcription occurs through a unique mechanis...  \\\n","1     Transcription occurs through a unique mechanis...   \n","2     Transcription occurs through a unique mechanis...   \n","3     The viral fiber glycoproteins code for 40 prot...   \n","4     The viral fiber glycoproteins code for 40 prot...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      C   \n","0     Reverse transcription is the method of transcr...  \\\n","1     Reverse transcription is the method of transcr...   \n","2     Reverse transcription is the method of transcr...   \n","3     The viral fiber glycoproteins are responsible ...   \n","4     The viral fiber glycoproteins are responsible ...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      D   \n","0     DNA-templated transcription is the method of t...  \\\n","1     DNA-templated transcription is the method of t...   \n","2     DNA-templated transcription is the method of t...   \n","3     The viral fiber glycoproteins mediate endocyto...   \n","4     The viral fiber glycoproteins mediate endocyto...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      E answer   id   \n","0     Transcription does not occur in the life cycle...      D    0  \\\n","1     Transcription does not occur in the life cycle...      D    0   \n","2     Transcription does not occur in the life cycle...      D    0   \n","3     The viral fiber glycoproteins are responsible ...      D    1   \n","4     The viral fiber glycoproteins are responsible ...      D    1   \n","...                                                 ...    ...  ...   \n","4205  Arthur Eddington showed that two of Einstein's...      C  499   \n","4206  Arthur Eddington showed that two of Einstein's...      C  499   \n","4207  Arthur Eddington showed that two of Einstein's...      C  499   \n","4208  Arthur Eddington showed that two of Einstein's...      C  499   \n","4209  Arthur Eddington showed that two of Einstein's...      C  499   \n","\n","                                                context   \n","0     The given phonetic transcription is how the pr...  \\\n","1     rd because it does not have a one-to-one corre...   \n","2     here it is more commonly termed \"captioning.\"\\...   \n","3     Viral glycoprotein-receptor interactions are r...   \n","4     hile the transmembrane (TM) glycoproteins anch...   \n","...                                                 ...   \n","4205  ropagate at the speed of light regardless of c...   \n","4206  he full general theory of relativity because a...   \n","4207   reported that the singularities in question w...   \n","4208  grily withdrew the manuscript, never to publis...   \n","4209  s, his assistant Leopold Infeld, who had been ...   \n","\n","                                             answer_all   \n","0     a) RNA-templated transcription is the method o...  \\\n","1     a) RNA-templated transcription is the method o...   \n","2     a) RNA-templated transcription is the method o...   \n","3     a) The viral fiber glycoproteins are involved ...   \n","4     a) The viral fiber glycoproteins are involved ...   \n","...                                                 ...   \n","4205  a) Arthur Eddington showed that two of Einstei...   \n","4206  a) Arthur Eddington showed that two of Einstei...   \n","4207  a) Arthur Eddington showed that two of Einstei...   \n","4208  a) Arthur Eddington showed that two of Einstei...   \n","4209  a) Arthur Eddington showed that two of Einstei...   \n","\n","                                     prompt_and_context  \n","0     The given phonetic transcription is how the pr...  \n","1     rd because it does not have a one-to-one corre...  \n","2     here it is more commonly termed \"captioning.\"\\...  \n","3     Viral glycoprotein-receptor interactions are r...  \n","4     hile the transmembrane (TM) glycoproteins anch...  \n","...                                                 ...  \n","4205  ropagate at the speed of light regardless of c...  \n","4206  he full general theory of relativity because a...  \n","4207   reported that the singularities in question w...  \n","4208  grily withdrew the manuscript, never to publis...  \n","4209  s, his assistant Leopold Infeld, who had been ...  \n","\n","[4210 rows x 11 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["@dataclass\n","class DataCollatorForMultipleChoice:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    \n","    def __call__(self, features):\n","        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n","        labels = [feature.pop(label_name) for feature in features]\n","        batch_size = len(features)\n","        num_choices = len(features[0]['input_ids'])\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","        \n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n","        return batch"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["DebertaV2ForMultipleChoice(\n","  (deberta): DebertaV2Model(\n","    (embeddings): DebertaV2Embeddings(\n","      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaV2Encoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(512, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n","    )\n","  )\n","  (pooler): ContextPooler(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): StableDropout()\n","  )\n","  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n","  (dropout): StableDropout()\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# model_dir = \"/kaggle/input/how-to-train-open-book-model-part-1/model_v2\"\n","# model_dir = \"/kaggle/input/llm-submissions-viktor/work_dirs/deberta-v3-data-wiki_sci-with-wiki-sentence-context-eval-kaggle-all-folds-grad-accum-128-60k/deberta-v3-large-2023-09-05-07-35-55/checkpoint-3281\"\n","model_dir =\"/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-deberta/deberta-v3-large-2023-09-17-10-00-20/checkpoint-14400\"\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n","model.eval()"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"590fd287b0e14a8281ec0a8d7a5ba22a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/4210 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["tokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt_and_context', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt_and_context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n","# tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\n","data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n","test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)"]},{"cell_type":"markdown","metadata":{},"source":["# viktor"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T07:32:49.213925Z","iopub.status.busy":"2023-10-01T07:32:49.213355Z","iopub.status.idle":"2023-10-01T07:34:45.846723Z","shell.execute_reply":"2023-10-01T07:34:45.845718Z","shell.execute_reply.started":"2023-10-01T07:32:49.213892Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"179cf4994201461a8584dc3d4c49b22a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4210 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]}],"source":["test_predictions_viktor = []\n","\n","\n","for batch in tqdm(test_dataloader):\n","    for k in batch.keys():\n","        batch[k] = batch[k].cuda()\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","    test_predictions_viktor.append(outputs.logits.cpu().detach())\n","    \n","test_predictions_viktor = torch.cat(test_predictions_viktor)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T07:34:45.851188Z","iopub.status.busy":"2023-10-01T07:34:45.850388Z","iopub.status.idle":"2023-10-01T07:34:45.86688Z","shell.execute_reply":"2023-10-01T07:34:45.865412Z","shell.execute_reply.started":"2023-10-01T07:34:45.851154Z"},"trusted":true},"outputs":[],"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","    \n","test_predictions_viktor = sigmoid(test_predictions_viktor).numpy()\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["(4210, 5)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["test_predictions_viktor.shape"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","      <th>E</th>\n","      <th>answer</th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>answer_all</th>\n","      <th>prompt_and_context</th>\n","      <th>predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What is the method of transcription in the lif...</td>\n","      <td>RNA-templated transcription is the method of t...</td>\n","      <td>Transcription occurs through a unique mechanis...</td>\n","      <td>Reverse transcription is the method of transcr...</td>\n","      <td>DNA-templated transcription is the method of t...</td>\n","      <td>Transcription does not occur in the life cycle...</td>\n","      <td>D</td>\n","      <td>0</td>\n","      <td>The given phonetic transcription is how the pr...</td>\n","      <td>a) RNA-templated transcription is the method o...</td>\n","      <td>The given phonetic transcription is how the pr...</td>\n","      <td>[0.8101109862327576, 0.3025016486644745, 0.202...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What is the method of transcription in the lif...</td>\n","      <td>RNA-templated transcription is the method of t...</td>\n","      <td>Transcription occurs through a unique mechanis...</td>\n","      <td>Reverse transcription is the method of transcr...</td>\n","      <td>DNA-templated transcription is the method of t...</td>\n","      <td>Transcription does not occur in the life cycle...</td>\n","      <td>D</td>\n","      <td>0</td>\n","      <td>rd because it does not have a one-to-one corre...</td>\n","      <td>a) RNA-templated transcription is the method o...</td>\n","      <td>rd because it does not have a one-to-one corre...</td>\n","      <td>[0.7801524996757507, 0.4729377329349518, 0.436...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What is the method of transcription in the lif...</td>\n","      <td>RNA-templated transcription is the method of t...</td>\n","      <td>Transcription occurs through a unique mechanis...</td>\n","      <td>Reverse transcription is the method of transcr...</td>\n","      <td>DNA-templated transcription is the method of t...</td>\n","      <td>Transcription does not occur in the life cycle...</td>\n","      <td>D</td>\n","      <td>0</td>\n","      <td>here it is more commonly termed \"captioning.\"\\...</td>\n","      <td>a) RNA-templated transcription is the method o...</td>\n","      <td>here it is more commonly termed \"captioning.\"\\...</td>\n","      <td>[0.7622959613800049, 0.3203194737434387, 0.383...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What is the role of the viral fiber glycoprote...</td>\n","      <td>The viral fiber glycoproteins are involved in ...</td>\n","      <td>The viral fiber glycoproteins code for 40 prot...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>The viral fiber glycoproteins mediate endocyto...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>D</td>\n","      <td>1</td>\n","      <td>Viral glycoprotein-receptor interactions are r...</td>\n","      <td>a) The viral fiber glycoproteins are involved ...</td>\n","      <td>Viral glycoprotein-receptor interactions are r...</td>\n","      <td>[0.010664276778697968, 0.06569230556488037, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What is the role of the viral fiber glycoprote...</td>\n","      <td>The viral fiber glycoproteins are involved in ...</td>\n","      <td>The viral fiber glycoproteins code for 40 prot...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>The viral fiber glycoproteins mediate endocyto...</td>\n","      <td>The viral fiber glycoproteins are responsible ...</td>\n","      <td>D</td>\n","      <td>1</td>\n","      <td>hile the transmembrane (TM) glycoproteins anch...</td>\n","      <td>a) The viral fiber glycoproteins are involved ...</td>\n","      <td>hile the transmembrane (TM) glycoproteins anch...</td>\n","      <td>[0.015026367269456387, 0.05148383602499962, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4205</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>ropagate at the speed of light regardless of c...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>ropagate at the speed of light regardless of c...</td>\n","      <td>[0.9864804148674011, 0.9629263281822205, 0.989...</td>\n","    </tr>\n","    <tr>\n","      <th>4206</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>he full general theory of relativity because a...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>he full general theory of relativity because a...</td>\n","      <td>[0.9874871969223022, 0.977417528629303, 0.9906...</td>\n","    </tr>\n","    <tr>\n","      <th>4207</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>reported that the singularities in question w...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>reported that the singularities in question w...</td>\n","      <td>[0.9929078817367554, 0.982878565788269, 0.9939...</td>\n","    </tr>\n","    <tr>\n","      <th>4208</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>grily withdrew the manuscript, never to publis...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>grily withdrew the manuscript, never to publis...</td>\n","      <td>[0.9937723278999329, 0.9794983267784119, 0.992...</td>\n","    </tr>\n","    <tr>\n","      <th>4209</th>\n","      <td>What did Arthur Eddington discover about two o...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>Arthur Eddington showed that two of Einstein's...</td>\n","      <td>C</td>\n","      <td>499</td>\n","      <td>s, his assistant Leopold Infeld, who had been ...</td>\n","      <td>a) Arthur Eddington showed that two of Einstei...</td>\n","      <td>s, his assistant Leopold Infeld, who had been ...</td>\n","      <td>[0.9898158311843872, 0.9753148555755615, 0.990...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4210 rows × 12 columns</p>\n","</div>"],"text/plain":["                                                 prompt   \n","0     What is the method of transcription in the lif...  \\\n","1     What is the method of transcription in the lif...   \n","2     What is the method of transcription in the lif...   \n","3     What is the role of the viral fiber glycoprote...   \n","4     What is the role of the viral fiber glycoprote...   \n","...                                                 ...   \n","4205  What did Arthur Eddington discover about two o...   \n","4206  What did Arthur Eddington discover about two o...   \n","4207  What did Arthur Eddington discover about two o...   \n","4208  What did Arthur Eddington discover about two o...   \n","4209  What did Arthur Eddington discover about two o...   \n","\n","                                                      A   \n","0     RNA-templated transcription is the method of t...  \\\n","1     RNA-templated transcription is the method of t...   \n","2     RNA-templated transcription is the method of t...   \n","3     The viral fiber glycoproteins are involved in ...   \n","4     The viral fiber glycoproteins are involved in ...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      B   \n","0     Transcription occurs through a unique mechanis...  \\\n","1     Transcription occurs through a unique mechanis...   \n","2     Transcription occurs through a unique mechanis...   \n","3     The viral fiber glycoproteins code for 40 prot...   \n","4     The viral fiber glycoproteins code for 40 prot...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      C   \n","0     Reverse transcription is the method of transcr...  \\\n","1     Reverse transcription is the method of transcr...   \n","2     Reverse transcription is the method of transcr...   \n","3     The viral fiber glycoproteins are responsible ...   \n","4     The viral fiber glycoproteins are responsible ...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      D   \n","0     DNA-templated transcription is the method of t...  \\\n","1     DNA-templated transcription is the method of t...   \n","2     DNA-templated transcription is the method of t...   \n","3     The viral fiber glycoproteins mediate endocyto...   \n","4     The viral fiber glycoproteins mediate endocyto...   \n","...                                                 ...   \n","4205  Arthur Eddington showed that two of Einstein's...   \n","4206  Arthur Eddington showed that two of Einstein's...   \n","4207  Arthur Eddington showed that two of Einstein's...   \n","4208  Arthur Eddington showed that two of Einstein's...   \n","4209  Arthur Eddington showed that two of Einstein's...   \n","\n","                                                      E answer   id   \n","0     Transcription does not occur in the life cycle...      D    0  \\\n","1     Transcription does not occur in the life cycle...      D    0   \n","2     Transcription does not occur in the life cycle...      D    0   \n","3     The viral fiber glycoproteins are responsible ...      D    1   \n","4     The viral fiber glycoproteins are responsible ...      D    1   \n","...                                                 ...    ...  ...   \n","4205  Arthur Eddington showed that two of Einstein's...      C  499   \n","4206  Arthur Eddington showed that two of Einstein's...      C  499   \n","4207  Arthur Eddington showed that two of Einstein's...      C  499   \n","4208  Arthur Eddington showed that two of Einstein's...      C  499   \n","4209  Arthur Eddington showed that two of Einstein's...      C  499   \n","\n","                                                context   \n","0     The given phonetic transcription is how the pr...  \\\n","1     rd because it does not have a one-to-one corre...   \n","2     here it is more commonly termed \"captioning.\"\\...   \n","3     Viral glycoprotein-receptor interactions are r...   \n","4     hile the transmembrane (TM) glycoproteins anch...   \n","...                                                 ...   \n","4205  ropagate at the speed of light regardless of c...   \n","4206  he full general theory of relativity because a...   \n","4207   reported that the singularities in question w...   \n","4208  grily withdrew the manuscript, never to publis...   \n","4209  s, his assistant Leopold Infeld, who had been ...   \n","\n","                                             answer_all   \n","0     a) RNA-templated transcription is the method o...  \\\n","1     a) RNA-templated transcription is the method o...   \n","2     a) RNA-templated transcription is the method o...   \n","3     a) The viral fiber glycoproteins are involved ...   \n","4     a) The viral fiber glycoproteins are involved ...   \n","...                                                 ...   \n","4205  a) Arthur Eddington showed that two of Einstei...   \n","4206  a) Arthur Eddington showed that two of Einstei...   \n","4207  a) Arthur Eddington showed that two of Einstei...   \n","4208  a) Arthur Eddington showed that two of Einstei...   \n","4209  a) Arthur Eddington showed that two of Einstei...   \n","\n","                                     prompt_and_context   \n","0     The given phonetic transcription is how the pr...  \\\n","1     rd because it does not have a one-to-one corre...   \n","2     here it is more commonly termed \"captioning.\"\\...   \n","3     Viral glycoprotein-receptor interactions are r...   \n","4     hile the transmembrane (TM) glycoproteins anch...   \n","...                                                 ...   \n","4205  ropagate at the speed of light regardless of c...   \n","4206  he full general theory of relativity because a...   \n","4207   reported that the singularities in question w...   \n","4208  grily withdrew the manuscript, never to publis...   \n","4209  s, his assistant Leopold Infeld, who had been ...   \n","\n","                                            predictions  \n","0     [0.8101109862327576, 0.3025016486644745, 0.202...  \n","1     [0.7801524996757507, 0.4729377329349518, 0.436...  \n","2     [0.7622959613800049, 0.3203194737434387, 0.383...  \n","3     [0.010664276778697968, 0.06569230556488037, 0....  \n","4     [0.015026367269456387, 0.05148383602499962, 0....  \n","...                                                 ...  \n","4205  [0.9864804148674011, 0.9629263281822205, 0.989...  \n","4206  [0.9874871969223022, 0.977417528629303, 0.9906...  \n","4207  [0.9929078817367554, 0.982878565788269, 0.9939...  \n","4208  [0.9937723278999329, 0.9794983267784119, 0.992...  \n","4209  [0.9898158311843872, 0.9753148555755615, 0.990...  \n","\n","[4210 rows x 12 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["test_df['predictions'] = test_predictions_viktor.tolist()\n","test_df"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["\n","\n","# save test_df as rag_2.parquet\n","test_df.to_parquet(\"wiki_sci_3_rag_2.parquet\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import pandas as pd\n","test_df = pd.read_parquet(\"wiki_sci_3_rag_2.parquet\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","ids = sorted(list(set(test_df['id'].values)))\n","\n","avgs = []\n","maxes  = []\n","answers = []\n","diffs_maxes = []\n","\n","for id in ids:\n","    df_id = test_df[test_df['id']==id].reset_index(drop=True)\n","    answer = df_id['answer'].values[0]\n","    answers.append(answer)\n","    \n","    predictions = np.vstack(df_id['predictions'].values)\n","    \n","    predictions_avg = np.mean(predictions, axis=0)\n","    predictions_max = np.max(predictions, axis=0)\n","    \n","    predictions_diff = predictions - predictions_avg\n","    predictions_diff_max = np.max(predictions_diff, axis=0)\n","    \n","    \n","    avgs.append(predictions_avg)\n","    maxes.append(predictions_max)\n","    diffs_maxes.append(predictions_diff_max)\n","    \n","    diffs_maxes_argmax = np.argmax(diffs_maxes, axis=1)\n","    \n","    "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 6 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers  \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D  \n","1    [0.010471680836582726, 0.021965994753620842, 0...       D  \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A  \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B  \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A  \n","..                                                 ...     ...  \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C  \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B  \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B  \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D  \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C  \n","\n","[500 rows x 6 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_agg = pd.DataFrame({'id': ids, 'answer': answers, 'avg': avgs, 'max': maxes, 'diff_max': diffs_maxes, 'answers': answers})\n","df_agg"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 15 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D        A  \\\n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D   \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A        C   \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B        B   \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A        A   \n","..                                                 ...     ...      ...   \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C        C   \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B        B   \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B        B   \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D        D   \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          A             B          D          D               C          B  \\\n","1          D             D          E          E               E          C   \n","2          C             C          E          E               E          B   \n","3          A             A          C          B               E          E   \n","4          A             D          B          D               E          D   \n","..       ...           ...        ...        ...             ...        ...   \n","495        C             A          A          A               D          E   \n","496        B             E          C          C               D          A   \n","497        B             D          A          A               A          D   \n","498        D             E          C          C               B          B   \n","499        C             B          A          E               E          D   \n","\n","    pred_max_3 pred_diff_max_3  \n","0            B               D  \n","1            C               C  \n","2            B               D  \n","3            C               C  \n","4            E               C  \n","..         ...             ...  \n","495          E               E  \n","496          A               A  \n","497          D               E  \n","498          B               A  \n","499          D               D  \n","\n","[500 rows x 15 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["\n","options = 'ABCDE'\n","indices = list(range(5))\n","\n","option_to_index = {option: index for option, index in zip(options, indices)}\n","index_to_option = {index: option for option, index in zip(options, indices)}\n","\n","\n","df_agg['pred_avg'] = df_agg['avg'].apply(lambda x: index_to_option[np.argmax(x)])\n","df_agg['pred_max'] = df_agg['max'].apply(lambda x: index_to_option[np.argmax(x)])\n","df_agg['pred_diff_max'] = df_agg['diff_max'].apply(lambda x: index_to_option[np.argmax(x)])\n","\n","# 2nd to argmax\n","df_agg['pred_avg_2'] = df_agg['avg'].apply(lambda x: index_to_option[np.argsort(x)[-2]])\n","df_agg['pred_max_2'] = df_agg['max'].apply(lambda x: index_to_option[np.argsort(x)[-2]])\n","df_agg['pred_diff_max_2'] = df_agg['diff_max'].apply(lambda x: index_to_option[np.argsort(x)[-2]])\n","\n","# 3nd to argmax\n","df_agg['pred_avg_3'] = df_agg['avg'].apply(lambda x: index_to_option[np.argsort(x)[-3]])\n","df_agg['pred_max_3'] = df_agg['max'].apply(lambda x: index_to_option[np.argsort(x)[-3]])\n","df_agg['pred_diff_max_3'] = df_agg['diff_max'].apply(lambda x: index_to_option[np.argsort(x)[-3]])\n","\n","df_agg  "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>avg_prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A D B</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D E C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>C E B</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B C E</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>A B D</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C A E</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B C A</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>B A D</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D C B</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C A D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 16 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D        A  \\\n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D   \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A        C   \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B        B   \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A        A   \n","..                                                 ...     ...      ...   \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C        C   \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B        B   \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B        B   \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D        D   \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          A             B          D          D               C          B  \\\n","1          D             D          E          E               E          C   \n","2          C             C          E          E               E          B   \n","3          A             A          C          B               E          E   \n","4          A             D          B          D               E          D   \n","..       ...           ...        ...        ...             ...        ...   \n","495        C             A          A          A               D          E   \n","496        B             E          C          C               D          A   \n","497        B             D          A          A               A          D   \n","498        D             E          C          C               B          B   \n","499        C             B          A          E               E          D   \n","\n","    pred_max_3 pred_diff_max_3 avg_prediction  \n","0            B               D          A D B  \n","1            C               C          D E C  \n","2            B               D          C E B  \n","3            C               C          B C E  \n","4            E               C          A B D  \n","..         ...             ...            ...  \n","495          E               E          C A E  \n","496          A               A          B C A  \n","497          D               E          B A D  \n","498          B               A          D C B  \n","499          D               D          C A D  \n","\n","[500 rows x 16 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["avg_values = np.vstack(df_agg['avg'].values)\n","predictions_overall = np.argsort(-avg_values)[:,:3]\n","predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_overall]\n","df_agg['avg_prediction'] = [\n","    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n","]\n","df_agg"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>avg_prediction</th>\n","      <th>max_prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A D B</td>\n","      <td>A D B</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D E C</td>\n","      <td>D E C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>C E B</td>\n","      <td>C E B</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B C E</td>\n","      <td>A B C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>A B D</td>\n","      <td>A D E</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C A E</td>\n","      <td>C A E</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B C A</td>\n","      <td>B C A</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>B A D</td>\n","      <td>B A D</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D C B</td>\n","      <td>D C B</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C A D</td>\n","      <td>C E D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 17 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D        A  \\\n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D   \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A        C   \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B        B   \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A        A   \n","..                                                 ...     ...      ...   \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C        C   \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B        B   \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B        B   \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D        D   \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          A             B          D          D               C          B  \\\n","1          D             D          E          E               E          C   \n","2          C             C          E          E               E          B   \n","3          A             A          C          B               E          E   \n","4          A             D          B          D               E          D   \n","..       ...           ...        ...        ...             ...        ...   \n","495        C             A          A          A               D          E   \n","496        B             E          C          C               D          A   \n","497        B             D          A          A               A          D   \n","498        D             E          C          C               B          B   \n","499        C             B          A          E               E          D   \n","\n","    pred_max_3 pred_diff_max_3 avg_prediction max_prediction  \n","0            B               D          A D B          A D B  \n","1            C               C          D E C          D E C  \n","2            B               D          C E B          C E B  \n","3            C               C          B C E          A B C  \n","4            E               C          A B D          A D E  \n","..         ...             ...            ...            ...  \n","495          E               E          C A E          C A E  \n","496          A               A          B C A          B C A  \n","497          D               E          B A D          B A D  \n","498          B               A          D C B          D C B  \n","499          D               D          C A D          C E D  \n","\n","[500 rows x 17 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["avg_values = np.vstack(df_agg['max'].values)\n","predictions_overall = np.argsort(-avg_values)[:,:3]\n","predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_overall]\n","df_agg['max_prediction'] = [\n","    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n","]\n","df_agg"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def calculate_map3(answers, predictions):\n","    map3 = 0\n","    for answer, prediction in zip(answers, predictions):\n","        if answer == prediction[0]:\n","            map3 += 1\n","        if answer == prediction[2]:\n","            map3 += 1./2\n","        if answer == prediction[4]:\n","            map3 += 1./3\n","    \n","    map3 = map3 / len(answers)\n","    return map3\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["0.8279999999999998"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["calculate_map3(df_agg['answer'].values, df_agg['avg_prediction'].values)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["0.854"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["\n","        \n","calculate_map3(df_agg['answer'].values, df_agg['max_prediction'].values)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# The final is a string like 'A B C', where the first letter is the prediction of the answer, second is the second best, third is the third best\n","# For the final prediction, use the following logic\n","# Use pred_max as the first option\n","# Now for the second option:\n","# Use pred_diff_max as the second option. If it's the same as pred_max, use pred_avg\n","# If the pred_avg is the same as pred_max, use pred_avg_2\n","# If pred_avg_2 is the same as pred_max, use pred_max_2\n","# For the third option, use similar logic\n","df['final_prediction'] = df_agg['pred_max'] + ' ' + df_agg['pred_diff_max'] + ' '"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["(0.732, 0.77, 0.078)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["np.average(df_agg['pred_avg'] == df_agg['answer']), np.average(df_agg['pred_max'] == df_agg['answer']), np.average(df_agg['pred_diff_max'] == df_agg['answer'])"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["(0.156, 0.14, 0.062)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["np.average(df_agg['pred_avg_2'] == df_agg['answer']), np.average(df_agg['pred_max_2'] == df_agg['answer']), np.average(df_agg['pred_diff_max_2'] == df_agg['answer'])"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["(0.054, 0.042, 0.102)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["np.average(df_agg['pred_avg_3'] == df_agg['answer']), np.average(df_agg['pred_max_3'] == df_agg['answer']), np.average(df_agg['pred_diff_max_3'] == df_agg['answer'])"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>pred_max_2</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>avg_prediction</th>\n","      <th>max_prediction</th>\n","      <th>diff_max_max_el</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A D B</td>\n","      <td>A D B</td>\n","      <td>0.107685</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D E C</td>\n","      <td>D E C</td>\n","      <td>0.210966</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>C E B</td>\n","      <td>C E B</td>\n","      <td>0.103654</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B C E</td>\n","      <td>A B C</td>\n","      <td>0.263870</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>A B D</td>\n","      <td>A D E</td>\n","      <td>0.499348</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C A E</td>\n","      <td>C A E</td>\n","      <td>0.207745</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B C A</td>\n","      <td>B C A</td>\n","      <td>0.146366</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>B A D</td>\n","      <td>B A D</td>\n","      <td>0.009044</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D C B</td>\n","      <td>D C B</td>\n","      <td>0.195286</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C A D</td>\n","      <td>C E D</td>\n","      <td>0.040849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 18 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D        A  \\\n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D   \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A        C   \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B        B   \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A        A   \n","..                                                 ...     ...      ...   \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C        C   \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B        B   \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B        B   \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D        D   \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2 pred_max_2 pred_diff_max_2 pred_avg_3   \n","0          A             B          D          D               C          B  \\\n","1          D             D          E          E               E          C   \n","2          C             C          E          E               E          B   \n","3          A             A          C          B               E          E   \n","4          A             D          B          D               E          D   \n","..       ...           ...        ...        ...             ...        ...   \n","495        C             A          A          A               D          E   \n","496        B             E          C          C               D          A   \n","497        B             D          A          A               A          D   \n","498        D             E          C          C               B          B   \n","499        C             B          A          E               E          D   \n","\n","    pred_max_3 pred_diff_max_3 avg_prediction max_prediction  diff_max_max_el  \n","0            B               D          A D B          A D B         0.107685  \n","1            C               C          D E C          D E C         0.210966  \n","2            B               D          C E B          C E B         0.103654  \n","3            C               C          B C E          A B C         0.263870  \n","4            E               C          A B D          A D E         0.499348  \n","..         ...             ...            ...            ...              ...  \n","495          E               E          C A E          C A E         0.207745  \n","496          A               A          B C A          B C A         0.146366  \n","497          D               E          B A D          B A D         0.009044  \n","498          B               A          D C B          D C B         0.195286  \n","499          D               D          C A D          C E D         0.040849  \n","\n","[500 rows x 18 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["df_agg['diff_max_max_el'] = df_agg['diff_max'].apply(lambda x: np.max(x))\n","df_agg"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["df_agg['pred_diff_max_max_avg'] = df_agg['avg'].apply(lambda x: np.max(x))\n","df_agg['pred_diff_max_max_max'] = df_agg['max'].apply(lambda x: np.max(x))\n","df_agg['pred_diff_max_diff_max_max'] = df_agg['diff_max'].apply(lambda x: np.max(x))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>...</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>avg_prediction</th>\n","      <th>max_prediction</th>\n","      <th>diff_max_max_el</th>\n","      <th>pred_diff_max_max_avg</th>\n","      <th>pred_diff_max_max_max</th>\n","      <th>pred_diff_max_diff_max_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A D B</td>\n","      <td>A D B</td>\n","      <td>0.107685</td>\n","      <td>0.784186</td>\n","      <td>0.810111</td>\n","      <td>0.107685</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D E C</td>\n","      <td>D E C</td>\n","      <td>0.210966</td>\n","      <td>0.330769</td>\n","      <td>0.541735</td>\n","      <td>0.210966</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>C E B</td>\n","      <td>C E B</td>\n","      <td>0.103654</td>\n","      <td>0.119930</td>\n","      <td>0.223584</td>\n","      <td>0.103654</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B C E</td>\n","      <td>A B C</td>\n","      <td>0.263870</td>\n","      <td>0.440113</td>\n","      <td>0.539816</td>\n","      <td>0.263870</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>A B D</td>\n","      <td>A D E</td>\n","      <td>0.499348</td>\n","      <td>0.764125</td>\n","      <td>0.977437</td>\n","      <td>0.499348</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C A E</td>\n","      <td>C A E</td>\n","      <td>0.207745</td>\n","      <td>0.988161</td>\n","      <td>0.995408</td>\n","      <td>0.207745</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B C A</td>\n","      <td>B C A</td>\n","      <td>0.146366</td>\n","      <td>0.988875</td>\n","      <td>0.998379</td>\n","      <td>0.146366</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>B A D</td>\n","      <td>B A D</td>\n","      <td>0.009044</td>\n","      <td>0.993645</td>\n","      <td>0.999492</td>\n","      <td>0.009044</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>D C B</td>\n","      <td>D C B</td>\n","      <td>0.195286</td>\n","      <td>0.954106</td>\n","      <td>0.976501</td>\n","      <td>0.195286</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C A D</td>\n","      <td>C E D</td>\n","      <td>0.040849</td>\n","      <td>0.989412</td>\n","      <td>0.999031</td>\n","      <td>0.040849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 21 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D        A  \\\n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D   \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A        C   \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B        B   \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A        A   \n","..                                                 ...     ...      ...   \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C        C   \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B        B   \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B        B   \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D        D   \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2  ... pred_diff_max_2 pred_avg_3   \n","0          A             B          D  ...               C          B  \\\n","1          D             D          E  ...               E          C   \n","2          C             C          E  ...               E          B   \n","3          A             A          C  ...               E          E   \n","4          A             D          B  ...               E          D   \n","..       ...           ...        ...  ...             ...        ...   \n","495        C             A          A  ...               D          E   \n","496        B             E          C  ...               D          A   \n","497        B             D          A  ...               A          D   \n","498        D             E          C  ...               B          B   \n","499        C             B          A  ...               E          D   \n","\n","    pred_max_3 pred_diff_max_3 avg_prediction max_prediction diff_max_max_el   \n","0            B               D          A D B          A D B        0.107685  \\\n","1            C               C          D E C          D E C        0.210966   \n","2            B               D          C E B          C E B        0.103654   \n","3            C               C          B C E          A B C        0.263870   \n","4            E               C          A B D          A D E        0.499348   \n","..         ...             ...            ...            ...             ...   \n","495          E               E          C A E          C A E        0.207745   \n","496          A               A          B C A          B C A        0.146366   \n","497          D               E          B A D          B A D        0.009044   \n","498          B               A          D C B          D C B        0.195286   \n","499          D               D          C A D          C E D        0.040849   \n","\n","     pred_diff_max_max_avg  pred_diff_max_max_max  pred_diff_max_diff_max_max  \n","0                 0.784186               0.810111                    0.107685  \n","1                 0.330769               0.541735                    0.210966  \n","2                 0.119930               0.223584                    0.103654  \n","3                 0.440113               0.539816                    0.263870  \n","4                 0.764125               0.977437                    0.499348  \n","..                     ...                    ...                         ...  \n","495               0.988161               0.995408                    0.207745  \n","496               0.988875               0.998379                    0.146366  \n","497               0.993645               0.999492                    0.009044  \n","498               0.954106               0.976501                    0.195286  \n","499               0.989412               0.999031                    0.040849  \n","\n","[500 rows x 21 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df_agg"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>...</th>\n","      <th>pred_diff_max_2</th>\n","      <th>pred_avg_3</th>\n","      <th>pred_max_3</th>\n","      <th>pred_diff_max_3</th>\n","      <th>avg_prediction</th>\n","      <th>max_prediction</th>\n","      <th>diff_max_max_el</th>\n","      <th>pred_diff_max_max_avg</th>\n","      <th>pred_diff_max_max_max</th>\n","      <th>pred_diff_max_diff_max_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D E C</td>\n","      <td>D E C</td>\n","      <td>0.210966</td>\n","      <td>0.330769</td>\n","      <td>0.541735</td>\n","      <td>0.210966</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>A</td>\n","      <td>[0.9057069271802902, 0.9309955537319183, 0.960...</td>\n","      <td>[0.9802614450454712, 0.992434024810791, 0.9924...</td>\n","      <td>[0.07455451786518097, 0.06143847107887268, 0.0...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D E C</td>\n","      <td>D B C</td>\n","      <td>0.074555</td>\n","      <td>0.992374</td>\n","      <td>0.998431</td>\n","      <td>0.074555</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>A</td>\n","      <td>[0.5082516670227051, 0.4525325496991475, 0.197...</td>\n","      <td>[0.6319497227668762, 0.5474225878715515, 0.291...</td>\n","      <td>[0.12369805574417114, 0.09489003817240399, 0.0...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D A B</td>\n","      <td>D A B</td>\n","      <td>0.123698</td>\n","      <td>0.710191</td>\n","      <td>0.816382</td>\n","      <td>0.123698</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>D</td>\n","      <td>[0.7073423564434052, 0.7902349313100179, 0.725...</td>\n","      <td>[0.8780617117881775, 0.9872245788574219, 0.980...</td>\n","      <td>[0.17071935534477234, 0.196989647547404, 0.254...</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B C A</td>\n","      <td>D B C</td>\n","      <td>0.432833</td>\n","      <td>0.790235</td>\n","      <td>0.991224</td>\n","      <td>0.432833</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>A</td>\n","      <td>[0.5012546107172966, 0.13467734307050705, 0.50...</td>\n","      <td>[0.979089081287384, 0.204781174659729, 0.83773...</td>\n","      <td>[0.47783447057008743, 0.07010383158922195, 0.3...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>D E C</td>\n","      <td>A D C</td>\n","      <td>0.477834</td>\n","      <td>0.791697</td>\n","      <td>0.979089</td>\n","      <td>0.477834</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>32</td>\n","      <td>B</td>\n","      <td>[0.8793227672576904, 0.9168046772480011, 0.988...</td>\n","      <td>[0.916037917137146, 0.9958233833312988, 0.9960...</td>\n","      <td>[0.036715149879455566, 0.07901870608329775, 0....</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C E B</td>\n","      <td>C B E</td>\n","      <td>0.079019</td>\n","      <td>0.988247</td>\n","      <td>0.996015</td>\n","      <td>0.079019</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>55</td>\n","      <td>C</td>\n","      <td>[0.366414475440979, 0.9754886031150818, 0.7576...</td>\n","      <td>[0.5051088333129883, 0.9890007972717285, 0.944...</td>\n","      <td>[0.1386943578720093, 0.013512194156646729, 0.1...</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>B C D</td>\n","      <td>B C D</td>\n","      <td>0.187194</td>\n","      <td>0.975489</td>\n","      <td>0.989001</td>\n","      <td>0.187194</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>57</td>\n","      <td>D</td>\n","      <td>[0.35415890999138355, 0.3944940883666277, 0.76...</td>\n","      <td>[0.48465296626091003, 0.5320876240730286, 0.87...</td>\n","      <td>[0.13049405626952648, 0.13759353570640087, 0.1...</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C D B</td>\n","      <td>D C B</td>\n","      <td>0.372023</td>\n","      <td>0.767295</td>\n","      <td>0.981467</td>\n","      <td>0.372023</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>74</td>\n","      <td>A</td>\n","      <td>[0.4125587618909776, 0.14463143795728683, 0.06...</td>\n","      <td>[0.7992594838142395, 0.21910026669502258, 0.09...</td>\n","      <td>[0.3867007219232619, 0.07446882873773575, 0.03...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A E B</td>\n","      <td>A E B</td>\n","      <td>0.386701</td>\n","      <td>0.412559</td>\n","      <td>0.799259</td>\n","      <td>0.386701</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>75</td>\n","      <td>A</td>\n","      <td>[0.4942706137895584, 0.6703789561986924, 0.750...</td>\n","      <td>[0.8926798701286316, 0.8924582004547119, 0.850...</td>\n","      <td>[0.3984092563390732, 0.22207924425601955, 0.09...</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>E D C</td>\n","      <td>E D A</td>\n","      <td>0.398409</td>\n","      <td>0.971753</td>\n","      <td>0.994117</td>\n","      <td>0.398409</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>107</td>\n","      <td>D</td>\n","      <td>[0.0690241093850798, 0.06554241975148518, 0.87...</td>\n","      <td>[0.16269086301326752, 0.13523858785629272, 0.9...</td>\n","      <td>[0.09366675362818772, 0.06969616810480754, 0.0...</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>C D E</td>\n","      <td>C D E</td>\n","      <td>0.268400</td>\n","      <td>0.876247</td>\n","      <td>0.930956</td>\n","      <td>0.268400</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>110</td>\n","      <td>D</td>\n","      <td>[0.5816498945156733, 0.25063809131582576, 0.75...</td>\n","      <td>[0.8776097893714905, 0.5484265089035034, 0.959...</td>\n","      <td>[0.2959598948558172, 0.29778841758767766, 0.20...</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C D A</td>\n","      <td>C D A</td>\n","      <td>0.323211</td>\n","      <td>0.752731</td>\n","      <td>0.959348</td>\n","      <td>0.323211</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>111</td>\n","      <td>C</td>\n","      <td>[0.2501998259262605, 0.9846792004325173, 0.277...</td>\n","      <td>[0.3863047659397125, 0.991550087928772, 0.8220...</td>\n","      <td>[0.13610494001345202, 0.006870887496254641, 0....</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>B D C</td>\n","      <td>B D C</td>\n","      <td>0.544333</td>\n","      <td>0.984679</td>\n","      <td>0.991550</td>\n","      <td>0.544333</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>114</td>\n","      <td>B</td>\n","      <td>[0.07947436968485515, 0.8357987999916077, 0.96...</td>\n","      <td>[0.13163428008556366, 0.9203312993049622, 0.98...</td>\n","      <td>[0.05215991040070851, 0.08453249931335449, 0.0...</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>C E B</td>\n","      <td>C E B</td>\n","      <td>0.084532</td>\n","      <td>0.966799</td>\n","      <td>0.988956</td>\n","      <td>0.084532</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>138</td>\n","      <td>C</td>\n","      <td>[0.7345188591215346, 0.13277622063954672, 0.25...</td>\n","      <td>[0.8995800018310547, 0.2088518887758255, 0.612...</td>\n","      <td>[0.1650611427095201, 0.07607566813627878, 0.35...</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>D A E</td>\n","      <td>D A E</td>\n","      <td>0.353729</td>\n","      <td>0.788556</td>\n","      <td>0.955085</td>\n","      <td>0.353729</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>140</td>\n","      <td>A</td>\n","      <td>[0.6442915946245193, 0.1387767056003213, 0.731...</td>\n","      <td>[0.940511167049408, 0.2676418423652649, 0.8083...</td>\n","      <td>[0.2962195724248886, 0.1288651367649436, 0.076...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D C E</td>\n","      <td>A D E</td>\n","      <td>0.296220</td>\n","      <td>0.742778</td>\n","      <td>0.940511</td>\n","      <td>0.296220</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>152</td>\n","      <td>C</td>\n","      <td>[0.5295147912369834, 0.24411805843313536, 0.76...</td>\n","      <td>[0.6620744466781616, 0.3441373407840729, 0.970...</td>\n","      <td>[0.1325596554411782, 0.10001928235093752, 0.20...</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E C A</td>\n","      <td>C E A</td>\n","      <td>0.204735</td>\n","      <td>0.921933</td>\n","      <td>0.970016</td>\n","      <td>0.204735</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>158</td>\n","      <td>C</td>\n","      <td>[0.2860307142138481, 0.9487409234046936, 0.509...</td>\n","      <td>[0.3520072102546692, 0.9703423976898193, 0.616...</td>\n","      <td>[0.06597649604082106, 0.02160147428512571, 0.1...</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>B C D</td>\n","      <td>B C D</td>\n","      <td>0.107651</td>\n","      <td>0.948741</td>\n","      <td>0.970342</td>\n","      <td>0.107651</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>163</td>\n","      <td>B</td>\n","      <td>[0.9626410752534866, 0.7990340441465378, 0.897...</td>\n","      <td>[0.9796985387802124, 0.9957964420318604, 0.992...</td>\n","      <td>[0.01705746352672577, 0.19676239788532257, 0.0...</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>A C D</td>\n","      <td>B C D</td>\n","      <td>0.196762</td>\n","      <td>0.962641</td>\n","      <td>0.995796</td>\n","      <td>0.196762</td>\n","    </tr>\n","    <tr>\n","      <th>189</th>\n","      <td>189</td>\n","      <td>B</td>\n","      <td>[0.8953603370623155, 0.5452519072727724, 0.646...</td>\n","      <td>[0.9824381470680237, 0.8277055621147156, 0.875...</td>\n","      <td>[0.08707781000570813, 0.2824536548419432, 0.22...</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A C E</td>\n","      <td>A C B</td>\n","      <td>0.282454</td>\n","      <td>0.895360</td>\n","      <td>0.982438</td>\n","      <td>0.282454</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>193</td>\n","      <td>A</td>\n","      <td>[0.38222915513647926, 0.6702627109156715, 0.76...</td>\n","      <td>[0.9659400582313538, 0.9313564896583557, 0.865...</td>\n","      <td>[0.5837109030948745, 0.26109377874268425, 0.10...</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E C B</td>\n","      <td>A B E</td>\n","      <td>0.583711</td>\n","      <td>0.891948</td>\n","      <td>0.965940</td>\n","      <td>0.583711</td>\n","    </tr>\n","    <tr>\n","      <th>215</th>\n","      <td>215</td>\n","      <td>E</td>\n","      <td>[0.9938973486423492, 0.9902341465155283, 0.976...</td>\n","      <td>[0.996553897857666, 0.995484471321106, 0.99515...</td>\n","      <td>[0.0026565492153167725, 0.005250324805577633, ...</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>A B C</td>\n","      <td>E A B</td>\n","      <td>0.036209</td>\n","      <td>0.993897</td>\n","      <td>0.997928</td>\n","      <td>0.036209</td>\n","    </tr>\n","    <tr>\n","      <th>219</th>\n","      <td>219</td>\n","      <td>D</td>\n","      <td>[0.9788484672705332, 0.8888132671515147, 0.857...</td>\n","      <td>[0.9818950295448303, 0.9213659763336182, 0.880...</td>\n","      <td>[0.0030465622742971155, 0.03255270918210351, 0...</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>A E D</td>\n","      <td>A D E</td>\n","      <td>0.040106</td>\n","      <td>0.978848</td>\n","      <td>0.981895</td>\n","      <td>0.040106</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>233</td>\n","      <td>D</td>\n","      <td>[0.08037860617041588, 0.006497192103415728, 0....</td>\n","      <td>[0.12479611486196518, 0.008290672674775124, 0....</td>\n","      <td>[0.0444175086915493, 0.0017934805713593956, 0....</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D A E</td>\n","      <td>D A E</td>\n","      <td>0.141686</td>\n","      <td>0.496233</td>\n","      <td>0.637919</td>\n","      <td>0.141686</td>\n","    </tr>\n","    <tr>\n","      <th>242</th>\n","      <td>242</td>\n","      <td>C</td>\n","      <td>[0.8937579616904259, 0.2354785455390811, 0.737...</td>\n","      <td>[0.9508556127548218, 0.3438957631587982, 0.991...</td>\n","      <td>[0.057097651064395905, 0.10841721761971712, 0....</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>D A C</td>\n","      <td>C D A</td>\n","      <td>0.253743</td>\n","      <td>0.909258</td>\n","      <td>0.991563</td>\n","      <td>0.253743</td>\n","    </tr>\n","    <tr>\n","      <th>255</th>\n","      <td>255</td>\n","      <td>D</td>\n","      <td>[0.8356311236109052, 0.7695851581437247, 0.724...</td>\n","      <td>[0.8842151761054993, 0.8801301121711731, 0.872...</td>\n","      <td>[0.04858405249459408, 0.11054495402744835, 0.1...</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>A D B</td>\n","      <td>D A B</td>\n","      <td>0.153832</td>\n","      <td>0.835631</td>\n","      <td>0.984851</td>\n","      <td>0.153832</td>\n","    </tr>\n","    <tr>\n","      <th>256</th>\n","      <td>256</td>\n","      <td>B</td>\n","      <td>[0.8600116431713104, 0.8950957000255585, 0.995...</td>\n","      <td>[0.9248510599136353, 0.9920622110366821, 0.998...</td>\n","      <td>[0.06483941674232485, 0.09696651101112364, 0.0...</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>C E D</td>\n","      <td>C B E</td>\n","      <td>0.096967</td>\n","      <td>0.995589</td>\n","      <td>0.998140</td>\n","      <td>0.096967</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>287</td>\n","      <td>C</td>\n","      <td>[0.9610239352498736, 0.633027468408857, 0.7332...</td>\n","      <td>[0.996322751045227, 0.7809031009674072, 0.9481...</td>\n","      <td>[0.03529881579535343, 0.14787563255855019, 0.2...</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>A E D</td>\n","      <td>A D E</td>\n","      <td>0.214889</td>\n","      <td>0.961024</td>\n","      <td>0.996323</td>\n","      <td>0.214889</td>\n","    </tr>\n","    <tr>\n","      <th>308</th>\n","      <td>308</td>\n","      <td>C</td>\n","      <td>[0.7583817499024528, 0.7527005842753819, 0.644...</td>\n","      <td>[0.9008192420005798, 0.8914328813552856, 0.993...</td>\n","      <td>[0.14243749209812706, 0.13873229707990375, 0.3...</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A B C</td>\n","      <td>C A B</td>\n","      <td>0.348889</td>\n","      <td>0.758382</td>\n","      <td>0.993426</td>\n","      <td>0.348889</td>\n","    </tr>\n","    <tr>\n","      <th>321</th>\n","      <td>321</td>\n","      <td>D</td>\n","      <td>[0.09932226222008467, 0.8286319077014923, 0.84...</td>\n","      <td>[0.12347231060266495, 0.9141005277633667, 0.87...</td>\n","      <td>[0.02415004838258028, 0.08546862006187439, 0.0...</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>E D C</td>\n","      <td>D E B</td>\n","      <td>0.125746</td>\n","      <td>0.883406</td>\n","      <td>0.996453</td>\n","      <td>0.125746</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>325</td>\n","      <td>E</td>\n","      <td>[0.01316079537251166, 0.01426170686525958, 0.0...</td>\n","      <td>[0.016024725511670113, 0.016621602699160576, 0...</td>\n","      <td>[0.0028639301391584528, 0.002359895833900996, ...</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>B</td>\n","      <td>...</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E B D</td>\n","      <td>E C D</td>\n","      <td>0.012121</td>\n","      <td>0.983785</td>\n","      <td>0.995905</td>\n","      <td>0.012121</td>\n","    </tr>\n","    <tr>\n","      <th>338</th>\n","      <td>338</td>\n","      <td>E</td>\n","      <td>[0.012193658544371525, 0.019665469881147146, 0...</td>\n","      <td>[0.025632521137595177, 0.03978617116808891, 0....</td>\n","      <td>[0.013438862593223652, 0.020120701286941767, 0...</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D E B</td>\n","      <td>D E B</td>\n","      <td>0.044106</td>\n","      <td>0.920802</td>\n","      <td>0.961103</td>\n","      <td>0.044106</td>\n","    </tr>\n","    <tr>\n","      <th>341</th>\n","      <td>341</td>\n","      <td>C</td>\n","      <td>[0.945224485614083, 0.9494538578120145, 0.9362...</td>\n","      <td>[0.9730257987976074, 0.9743620157241821, 0.998...</td>\n","      <td>[0.027801313183524412, 0.024908157912167606, 0...</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E D B</td>\n","      <td>C E B</td>\n","      <td>0.062566</td>\n","      <td>0.956870</td>\n","      <td>0.998804</td>\n","      <td>0.062566</td>\n","    </tr>\n","    <tr>\n","      <th>354</th>\n","      <td>354</td>\n","      <td>B</td>\n","      <td>[0.8588932037353516, 0.8469779253005981, 0.038...</td>\n","      <td>[0.9548124670982361, 0.9982913136482239, 0.076...</td>\n","      <td>[0.09591926336288448, 0.15131338834762575, 0.0...</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>A B D</td>\n","      <td>B A E</td>\n","      <td>0.151313</td>\n","      <td>0.858893</td>\n","      <td>0.998291</td>\n","      <td>0.151313</td>\n","    </tr>\n","    <tr>\n","      <th>367</th>\n","      <td>367</td>\n","      <td>E</td>\n","      <td>[0.025257693349637768, 0.009595852810889482, 0...</td>\n","      <td>[0.07041119784116745, 0.030593598261475563, 0....</td>\n","      <td>[0.04515350449152968, 0.02099774545058608, 0.0...</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E A C</td>\n","      <td>E A C</td>\n","      <td>0.085120</td>\n","      <td>0.910624</td>\n","      <td>0.995744</td>\n","      <td>0.085120</td>\n","    </tr>\n","    <tr>\n","      <th>377</th>\n","      <td>377</td>\n","      <td>B</td>\n","      <td>[0.1068253672371308, 0.6886932005484899, 0.167...</td>\n","      <td>[0.30152228474617004, 0.9941599369049072, 0.36...</td>\n","      <td>[0.19469691750903922, 0.3054667363564173, 0.19...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>B E D</td>\n","      <td>B E D</td>\n","      <td>0.305467</td>\n","      <td>0.688693</td>\n","      <td>0.994160</td>\n","      <td>0.305467</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>402</td>\n","      <td>C</td>\n","      <td>[0.20679292641580105, 0.15079041197896004, 0.6...</td>\n","      <td>[0.24768920242786407, 0.20859570801258087, 0.7...</td>\n","      <td>[0.040896276012063026, 0.057805296033620834, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>C A B</td>\n","      <td>C A B</td>\n","      <td>0.076441</td>\n","      <td>0.628813</td>\n","      <td>0.705254</td>\n","      <td>0.076441</td>\n","    </tr>\n","    <tr>\n","      <th>412</th>\n","      <td>412</td>\n","      <td>A</td>\n","      <td>[0.7146107128688267, 0.3955273170556341, 0.479...</td>\n","      <td>[0.993107259273529, 0.6136086583137512, 0.6440...</td>\n","      <td>[0.27849654640470234, 0.21808134125811712, 0.1...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>A D E</td>\n","      <td>A E D</td>\n","      <td>0.278497</td>\n","      <td>0.714611</td>\n","      <td>0.993107</td>\n","      <td>0.278497</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>422</td>\n","      <td>B</td>\n","      <td>[0.290720921009779, 0.835979238152504, 0.40544...</td>\n","      <td>[0.33900585770606995, 0.9865977764129639, 0.47...</td>\n","      <td>[0.04828493669629097, 0.1506185382604599, 0.07...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B E C</td>\n","      <td>B E C</td>\n","      <td>0.150619</td>\n","      <td>0.835979</td>\n","      <td>0.986598</td>\n","      <td>0.150619</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>39 rows × 21 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...  \\\n","7      7      A  [0.9057069271802902, 0.9309955537319183, 0.960...   \n","14    14      A  [0.5082516670227051, 0.4525325496991475, 0.197...   \n","22    22      D  [0.7073423564434052, 0.7902349313100179, 0.725...   \n","23    23      A  [0.5012546107172966, 0.13467734307050705, 0.50...   \n","32    32      B  [0.8793227672576904, 0.9168046772480011, 0.988...   \n","55    55      C  [0.366414475440979, 0.9754886031150818, 0.7576...   \n","57    57      D  [0.35415890999138355, 0.3944940883666277, 0.76...   \n","74    74      A  [0.4125587618909776, 0.14463143795728683, 0.06...   \n","75    75      A  [0.4942706137895584, 0.6703789561986924, 0.750...   \n","107  107      D  [0.0690241093850798, 0.06554241975148518, 0.87...   \n","110  110      D  [0.5816498945156733, 0.25063809131582576, 0.75...   \n","111  111      C  [0.2501998259262605, 0.9846792004325173, 0.277...   \n","114  114      B  [0.07947436968485515, 0.8357987999916077, 0.96...   \n","138  138      C  [0.7345188591215346, 0.13277622063954672, 0.25...   \n","140  140      A  [0.6442915946245193, 0.1387767056003213, 0.731...   \n","152  152      C  [0.5295147912369834, 0.24411805843313536, 0.76...   \n","158  158      C  [0.2860307142138481, 0.9487409234046936, 0.509...   \n","163  163      B  [0.9626410752534866, 0.7990340441465378, 0.897...   \n","189  189      B  [0.8953603370623155, 0.5452519072727724, 0.646...   \n","193  193      A  [0.38222915513647926, 0.6702627109156715, 0.76...   \n","215  215      E  [0.9938973486423492, 0.9902341465155283, 0.976...   \n","219  219      D  [0.9788484672705332, 0.8888132671515147, 0.857...   \n","233  233      D  [0.08037860617041588, 0.006497192103415728, 0....   \n","242  242      C  [0.8937579616904259, 0.2354785455390811, 0.737...   \n","255  255      D  [0.8356311236109052, 0.7695851581437247, 0.724...   \n","256  256      B  [0.8600116431713104, 0.8950957000255585, 0.995...   \n","287  287      C  [0.9610239352498736, 0.633027468408857, 0.7332...   \n","308  308      C  [0.7583817499024528, 0.7527005842753819, 0.644...   \n","321  321      D  [0.09932226222008467, 0.8286319077014923, 0.84...   \n","325  325      E  [0.01316079537251166, 0.01426170686525958, 0.0...   \n","338  338      E  [0.012193658544371525, 0.019665469881147146, 0...   \n","341  341      C  [0.945224485614083, 0.9494538578120145, 0.9362...   \n","354  354      B  [0.8588932037353516, 0.8469779253005981, 0.038...   \n","367  367      E  [0.025257693349637768, 0.009595852810889482, 0...   \n","377  377      B  [0.1068253672371308, 0.6886932005484899, 0.167...   \n","402  402      C  [0.20679292641580105, 0.15079041197896004, 0.6...   \n","412  412      A  [0.7146107128688267, 0.3955273170556341, 0.479...   \n","422  422      B  [0.290720921009779, 0.835979238152504, 0.40544...   \n","\n","                                                   max   \n","1    [0.023958779871463776, 0.07085713744163513, 0....  \\\n","7    [0.9802614450454712, 0.992434024810791, 0.9924...   \n","14   [0.6319497227668762, 0.5474225878715515, 0.291...   \n","22   [0.8780617117881775, 0.9872245788574219, 0.980...   \n","23   [0.979089081287384, 0.204781174659729, 0.83773...   \n","32   [0.916037917137146, 0.9958233833312988, 0.9960...   \n","55   [0.5051088333129883, 0.9890007972717285, 0.944...   \n","57   [0.48465296626091003, 0.5320876240730286, 0.87...   \n","74   [0.7992594838142395, 0.21910026669502258, 0.09...   \n","75   [0.8926798701286316, 0.8924582004547119, 0.850...   \n","107  [0.16269086301326752, 0.13523858785629272, 0.9...   \n","110  [0.8776097893714905, 0.5484265089035034, 0.959...   \n","111  [0.3863047659397125, 0.991550087928772, 0.8220...   \n","114  [0.13163428008556366, 0.9203312993049622, 0.98...   \n","138  [0.8995800018310547, 0.2088518887758255, 0.612...   \n","140  [0.940511167049408, 0.2676418423652649, 0.8083...   \n","152  [0.6620744466781616, 0.3441373407840729, 0.970...   \n","158  [0.3520072102546692, 0.9703423976898193, 0.616...   \n","163  [0.9796985387802124, 0.9957964420318604, 0.992...   \n","189  [0.9824381470680237, 0.8277055621147156, 0.875...   \n","193  [0.9659400582313538, 0.9313564896583557, 0.865...   \n","215  [0.996553897857666, 0.995484471321106, 0.99515...   \n","219  [0.9818950295448303, 0.9213659763336182, 0.880...   \n","233  [0.12479611486196518, 0.008290672674775124, 0....   \n","242  [0.9508556127548218, 0.3438957631587982, 0.991...   \n","255  [0.8842151761054993, 0.8801301121711731, 0.872...   \n","256  [0.9248510599136353, 0.9920622110366821, 0.998...   \n","287  [0.996322751045227, 0.7809031009674072, 0.9481...   \n","308  [0.9008192420005798, 0.8914328813552856, 0.993...   \n","321  [0.12347231060266495, 0.9141005277633667, 0.87...   \n","325  [0.016024725511670113, 0.016621602699160576, 0...   \n","338  [0.025632521137595177, 0.03978617116808891, 0....   \n","341  [0.9730257987976074, 0.9743620157241821, 0.998...   \n","354  [0.9548124670982361, 0.9982913136482239, 0.076...   \n","367  [0.07041119784116745, 0.030593598261475563, 0....   \n","377  [0.30152228474617004, 0.9941599369049072, 0.36...   \n","402  [0.24768920242786407, 0.20859570801258087, 0.7...   \n","412  [0.993107259273529, 0.6136086583137512, 0.6440...   \n","422  [0.33900585770606995, 0.9865977764129639, 0.47...   \n","\n","                                              diff_max answers pred_avg   \n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D  \\\n","7    [0.07455451786518097, 0.06143847107887268, 0.0...       A        D   \n","14   [0.12369805574417114, 0.09489003817240399, 0.0...       A        D   \n","22   [0.17071935534477234, 0.196989647547404, 0.254...       D        B   \n","23   [0.47783447057008743, 0.07010383158922195, 0.3...       A        D   \n","32   [0.036715149879455566, 0.07901870608329775, 0....       B        C   \n","55   [0.1386943578720093, 0.013512194156646729, 0.1...       C        B   \n","57   [0.13049405626952648, 0.13759353570640087, 0.1...       D        C   \n","74   [0.3867007219232619, 0.07446882873773575, 0.03...       A        A   \n","75   [0.3984092563390732, 0.22207924425601955, 0.09...       A        E   \n","107  [0.09366675362818772, 0.06969616810480754, 0.0...       D        C   \n","110  [0.2959598948558172, 0.29778841758767766, 0.20...       D        C   \n","111  [0.13610494001345202, 0.006870887496254641, 0....       C        B   \n","114  [0.05215991040070851, 0.08453249931335449, 0.0...       B        C   \n","138  [0.1650611427095201, 0.07607566813627878, 0.35...       C        D   \n","140  [0.2962195724248886, 0.1288651367649436, 0.076...       A        D   \n","152  [0.1325596554411782, 0.10001928235093752, 0.20...       C        E   \n","158  [0.06597649604082106, 0.02160147428512571, 0.1...       C        B   \n","163  [0.01705746352672577, 0.19676239788532257, 0.0...       B        A   \n","189  [0.08707781000570813, 0.2824536548419432, 0.22...       B        A   \n","193  [0.5837109030948745, 0.26109377874268425, 0.10...       A        E   \n","215  [0.0026565492153167725, 0.005250324805577633, ...       E        A   \n","219  [0.0030465622742971155, 0.03255270918210351, 0...       D        A   \n","233  [0.0444175086915493, 0.0017934805713593956, 0....       D        D   \n","242  [0.057097651064395905, 0.10841721761971712, 0....       C        D   \n","255  [0.04858405249459408, 0.11054495402744835, 0.1...       D        A   \n","256  [0.06483941674232485, 0.09696651101112364, 0.0...       B        C   \n","287  [0.03529881579535343, 0.14787563255855019, 0.2...       C        A   \n","308  [0.14243749209812706, 0.13873229707990375, 0.3...       C        A   \n","321  [0.02415004838258028, 0.08546862006187439, 0.0...       D        E   \n","325  [0.0028639301391584528, 0.002359895833900996, ...       E        E   \n","338  [0.013438862593223652, 0.020120701286941767, 0...       E        D   \n","341  [0.027801313183524412, 0.024908157912167606, 0...       C        E   \n","354  [0.09591926336288448, 0.15131338834762575, 0.0...       B        A   \n","367  [0.04515350449152968, 0.02099774545058608, 0.0...       E        E   \n","377  [0.19469691750903922, 0.3054667363564173, 0.19...       B        B   \n","402  [0.040896276012063026, 0.057805296033620834, 0...       C        C   \n","412  [0.27849654640470234, 0.21808134125811712, 0.1...       A        A   \n","422  [0.04828493669629097, 0.1506185382604599, 0.07...       B        B   \n","\n","    pred_max pred_diff_max pred_avg_2  ... pred_diff_max_2 pred_avg_3   \n","1          D             D          E  ...               E          C  \\\n","7          D             A          E  ...               B          C   \n","14         D             A          A  ...               D          B   \n","22         D             D          C  ...               C          A   \n","23         A             A          E  ...               C          C   \n","32         C             B          E  ...               D          B   \n","55         B             C          C  ...               A          D   \n","57         D             D          D  ...               E          B   \n","74         A             A          E  ...               E          B   \n","75         E             A          D  ...               B          C   \n","107        C             D          D  ...               A          E   \n","110        C             D          D  ...               B          A   \n","111        B             C          D  ...               D          C   \n","114        C             B          E  ...               D          B   \n","138        D             C          A  ...               D          E   \n","140        A             A          C  ...               D          E   \n","152        C             C          C  ...               D          A   \n","158        B             C          C  ...               E          D   \n","163        B             B          C  ...               D          D   \n","189        A             B          C  ...               C          E   \n","193        A             A          C  ...               B          B   \n","215        E             E          B  ...               D          C   \n","219        A             D          E  ...               B          D   \n","233        D             D          A  ...               A          E   \n","242        C             C          A  ...               B          C   \n","255        D             D          D  ...               C          B   \n","256        C             B          E  ...               A          D   \n","287        A             C          E  ...               B          D   \n","308        C             C          B  ...               D          C   \n","321        D             D          D  ...               B          C   \n","325        E             E          B  ...               C          D   \n","338        D             E          E  ...               D          B   \n","341        C             C          D  ...               A          B   \n","354        B             B          B  ...               A          D   \n","367        E             E          A  ...               A          C   \n","377        B             B          E  ...               A          D   \n","402        C             C          A  ...               B          B   \n","412        A             A          D  ...               B          E   \n","422        B             B          E  ...               E          C   \n","\n","    pred_max_3 pred_diff_max_3 avg_prediction max_prediction diff_max_max_el   \n","1            C               C          D E C          D E C        0.210966  \\\n","7            C               C          D E C          D B C        0.074555   \n","14           B               B          D A B          D A B        0.123698   \n","22           C               B          B C A          D B C        0.432833   \n","23           C               E          D E C          A D C        0.477834   \n","32           E               E          C E B          C B E        0.079019   \n","55           D               D          B C D          B C D        0.187194   \n","57           B               B          C D B          D C B        0.372023   \n","74           B               B          A E B          A E B        0.386701   \n","75           A               C          E D C          E D A        0.398409   \n","107          E               E          C D E          C D E        0.268400   \n","110          A               A          C D A          C D A        0.323211   \n","111          C               E          B D C          B D C        0.544333   \n","114          B               A          C E B          C E B        0.084532   \n","138          E               A          D A E          D A E        0.353729   \n","140          E               E          D C E          A D E        0.296220   \n","152          A               A          E C A          C E A        0.204735   \n","158          D               A          B C D          B C D        0.107651   \n","163          D               C          A C D          B C D        0.196762   \n","189          B               D          A C E          A C B        0.282454   \n","193          E               D          E C B          A B E        0.583711   \n","215          B               C          A B C          E A B        0.036209   \n","219          E               C          A E D          A D E        0.040106   \n","233          E               E          D A E          D A E        0.141686   \n","242          A               E          D A C          C D A        0.253743   \n","255          B               E          A D B          D A B        0.153832   \n","256          E               D          C E D          C B E        0.096967   \n","287          E               D          A E D          A D E        0.214889   \n","308          B               A          A B C          C A B        0.348889   \n","321          B               E          E D C          D E B        0.125746   \n","325          D               D          E B D          E C D        0.012121   \n","338          B               B          D E B          D E B        0.044106   \n","341          B               B          E D B          C E B        0.062566   \n","354          E               E          A B D          B A E        0.151313   \n","367          C               C          E A C          E A C        0.085120   \n","377          D               C          B E D          B E D        0.305467   \n","402          B               A          C A B          C A B        0.076441   \n","412          D               E          A D E          A E D        0.278497   \n","422          C               C          B E C          B E C        0.150619   \n","\n","     pred_diff_max_max_avg  pred_diff_max_max_max  pred_diff_max_diff_max_max  \n","1                 0.330769               0.541735                    0.210966  \n","7                 0.992374               0.998431                    0.074555  \n","14                0.710191               0.816382                    0.123698  \n","22                0.790235               0.991224                    0.432833  \n","23                0.791697               0.979089                    0.477834  \n","32                0.988247               0.996015                    0.079019  \n","55                0.975489               0.989001                    0.187194  \n","57                0.767295               0.981467                    0.372023  \n","74                0.412559               0.799259                    0.386701  \n","75                0.971753               0.994117                    0.398409  \n","107               0.876247               0.930956                    0.268400  \n","110               0.752731               0.959348                    0.323211  \n","111               0.984679               0.991550                    0.544333  \n","114               0.966799               0.988956                    0.084532  \n","138               0.788556               0.955085                    0.353729  \n","140               0.742778               0.940511                    0.296220  \n","152               0.921933               0.970016                    0.204735  \n","158               0.948741               0.970342                    0.107651  \n","163               0.962641               0.995796                    0.196762  \n","189               0.895360               0.982438                    0.282454  \n","193               0.891948               0.965940                    0.583711  \n","215               0.993897               0.997928                    0.036209  \n","219               0.978848               0.981895                    0.040106  \n","233               0.496233               0.637919                    0.141686  \n","242               0.909258               0.991563                    0.253743  \n","255               0.835631               0.984851                    0.153832  \n","256               0.995589               0.998140                    0.096967  \n","287               0.961024               0.996323                    0.214889  \n","308               0.758382               0.993426                    0.348889  \n","321               0.883406               0.996453                    0.125746  \n","325               0.983785               0.995905                    0.012121  \n","338               0.920802               0.961103                    0.044106  \n","341               0.956870               0.998804                    0.062566  \n","354               0.858893               0.998291                    0.151313  \n","367               0.910624               0.995744                    0.085120  \n","377               0.688693               0.994160                    0.305467  \n","402               0.628813               0.705254                    0.076441  \n","412               0.714611               0.993107                    0.278497  \n","422               0.835979               0.986598                    0.150619  \n","\n","[39 rows x 21 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["df_agg[df_agg['pred_diff_max'] == df_agg['answer']]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","df_agg['max_max_el'] = df_agg['max'].apply(lambda x: np.max(x))\n","\n","# plt.hist(df_agg['max_max_el'], bins=10, density=True, alpha=0.4, label=\"correct\");\n","\n","plt.hist(df_agg[df_agg['pred_max']==df_agg['answer']]['max_max_el'], bins=30, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[df_agg['pred_max']!=df_agg['answer']]['max_max_el'], bins=30, density=True, alpha=0.4, label=\"incorrect\");\n","\n","plt.legend();"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["df_agg['avg_of_max'] = df_agg['max'].apply(lambda x: np.average(x))\n","\n","plt.hist(df_agg[df_agg['pred_diff_max']==df_agg['answer']]['avg_of_max'], bins=30, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[df_agg['pred_diff_max']!=df_agg['answer']]['avg_of_max'], bins=30, density=True, alpha=0.4, label=\"incorrect\");\n","\n","plt.legend();"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["df_agg['avg_of_avg'] = df_agg['avg'].apply(lambda x: np.average(x))\n","\n","plt.hist(df_agg[df_agg['pred_diff_max']==df_agg['answer']]['avg_of_avg'], bins=30, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[df_agg['pred_diff_max']!=df_agg['answer']]['avg_of_avg'], bins=30, density=True, alpha=0.4, label=\"incorrect\");\n","\n","plt.legend();"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["0.790356394129979"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["df_2 = df_agg[df_agg['max_max_el'] > 0.9]\n","np.average(df_2['pred_max']==df_2['answer'])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["0.34782608695652173"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["df_2 = df_agg[df_agg['max_max_el'] < 0.9]\n","np.average(df_2['pred_avg_2']==df_2['answer'])"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["0.77"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# create \"combined_prediction\" as follows: where df_agg['max_max_el'] > 0.9, take pred_max, otherwise take pred_avg_2\n","df_agg['combined_prediction'] = df_agg.apply(lambda row: row['pred_max'] if row['max_max_el'] > 0.9 else row['pred_avg_2'], axis=1)\n","\n","np.average(df_agg['combined_prediction']==df_agg['answer'])"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.hist(df_agg[(df_agg['pred_diff_max']==df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[(df_agg['pred_diff_max']!=df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"incorrect\");\n","plt.legend();"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.hist(df_agg[(df_agg['pred_diff_max']==df_agg['answer']) & (df_agg['pred_max']==df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"correct\");\n","plt.hist(df_agg[(df_agg['pred_diff_max']!=df_agg['answer']) & (df_agg['pred_diff_max']!=df_agg['answer'])]['diff_max_max_el'], bins=10, density=True, alpha=0.4, label=\"incorrect\");\n","plt.legend();"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>answer</th>\n","      <th>avg</th>\n","      <th>max</th>\n","      <th>diff_max</th>\n","      <th>answers</th>\n","      <th>pred_avg</th>\n","      <th>pred_max</th>\n","      <th>pred_diff_max</th>\n","      <th>pred_avg_2</th>\n","      <th>...</th>\n","      <th>avg_prediction</th>\n","      <th>max_prediction</th>\n","      <th>diff_max_max_el</th>\n","      <th>pred_diff_max_max_avg</th>\n","      <th>pred_diff_max_max_max</th>\n","      <th>pred_diff_max_diff_max_max</th>\n","      <th>max_max_el</th>\n","      <th>avg_of_max</th>\n","      <th>avg_of_avg</th>\n","      <th>combined_prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>D</td>\n","      <td>[0.7841864824295044, 0.365252951780955, 0.3408...</td>\n","      <td>[0.8101109862327576, 0.4729377329349518, 0.436...</td>\n","      <td>[0.025924503803253174, 0.10768478115399677, 0....</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>...</td>\n","      <td>A D B</td>\n","      <td>A D B</td>\n","      <td>0.107685</td>\n","      <td>0.784186</td>\n","      <td>0.810111</td>\n","      <td>0.107685</td>\n","      <td>0.810111</td>\n","      <td>0.522272</td>\n","      <td>0.465887</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>[0.01348709903488105, 0.04889114268801429, 0.0...</td>\n","      <td>[0.023958779871463776, 0.07085713744163513, 0....</td>\n","      <td>[0.010471680836582726, 0.021965994753620842, 0...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>D E C</td>\n","      <td>D E C</td>\n","      <td>0.210966</td>\n","      <td>0.330769</td>\n","      <td>0.541735</td>\n","      <td>0.210966</td>\n","      <td>0.541735</td>\n","      <td>0.220330</td>\n","      <td>0.135929</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>[0.022143802295128506, 0.06562760596474011, 0....</td>\n","      <td>[0.03270862624049187, 0.10062923282384872, 0.2...</td>\n","      <td>[0.010564823945363361, 0.03500162685910861, 0....</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>...</td>\n","      <td>C E B</td>\n","      <td>C E B</td>\n","      <td>0.103654</td>\n","      <td>0.119930</td>\n","      <td>0.223584</td>\n","      <td>0.103654</td>\n","      <td>0.223584</td>\n","      <td>0.131853</td>\n","      <td>0.076071</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>B</td>\n","      <td>[0.2759467549622059, 0.4401126056909561, 0.338...</td>\n","      <td>[0.5398164391517639, 0.48443925380706787, 0.42...</td>\n","      <td>[0.26386968418955803, 0.044326648116111755, 0....</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>B C E</td>\n","      <td>A B C</td>\n","      <td>0.263870</td>\n","      <td>0.440113</td>\n","      <td>0.539816</td>\n","      <td>0.263870</td>\n","      <td>0.539816</td>\n","      <td>0.411736</td>\n","      <td>0.298440</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>[0.7641253603829278, 0.2921374539534251, 0.241...</td>\n","      <td>[0.9774370193481445, 0.4866539537906647, 0.497...</td>\n","      <td>[0.21331165896521675, 0.19451649983723956, 0.2...</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>...</td>\n","      <td>A B D</td>\n","      <td>A D E</td>\n","      <td>0.499348</td>\n","      <td>0.764125</td>\n","      <td>0.977437</td>\n","      <td>0.499348</td>\n","      <td>0.977437</td>\n","      <td>0.682440</td>\n","      <td>0.357596</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>C</td>\n","      <td>[0.534287840127945, 0.14227384328842163, 0.988...</td>\n","      <td>[0.7420330047607422, 0.24698862433433533, 0.99...</td>\n","      <td>[0.20774516463279724, 0.1047147810459137, 0.00...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>C A E</td>\n","      <td>C A E</td>\n","      <td>0.207745</td>\n","      <td>0.988161</td>\n","      <td>0.995408</td>\n","      <td>0.207745</td>\n","      <td>0.995408</td>\n","      <td>0.549059</td>\n","      <td>0.427025</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>B</td>\n","      <td>[0.9662010073661804, 0.9888747096061706, 0.986...</td>\n","      <td>[0.9885849356651306, 0.9983788728713989, 0.996...</td>\n","      <td>[0.022383928298950195, 0.009504163265228294, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>B C A</td>\n","      <td>B C A</td>\n","      <td>0.146366</td>\n","      <td>0.988875</td>\n","      <td>0.998379</td>\n","      <td>0.146366</td>\n","      <td>0.998379</td>\n","      <td>0.927087</td>\n","      <td>0.872872</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>B</td>\n","      <td>[0.9921214481194814, 0.9936448832352957, 0.973...</td>\n","      <td>[0.9992356300354004, 0.9994922876358032, 0.979...</td>\n","      <td>[0.007114181915918949, 0.005847404400507572, 0...</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>B A D</td>\n","      <td>B A D</td>\n","      <td>0.009044</td>\n","      <td>0.993645</td>\n","      <td>0.999492</td>\n","      <td>0.009044</td>\n","      <td>0.999492</td>\n","      <td>0.986238</td>\n","      <td>0.979257</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>D</td>\n","      <td>[0.7139628529548645, 0.8319788106850216, 0.853...</td>\n","      <td>[0.8354699015617371, 0.9652966260910034, 0.965...</td>\n","      <td>[0.12150704860687256, 0.13331781540598187, 0.1...</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>...</td>\n","      <td>D C B</td>\n","      <td>D C B</td>\n","      <td>0.195286</td>\n","      <td>0.954106</td>\n","      <td>0.976501</td>\n","      <td>0.195286</td>\n","      <td>0.976501</td>\n","      <td>0.835516</td>\n","      <td>0.718509</td>\n","      <td>D</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>C</td>\n","      <td>[0.9810901752540043, 0.9420293058667865, 0.989...</td>\n","      <td>[0.9937723278999329, 0.982878565788269, 0.9990...</td>\n","      <td>[0.012682152645928535, 0.040849259921482584, 0...</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>C A D</td>\n","      <td>C E D</td>\n","      <td>0.040849</td>\n","      <td>0.989412</td>\n","      <td>0.999031</td>\n","      <td>0.040849</td>\n","      <td>0.999031</td>\n","      <td>0.992975</td>\n","      <td>0.968374</td>\n","      <td>C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 25 columns</p>\n","</div>"],"text/plain":["      id answer                                                avg   \n","0      0      D  [0.7841864824295044, 0.365252951780955, 0.3408...  \\\n","1      1      D  [0.01348709903488105, 0.04889114268801429, 0.0...   \n","2      2      A  [0.022143802295128506, 0.06562760596474011, 0....   \n","3      3      B  [0.2759467549622059, 0.4401126056909561, 0.338...   \n","4      4      A  [0.7641253603829278, 0.2921374539534251, 0.241...   \n","..   ...    ...                                                ...   \n","495  495      C  [0.534287840127945, 0.14227384328842163, 0.988...   \n","496  496      B  [0.9662010073661804, 0.9888747096061706, 0.986...   \n","497  497      B  [0.9921214481194814, 0.9936448832352957, 0.973...   \n","498  498      D  [0.7139628529548645, 0.8319788106850216, 0.853...   \n","499  499      C  [0.9810901752540043, 0.9420293058667865, 0.989...   \n","\n","                                                   max   \n","0    [0.8101109862327576, 0.4729377329349518, 0.436...  \\\n","1    [0.023958779871463776, 0.07085713744163513, 0....   \n","2    [0.03270862624049187, 0.10062923282384872, 0.2...   \n","3    [0.5398164391517639, 0.48443925380706787, 0.42...   \n","4    [0.9774370193481445, 0.4866539537906647, 0.497...   \n","..                                                 ...   \n","495  [0.7420330047607422, 0.24698862433433533, 0.99...   \n","496  [0.9885849356651306, 0.9983788728713989, 0.996...   \n","497  [0.9992356300354004, 0.9994922876358032, 0.979...   \n","498  [0.8354699015617371, 0.9652966260910034, 0.965...   \n","499  [0.9937723278999329, 0.982878565788269, 0.9990...   \n","\n","                                              diff_max answers pred_avg   \n","0    [0.025924503803253174, 0.10768478115399677, 0....       D        A  \\\n","1    [0.010471680836582726, 0.021965994753620842, 0...       D        D   \n","2    [0.010564823945363361, 0.03500162685910861, 0....       A        C   \n","3    [0.26386968418955803, 0.044326648116111755, 0....       B        B   \n","4    [0.21331165896521675, 0.19451649983723956, 0.2...       A        A   \n","..                                                 ...     ...      ...   \n","495  [0.20774516463279724, 0.1047147810459137, 0.00...       C        C   \n","496  [0.022383928298950195, 0.009504163265228294, 0...       B        B   \n","497  [0.007114181915918949, 0.005847404400507572, 0...       B        B   \n","498  [0.12150704860687256, 0.13331781540598187, 0.1...       D        D   \n","499  [0.012682152645928535, 0.040849259921482584, 0...       C        C   \n","\n","    pred_max pred_diff_max pred_avg_2  ... avg_prediction max_prediction   \n","0          A             B          D  ...          A D B          A D B  \\\n","1          D             D          E  ...          D E C          D E C   \n","2          C             C          E  ...          C E B          C E B   \n","3          A             A          C  ...          B C E          A B C   \n","4          A             D          B  ...          A B D          A D E   \n","..       ...           ...        ...  ...            ...            ...   \n","495        C             A          A  ...          C A E          C A E   \n","496        B             E          C  ...          B C A          B C A   \n","497        B             D          A  ...          B A D          B A D   \n","498        D             E          C  ...          D C B          D C B   \n","499        C             B          A  ...          C A D          C E D   \n","\n","    diff_max_max_el pred_diff_max_max_avg pred_diff_max_max_max   \n","0          0.107685              0.784186              0.810111  \\\n","1          0.210966              0.330769              0.541735   \n","2          0.103654              0.119930              0.223584   \n","3          0.263870              0.440113              0.539816   \n","4          0.499348              0.764125              0.977437   \n","..              ...                   ...                   ...   \n","495        0.207745              0.988161              0.995408   \n","496        0.146366              0.988875              0.998379   \n","497        0.009044              0.993645              0.999492   \n","498        0.195286              0.954106              0.976501   \n","499        0.040849              0.989412              0.999031   \n","\n","    pred_diff_max_diff_max_max max_max_el  avg_of_max  avg_of_avg   \n","0                     0.107685   0.810111    0.522272    0.465887  \\\n","1                     0.210966   0.541735    0.220330    0.135929   \n","2                     0.103654   0.223584    0.131853    0.076071   \n","3                     0.263870   0.539816    0.411736    0.298440   \n","4                     0.499348   0.977437    0.682440    0.357596   \n","..                         ...        ...         ...         ...   \n","495                   0.207745   0.995408    0.549059    0.427025   \n","496                   0.146366   0.998379    0.927087    0.872872   \n","497                   0.009044   0.999492    0.986238    0.979257   \n","498                   0.195286   0.976501    0.835516    0.718509   \n","499                   0.040849   0.999031    0.992975    0.968374   \n","\n","     combined_prediction  \n","0                      D  \n","1                      E  \n","2                      E  \n","3                      C  \n","4                      A  \n","..                   ...  \n","495                    C  \n","496                    B  \n","497                    B  \n","498                    D  \n","499                    C  \n","\n","[500 rows x 25 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["df_agg"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2992455/2882938264.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","/tmp/ipykernel_2992455/2882938264.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>answer</th>\n","      <th>avg_0</th>\n","      <th>avg_1</th>\n","      <th>avg_2</th>\n","      <th>avg_3</th>\n","      <th>avg_4</th>\n","      <th>max_0</th>\n","      <th>max_1</th>\n","      <th>max_2</th>\n","      <th>max_3</th>\n","      <th>max_4</th>\n","      <th>diff_max_0</th>\n","      <th>diff_max_1</th>\n","      <th>diff_max_2</th>\n","      <th>diff_max_3</th>\n","      <th>diff_max_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>0.784186</td>\n","      <td>0.365253</td>\n","      <td>0.340827</td>\n","      <td>0.722697</td>\n","      <td>0.116472</td>\n","      <td>0.810111</td>\n","      <td>0.472938</td>\n","      <td>0.436626</td>\n","      <td>0.768302</td>\n","      <td>0.123384</td>\n","      <td>0.025925</td>\n","      <td>0.107685</td>\n","      <td>0.095799</td>\n","      <td>0.045604</td>\n","      <td>0.006912</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>0.013487</td>\n","      <td>0.048891</td>\n","      <td>0.092969</td>\n","      <td>0.330769</td>\n","      <td>0.193528</td>\n","      <td>0.023959</td>\n","      <td>0.070857</td>\n","      <td>0.149080</td>\n","      <td>0.541735</td>\n","      <td>0.316021</td>\n","      <td>0.010472</td>\n","      <td>0.021966</td>\n","      <td>0.056111</td>\n","      <td>0.210966</td>\n","      <td>0.122492</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.022144</td>\n","      <td>0.065628</td>\n","      <td>0.119930</td>\n","      <td>0.054070</td>\n","      <td>0.118582</td>\n","      <td>0.032709</td>\n","      <td>0.100629</td>\n","      <td>0.223584</td>\n","      <td>0.089623</td>\n","      <td>0.212720</td>\n","      <td>0.010565</td>\n","      <td>0.035002</td>\n","      <td>0.103654</td>\n","      <td>0.035554</td>\n","      <td>0.094138</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.275947</td>\n","      <td>0.440113</td>\n","      <td>0.338320</td>\n","      <td>0.122112</td>\n","      <td>0.315707</td>\n","      <td>0.539816</td>\n","      <td>0.484439</td>\n","      <td>0.424694</td>\n","      <td>0.205369</td>\n","      <td>0.404360</td>\n","      <td>0.263870</td>\n","      <td>0.044327</td>\n","      <td>0.086373</td>\n","      <td>0.083257</td>\n","      <td>0.088653</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.764125</td>\n","      <td>0.292137</td>\n","      <td>0.241704</td>\n","      <td>0.249995</td>\n","      <td>0.240017</td>\n","      <td>0.977437</td>\n","      <td>0.486654</td>\n","      <td>0.497665</td>\n","      <td>0.749343</td>\n","      <td>0.701101</td>\n","      <td>0.213312</td>\n","      <td>0.194516</td>\n","      <td>0.255961</td>\n","      <td>0.499348</td>\n","      <td>0.461084</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>2</td>\n","      <td>0.534288</td>\n","      <td>0.142274</td>\n","      <td>0.988161</td>\n","      <td>0.145874</td>\n","      <td>0.324528</td>\n","      <td>0.742033</td>\n","      <td>0.246989</td>\n","      <td>0.995408</td>\n","      <td>0.303479</td>\n","      <td>0.457387</td>\n","      <td>0.207745</td>\n","      <td>0.104715</td>\n","      <td>0.007247</td>\n","      <td>0.157604</td>\n","      <td>0.132858</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>1</td>\n","      <td>0.966201</td>\n","      <td>0.988875</td>\n","      <td>0.986837</td>\n","      <td>0.861394</td>\n","      <td>0.561052</td>\n","      <td>0.988585</td>\n","      <td>0.998379</td>\n","      <td>0.996732</td>\n","      <td>0.944320</td>\n","      <td>0.707418</td>\n","      <td>0.022384</td>\n","      <td>0.009504</td>\n","      <td>0.009894</td>\n","      <td>0.082926</td>\n","      <td>0.146366</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>1</td>\n","      <td>0.992121</td>\n","      <td>0.993645</td>\n","      <td>0.973349</td>\n","      <td>0.974997</td>\n","      <td>0.962173</td>\n","      <td>0.999236</td>\n","      <td>0.999492</td>\n","      <td>0.979549</td>\n","      <td>0.984041</td>\n","      <td>0.968870</td>\n","      <td>0.007114</td>\n","      <td>0.005847</td>\n","      <td>0.006200</td>\n","      <td>0.009044</td>\n","      <td>0.006696</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>3</td>\n","      <td>0.713963</td>\n","      <td>0.831979</td>\n","      <td>0.853099</td>\n","      <td>0.954106</td>\n","      <td>0.239397</td>\n","      <td>0.835470</td>\n","      <td>0.965297</td>\n","      <td>0.965631</td>\n","      <td>0.976501</td>\n","      <td>0.434683</td>\n","      <td>0.121507</td>\n","      <td>0.133318</td>\n","      <td>0.112532</td>\n","      <td>0.022394</td>\n","      <td>0.195286</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>2</td>\n","      <td>0.981090</td>\n","      <td>0.942029</td>\n","      <td>0.989412</td>\n","      <td>0.967667</td>\n","      <td>0.961673</td>\n","      <td>0.993772</td>\n","      <td>0.982879</td>\n","      <td>0.999031</td>\n","      <td>0.993859</td>\n","      <td>0.995334</td>\n","      <td>0.012682</td>\n","      <td>0.040849</td>\n","      <td>0.009619</td>\n","      <td>0.026193</td>\n","      <td>0.033662</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 16 columns</p>\n","</div>"],"text/plain":["     answer     avg_0     avg_1     avg_2     avg_3     avg_4     max_0   \n","0         3  0.784186  0.365253  0.340827  0.722697  0.116472  0.810111  \\\n","1         3  0.013487  0.048891  0.092969  0.330769  0.193528  0.023959   \n","2         0  0.022144  0.065628  0.119930  0.054070  0.118582  0.032709   \n","3         1  0.275947  0.440113  0.338320  0.122112  0.315707  0.539816   \n","4         0  0.764125  0.292137  0.241704  0.249995  0.240017  0.977437   \n","..      ...       ...       ...       ...       ...       ...       ...   \n","495       2  0.534288  0.142274  0.988161  0.145874  0.324528  0.742033   \n","496       1  0.966201  0.988875  0.986837  0.861394  0.561052  0.988585   \n","497       1  0.992121  0.993645  0.973349  0.974997  0.962173  0.999236   \n","498       3  0.713963  0.831979  0.853099  0.954106  0.239397  0.835470   \n","499       2  0.981090  0.942029  0.989412  0.967667  0.961673  0.993772   \n","\n","        max_1     max_2     max_3     max_4  diff_max_0  diff_max_1   \n","0    0.472938  0.436626  0.768302  0.123384    0.025925    0.107685  \\\n","1    0.070857  0.149080  0.541735  0.316021    0.010472    0.021966   \n","2    0.100629  0.223584  0.089623  0.212720    0.010565    0.035002   \n","3    0.484439  0.424694  0.205369  0.404360    0.263870    0.044327   \n","4    0.486654  0.497665  0.749343  0.701101    0.213312    0.194516   \n","..        ...       ...       ...       ...         ...         ...   \n","495  0.246989  0.995408  0.303479  0.457387    0.207745    0.104715   \n","496  0.998379  0.996732  0.944320  0.707418    0.022384    0.009504   \n","497  0.999492  0.979549  0.984041  0.968870    0.007114    0.005847   \n","498  0.965297  0.965631  0.976501  0.434683    0.121507    0.133318   \n","499  0.982879  0.999031  0.993859  0.995334    0.012682    0.040849   \n","\n","     diff_max_2  diff_max_3  diff_max_4  \n","0      0.095799    0.045604    0.006912  \n","1      0.056111    0.210966    0.122492  \n","2      0.103654    0.035554    0.094138  \n","3      0.086373    0.083257    0.088653  \n","4      0.255961    0.499348    0.461084  \n","..          ...         ...         ...  \n","495    0.007247    0.157604    0.132858  \n","496    0.009894    0.082926    0.146366  \n","497    0.006200    0.009044    0.006696  \n","498    0.112532    0.022394    0.195286  \n","499    0.009619    0.026193    0.033662  \n","\n","[500 rows x 16 columns]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["df_xgboost = df_agg[['answer', 'avg', 'max', 'diff_max']]\n","# avg, max and diff_max are arrays. Create avg_0, avg_1, ..., diff_max_0, diff_max_1, ...\n","for i in range(5):\n","    df_xgboost[f'avg_{i}'] = df_xgboost['avg'].apply(lambda x: x[i])\n","for i in range(5):\n","    df_xgboost[f'max_{i}'] = df_xgboost['max'].apply(lambda x: x[i])\n","for i in range(5):\n","    df_xgboost[f'diff_max_{i}'] = df_xgboost['diff_max'].apply(lambda x: x[i])\n","    \n","df_xgboost = df_xgboost.drop(columns=['avg', 'max', 'diff_max'])\n","\n","# convert answer to 0, 1, 2, 3, 4\n","df_xgboost['answer'] = df_xgboost['answer'].apply(lambda x: option_to_index[x])\n","\n","df_xgboost"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6733333333333333\n"]}],"source":["import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Split the data into training and testing sets\n","X = df_xgboost.drop(columns=\"answer\")\n","y = df_xgboost[\"answer\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Convert the datasets into DMatrix instances, which is the data structure XGBoost uses\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","# Define the parameters for the XGBoost model\n","param = {\n","    'max_depth': 3,\n","    'eta': 0.3,\n","    'objective': 'multi:softprob',  # for multiclass classification problems\n","    'num_class': 5  # you mentioned 5 possible values for the answer column\n","}\n","num_round =30\n","\n","# Train the model\n","bst = xgb.train(param, dtrain, num_round)\n","\n","# Make predictions\n","preds_prob = bst.predict(dtest)\n","preds = preds_prob.argmax(axis=1)\n","\n","# Evaluate the model\n","acc = accuracy_score(y_test, preds)\n","print(f\"Accuracy: {acc}\")"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [10/300], Loss: 1.5525\n","Test Accuracy: 31.00%\n","Epoch [20/300], Loss: 1.4513\n","Test Accuracy: 39.00%\n","Epoch [30/300], Loss: 1.3303\n","Test Accuracy: 45.00%\n","Epoch [40/300], Loss: 1.1997\n","Test Accuracy: 48.00%\n","Epoch [50/300], Loss: 1.0828\n","Test Accuracy: 51.00%\n","Epoch [60/300], Loss: 0.9886\n","Test Accuracy: 53.00%\n","Epoch [70/300], Loss: 0.9135\n","Test Accuracy: 56.00%\n","Epoch [80/300], Loss: 0.8535\n","Test Accuracy: 58.00%\n","Epoch [90/300], Loss: 0.8046\n","Test Accuracy: 58.00%\n","Epoch [100/300], Loss: 0.7625\n","Test Accuracy: 57.00%\n","Epoch [110/300], Loss: 0.7248\n","Test Accuracy: 58.00%\n","Epoch [120/300], Loss: 0.6908\n","Test Accuracy: 58.00%\n","Epoch [130/300], Loss: 0.6597\n","Test Accuracy: 59.00%\n","Epoch [140/300], Loss: 0.6303\n","Test Accuracy: 60.00%\n","Epoch [150/300], Loss: 0.6041\n","Test Accuracy: 59.00%\n","Epoch [160/300], Loss: 0.5794\n","Test Accuracy: 59.00%\n","Epoch [170/300], Loss: 0.5556\n","Test Accuracy: 58.00%\n","Epoch [180/300], Loss: 0.5325\n","Test Accuracy: 58.00%\n","Epoch [190/300], Loss: 0.5105\n","Test Accuracy: 59.00%\n","Epoch [200/300], Loss: 0.4898\n","Test Accuracy: 59.00%\n","Epoch [210/300], Loss: 0.4697\n","Test Accuracy: 60.00%\n","Epoch [220/300], Loss: 0.4503\n","Test Accuracy: 60.00%\n","Epoch [230/300], Loss: 0.4319\n","Test Accuracy: 61.00%\n","Epoch [240/300], Loss: 0.4138\n","Test Accuracy: 61.00%\n","Epoch [250/300], Loss: 0.3965\n","Test Accuracy: 62.00%\n","Epoch [260/300], Loss: 0.3797\n","Test Accuracy: 61.00%\n","Epoch [270/300], Loss: 0.3636\n","Test Accuracy: 61.00%\n","Epoch [280/300], Loss: 0.3479\n","Test Accuracy: 60.00%\n","Epoch [290/300], Loss: 0.3331\n","Test Accuracy: 60.00%\n","Epoch [300/300], Loss: 0.3195\n","Test Accuracy: 61.00%\n","Test Accuracy: 61.00%\n"]}],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","\n","# Normalize the features\n","scaler = StandardScaler()\n","features = df_xgboost.drop(columns=\"answer\").values\n","features = scaler.fit_transform(features)\n","\n","\n","X = torch.tensor(features, dtype=torch.float32)\n","y = torch.tensor(df_xgboost[\"answer\"].values, dtype=torch.long)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","\n","# Define the neural network\n","class SimpleNN(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","    \n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","input_dim = X.shape[1]\n","output_dim = 5  # As there are 5 possible classes\n","model = SimpleNN(input_dim, output_dim)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training the model\n","epochs = 300\n","for epoch in range(epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n","        \n","        with torch.no_grad():\n","            test_outputs = model(X_test)\n","            _, predicted = test_outputs.max(1)\n","            acc = accuracy_score(y_test, predicted)\n","            print(f\"Test Accuracy: {acc * 100:.2f}%\")\n","\n","# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    test_outputs = model(X_test)\n","    _, predicted = test_outputs.max(1)\n","    acc = accuracy_score(y_test, predicted)\n","    print(f\"Test Accuracy: {acc * 100:.2f}%\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
