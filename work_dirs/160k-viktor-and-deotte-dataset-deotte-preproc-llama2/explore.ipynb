{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# read /home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-llama2/llama2-7b-stem-2023-09-19-19-26-03/train_tokenized_dataset.pkl to train_tokenized_dataset\n",
    "with open('/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-llama2/llama2-7b-stem-2023-09-19-19-26-03/train_tokenized_dataset.pkl', 'rb') as f:\n",
    "    train_tokenized_dataset = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', '__index_level_0__', 'input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with empty input_ids: 0\n"
     ]
    }
   ],
   "source": [
    "empty_input_ids_indices = []\n",
    "\n",
    "for i, sample in enumerate(train_tokenized_dataset):\n",
    "    if not sample[\"input_ids\"]:\n",
    "        empty_input_ids_indices.append(i)\n",
    "\n",
    "print(f\"Number of samples with empty input_ids: {len(empty_input_ids_indices)}\")\n",
    "\n",
    "# If you want to see the indices of samples with empty input_ids:\n",
    "if empty_input_ids_indices:\n",
    "    print(f\"Indices of samples with empty input_ids: {empty_input_ids_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# read /home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-llama2/llama2-7b-stem-2023-09-19-19-26-03/train_tokenized_dataset.pkl to train_tokenized_dataset\n",
    "with open('/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-llama2/llama2-7b-stem-2023-09-19-19-26-03/val_tokenized_dataset.pkl', 'rb') as f:\n",
    "    val_tokenized_dataset = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', '__index_level_0__', 'input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', '__index_level_0__', 'input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_llm.adapted_models import (\n",
    "    LlamaModelForMultipleChoice, \n",
    "    DebertaV2ForMultipleChoice2\n",
    ")\n",
    "from kaggle_llm.core import (\n",
    "    DataCollatorForMultipleChoice,\n",
    "    DataCollatorForMultipleChoicePrompting,\n",
    "    WORK_DIRS_PATH,\n",
    "    ROOT_PATH,\n",
    "    compute_map3_hf,\n",
    "    build_peft_model,\n",
    "    load_train_and_val_df,\n",
    "    get_tokenize_dataset_from_df,\n",
    "    get_mcp_tokenize_dataset_from_df,\n",
    "    train_and_save_best_model_on_error,\n",
    "    add_context\n",
    ")\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import json\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "logger.add(sys.stdout, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def main(config_path: str,\n",
    "         work_dir_path: str = None,\n",
    "         ):\n",
    "    with open(config_path, \"rb\") as f:\n",
    "        config = yaml.load(f, yaml.FullLoader)\n",
    "\n",
    "    load_from = config[\"load_from\"]\n",
    "    input_paths = config[\"inputs\"]\n",
    "    logger.info(json.dumps(config, indent=4))\n",
    "    logger.info(\"loading data\")\n",
    "    \n",
    "    if \"eval_on\" in config.keys():\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Load training data \n",
    "        train_df_1, val_df_1 = load_train_and_val_df(\n",
    "            input_paths=config[\"inputs\"],\n",
    "            i_fold=config[\"fold\"][\"num\"] if \"fold\" in config else 0,\n",
    "            total_fold=config[\"fold\"][\"of\"] if \"fold\" in config else 10,\n",
    "        )\n",
    "        train_df = pd.concat([train_df_1, val_df_1])\n",
    "        \n",
    "        \n",
    "        # Load validation data \n",
    "        train_df_2, val_df_2 = load_train_and_val_df(\n",
    "            input_paths=config[\"eval_on\"],\n",
    "            i_fold=config[\"fold\"][\"num\"] if \"fold\" in config else 0,\n",
    "            total_fold=config[\"fold\"][\"of\"] if \"fold\" in config else 10,\n",
    "        )\n",
    "        if \"eval_all_folds\" in config and config[\"eval_all_folds\"]:\n",
    "            val_df = pd.concat([train_df_2, val_df_2])\n",
    "        else:\n",
    "            val_df = val_df_2\n",
    "    else:\n",
    "        train_df, val_df = load_train_and_val_df(\n",
    "            input_paths=input_paths,\n",
    "            i_fold=config[\"fold\"][\"num\"],\n",
    "            total_fold=config[\"fold\"][\"of\"],\n",
    "        )  \n",
    "        \n",
    "        \n",
    "    print(\"train_df.dtypes\", train_df.dtypes)\n",
    "    \n",
    "    print(\"train_df:\")\n",
    "    print(train_df.iloc[0])\n",
    "    print(\"val_df:\")\n",
    "    print(val_df.iloc[0])\n",
    "    if \"add_context\" in config and config[\"add_context\"]:\n",
    "        train_df = add_context(train_df)\n",
    "        val_df = add_context(val_df)\n",
    "\n",
    "        print(f\"New train_df size: {len(train_df)}\")\n",
    "        print(f\"New val_df size: {len(val_df)}\")\n",
    "    \n",
    "        print(train_df.sample(1)['new_prompt'].values[0])\n",
    "        \n",
    "    print(f\"[INFO] train df size is {len(train_df)}\")\n",
    "    print(f\"[INFO] val df size is {len(val_df)}\")\n",
    "    \n",
    "    if \"train_size\" in config:\n",
    "        train_df = train_df.sample(config[\"train_size\"], replace=False).reset_index(drop=True)\n",
    "        print(f\"[INFO] Resampled df. New train df size is {len(train_df)}\")\n",
    "\n",
    "    \n",
    "    model_name = load_from.split(\"/\")[-1]\n",
    "    print(\"model_name:\", model_name)\n",
    "    if work_dir_path is None:\n",
    "        work_dir_path = WORK_DIRS_PATH\n",
    "    model_output_dir = os.path.join(work_dir_path, f\"{model_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\")\n",
    "    model_output_dir = Path(model_output_dir)\n",
    "    model_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    logger.info(f\"splitted dataset of size {len(train_df) + len(val_df)} -> {len(train_df)} & {len(val_df)}\")\n",
    "    logger.info(\"loaded data\")\n",
    "\n",
    "    logger.info(\"initting models\")\n",
    "    model, tokenizer = build_peft_model(\n",
    "        config[\"load_from\"],\n",
    "        use_peft=config[\"use_peft\"],\n",
    "        peft_class=config[\"peft_class\"],\n",
    "        transformer_class=\"AutoModelForMultipleChoice\",\n",
    "        use_8bit=config[\"use_8bit\"],\n",
    "        **config[\"peft_kwargs\"] if \"peft_kwargs\" in config else {},\n",
    "    )\n",
    "    \n",
    "    if 'freeze_embeddings' in config and config['freeze_embeddings'] and 'deberta' in config['load_from']:\n",
    "        print('Freezing embeddings.')\n",
    "        for param in model.deberta.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "    if 'freeze_layers' in config and config['freeze_layers'] and 'deberta' in config['load_from']:\n",
    "        freeze_layers = config['freeze_layers']\n",
    "        print(f'Freezing first {freeze_layers} layers.')\n",
    "        for layer in model.deberta.encoder.layer[:freeze_layers]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    \n",
    "    logger.info(f\"model.num_parameters() = {model.num_parameters() * 1e-6} Million\")\n",
    "    logger.info(f\"model.num_parameters() = {model.num_parameters() * 1e-9} Billion\")\n",
    "    logger.info(\"initted models\")\n",
    " \n",
    "    logger.info(\"initting dataset\")\n",
    "    \n",
    "    if 'separate_prompt_and_context' in config and config['separate_prompt_and_context']:\n",
    "        def get_context(text):\n",
    "            x = text.split(\" ### \")\n",
    "            # remove empty strings\n",
    "            x = [x for x in x if len(x) > 0]\n",
    "            \n",
    "            assert len(x) == 2, f\"Unsuccesful prompt splitting . len(x) = {len(x)}, x={x}\"\n",
    "            return x[0]\n",
    "        \n",
    "        \n",
    "        train_df['context'] = train_df['prompt'].apply(lambda x: get_context(x))\n",
    "        val_df['context'] = val_df['prompt'].apply(lambda x: get_context(x))\n",
    "        \n",
    "        def get_prompt(text):\n",
    "            x = text.split(\" ### \")\n",
    "            # remove empty strings\n",
    "            x = [x for x in x if len(x) > 0]\n",
    "            assert len(x) == 2, f\"Unsuccesful prompt splitting . len(x) = {len(x)}\"\n",
    "            return x[1]\n",
    "        \n",
    "        train_df['prompt'] = train_df['prompt'].apply(lambda x: get_prompt(x))\n",
    "        val_df['prompt'] = val_df['prompt'].apply(lambda x: get_prompt(x))\n",
    "        \n",
    "    \n",
    "    if \"max_context_size\" in config:\n",
    "        max_context_size = config[\"max_context_size\"]\n",
    "        def limit_context(x, max_context_size):\n",
    "            x = x[:max_context_size]\n",
    "            return x\n",
    "        train_df['context'] = train_df['context'].apply(lambda x: limit_context(x, max_context_size))\n",
    "        val_df['context'] = val_df['context'].apply(lambda x: limit_context(x, max_context_size))\n",
    "    \n",
    "    preprocess_type = 'sumo' if 'preprocess_type' not in config else config['preprocess_type']\n",
    "    print(f\"preprocess_type: {preprocess_type}\")\n",
    "    max_input = 512 if 'max_input' not in config else config['max_input']\n",
    "    \n",
    "    # Trim context length to reasonable size\n",
    "    train_df['context'] = train_df['context'].apply(lambda x: x[:12000])\n",
    "    val_df['context'] = val_df['context'].apply(lambda x: x[:12000])\n",
    "    \n",
    "    train_df['context_len'] = train_df['context'].apply(lambda x: len(x))\n",
    "    train_df['prompt_len'] = train_df['prompt'].apply(lambda x: len(x))\n",
    "    \n",
    "    val_df['context_len'] = val_df['context'].apply(lambda x: len(x))\n",
    "    val_df['prompt_len'] = val_df['prompt'].apply(lambda x: len(x))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"train_df['context_len'].min()\", train_df['context_len'].min())\n",
    "    print(\"train_df['context_len'].max()\", train_df['context_len'].max())\n",
    "    print(\"val_df['context_len'].min()\", val_df['context_len'].min())\n",
    "    print(\"val_df['context_len'].max()\", val_df['context_len'].max())\n",
    "    print(\"train_df['prompt_len'].min()\", train_df['prompt_len'].min())\n",
    "    print(\"train_df['prompt_len'].max()\", train_df['prompt_len'].max())\n",
    "    print(\"val_df['prompt_len'].min()\", val_df['prompt_len'].min())\n",
    "    print(\"val_df['prompt_len'].max()\", val_df['prompt_len'].max())\n",
    "    \n",
    "    # print unique answers\n",
    "    print(\"train_df['answer'].unique()\", train_df['answer'].unique())\n",
    "    print(\"val_df['answer'].unique()\", val_df['answer'].unique())\n",
    "    \n",
    "    # take only prompt, context, A, B, C, D, E and answer (if there's an answer)\n",
    "    train_df = train_df[['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer']]\n",
    "    val_df = val_df[['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer']]\n",
    "    \n",
    "    train_df['prompt'] = train_df['prompt'].astype(str)\n",
    "    val_df['prompt'] = val_df['prompt'].astype(str)\n",
    "    train_df['context'] = train_df['context'].astype(str)\n",
    "    val_df['context'] = val_df['context'].astype(str)\n",
    "    train_df['answer'] = train_df['answer'].astype(str)\n",
    "    val_df['answer'] = val_df['answer'].astype(str)\n",
    "\n",
    "    options = 'ABCDE'\n",
    "    for option in options:\n",
    "        train_df[option] = train_df[option].astype(str)\n",
    "        val_df[option] = val_df[option].astype(str)\n",
    "    \n",
    "    \n",
    "    train_df.to_csv(model_output_dir / \"train_df.csv\")\n",
    "    val_df.to_csv(model_output_dir / \"val_df.csv\")\n",
    "    \n",
    "    train_tokenized_dataset = get_tokenize_dataset_from_df(train_df, tokenizer, preprocess_type, max_input)\n",
    "    val_tokenized_dataset = get_tokenize_dataset_from_df(val_df, tokenizer, preprocess_type, max_input)\n",
    "    # train_tokenized_dataset = get_mcp_tokenize_dataset_from_df(train_df, tokenizer)\n",
    "    # val_tokenized_dataset = get_mcp_tokenize_dataset_from_df(val_df, tokenizer)\n",
    "    logger.info(\"initted dataset\")\n",
    "    \n",
    "    # save train_tokenized_dataset and val_tokenized_dataset as pickle files\n",
    "    import pickle\n",
    "    with open(model_output_dir / \"train_tokenized_dataset.pkl\", 'wb') as f:\n",
    "        pickle.dump(train_tokenized_dataset, f)\n",
    "    \n",
    "    with open(model_output_dir / \"val_tokenized_dataset.pkl\", 'wb') as f:\n",
    "        pickle.dump(val_tokenized_dataset, f)\n",
    "    \n",
    "    return\n",
    "\n",
    "    logger.info(\"initting trainer\")\n",
    "    warmup_epochs = 1\n",
    "    total_epochs = config[\"total_epochs\"]\n",
    "    warmup_ratio = warmup_epochs / total_epochs\n",
    "    training_args = TrainingArguments(\n",
    "        metric_for_best_model=\"map3\",\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        greater_is_better=True,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        learning_rate=float(config[\"lr\"]),\n",
    "        per_device_train_batch_size=1,\n",
    "        load_best_model_at_end=False,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        save_steps=50,\n",
    "        logging_steps=50,\n",
    "        per_device_eval_batch_size=2,\n",
    "        num_train_epochs=total_epochs,\n",
    "        save_total_limit=config[\"save_total_limit\"] if \"save_total_limit\" in config else 10,\n",
    "        report_to=config[\"report_to\"],\n",
    "        output_dir=str(model_output_dir),\n",
    "        # fp16=False if 'use_8bit' in config and config['use_8bit'] else True,\n",
    "        # gradient_checkpointing=True,\n",
    "        gradient_accumulation_steps=config[\"gradient_accumulation_steps\"],\n",
    "        # deepspeed=str((ROOT_PATH / \"configs\" / \"deepspeed.json\").resolve().absolute()),\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "        # data_collator=DataCollatorForMultipleChoicePrompting(tokenizer=tokenizer),\n",
    "        train_dataset=train_tokenized_dataset,\n",
    "        eval_dataset=val_tokenized_dataset,\n",
    "        compute_metrics=compute_map3_hf,\n",
    "        # callbacks=[\n",
    "        #     EarlyStoppingCallback(early_stopping_patience=config[\"early_stopping_patience\"]),\n",
    "        # ],\n",
    "    )\n",
    "    logger.info(\"initting trainer\")\n",
    "\n",
    "    trainer.train()\n",
    "    # train_and_save_best_model_on_error(\n",
    "    #     trainer,\n",
    "    #     model_output_dir,\n",
    "    #     \"best_map3_peft\" if config[\"use_peft\"] else \"best_map3\",\n",
    "    # )\n",
    "    \n",
    "    if config[\"report_to\"] == \"wandb\":\n",
    "        wandb.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/160k-viktor-and-deotte-dataset-deotte-preproc-llama2/configs/multiple_choice.yaml\"\n",
    "work_dir_path = \"./\"\n",
    "\n",
    "\n",
    "peft_kwargs = {\n",
    "        \"init_r\": 2048,\n",
    "        \"target_r\": 1024,\n",
    "        \"beta1\": 0.85,\n",
    "        \"beta2\": 0.85,\n",
    "        \"tinit\": 200,\n",
    "        \"tfinal\": 1000,\n",
    "        \"deltaT\": 10,\n",
    "        \"lora_alpha\": 256,\n",
    "        \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\n",
    "            \"q_proj\",\n",
    "            \"v_proj\"\n",
    "        ],\n",
    "        \"orth_reg_weight\": 0.5\n",
    "    }\n",
    "\n",
    "model, tokenizer = build_peft_model(\n",
    "        \"/home/viktor/Documents/kaggle/kaggle_llm/data/llama2-7b-stem\",\n",
    "        use_peft=True,\n",
    "        peft_class=\"AdaLoraConfig\",\n",
    "        transformer_class=\"AutoModelForMultipleChoice\",\n",
    "        use_8bit=True,\n",
    "        **peft_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>text = <span style=\"color: #808000; text-decoration-color: #808000\">\"ahha\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 tokenized_text = tokenizer(text, return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>tokenized_text                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'tokenizer'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mtext = \u001b[33m\"\u001b[0m\u001b[33mahha\u001b[0m\u001b[33m\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 tokenized_text = tokenizer(text, return_tensors=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mtokenized_text                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'tokenizer'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"ahha\"\n",
    "tokenized_text = tokenizer(text, return_tensors=\"pt\")\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The presence of a clustered thick disk-like co...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Many of these systems evolve in a self-similar...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>It is possible that this usage is related with...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Renormalization is distinct from regularizatio...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Several qualitative observations can be made o...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>What is the relation between the three moment ...</td>\n",
       "      <td>The second equation is more general as it does...</td>\n",
       "      <td>The three moment theorem expresses the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem describes the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem is used to derive the...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>What is the throttling process, and why is it ...</td>\n",
       "      <td>A throttle is the mechanism by which fluid flo...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>What happens to excess base metal as a solutio...</td>\n",
       "      <td>Furthermore, this melting may begin at a tempe...</td>\n",
       "      <td>The excess base metal will often solidify, bec...</td>\n",
       "      <td>The excess base metal will often crystallize-o...</td>\n",
       "      <td>The excess base metal will often dissolve, bec...</td>\n",
       "      <td>The excess base metal will often liquefy, beco...</td>\n",
       "      <td>The excess base metal will often evaporate, be...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>What is the relationship between mass, force, ...</td>\n",
       "      <td>Newton first set out the definition of mass Th...</td>\n",
       "      <td>Mass is a property that determines the weight ...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is a property that determines the size of...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>What did Arthur Eddington discover about two o...</td>\n",
       "      <td>Eddington's criticism seems to have been based...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt   \n",
       "0    Which of the following statements accurately d...  \\\n",
       "1    Which of the following is an accurate definiti...   \n",
       "2    Which of the following statements accurately d...   \n",
       "3    What is the significance of regularization in ...   \n",
       "4    Which of the following statements accurately d...   \n",
       "..                                                 ...   \n",
       "195  What is the relation between the three moment ...   \n",
       "196  What is the throttling process, and why is it ...   \n",
       "197  What happens to excess base metal as a solutio...   \n",
       "198  What is the relationship between mass, force, ...   \n",
       "199  What did Arthur Eddington discover about two o...   \n",
       "\n",
       "                                               context   \n",
       "0    The presence of a clustered thick disk-like co...  \\\n",
       "1    Many of these systems evolve in a self-similar...   \n",
       "2    It is possible that this usage is related with...   \n",
       "3    Renormalization is distinct from regularizatio...   \n",
       "4    Several qualitative observations can be made o...   \n",
       "..                                                 ...   \n",
       "195  The second equation is more general as it does...   \n",
       "196  A throttle is the mechanism by which fluid flo...   \n",
       "197  Furthermore, this melting may begin at a tempe...   \n",
       "198  Newton first set out the definition of mass Th...   \n",
       "199  Eddington's criticism seems to have been based...   \n",
       "\n",
       "                                                     A   \n",
       "0    MOND is a theory that reduces the observed mis...  \\\n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol was reconstructed as a fe...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem expresses the relatio...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often solidify, bec...   \n",
       "198  Mass is a property that determines the weight ...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     B   \n",
       "0    MOND is a theory that increases the discrepanc...  \\\n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol is a representation of th...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often crystallize-o...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     C   \n",
       "0    MOND is a theory that explains the missing bar...  \\\n",
       "1    Dynamic scaling refers to the evolution of sel...   \n",
       "2    The triskeles symbol is a representation of a ...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem describes the relatio...   \n",
       "196  The throttling process is a steady adiabatic f...   \n",
       "197  The excess base metal will often dissolve, bec...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     D   \n",
       "0    MOND is a theory that reduces the discrepancy ...  \\\n",
       "1    Dynamic scaling refers to the non-evolution of...   \n",
       "2    The triskeles symbol represents three interloc...   \n",
       "3    Regularizing the mass-energy of an electron wi...   \n",
       "4    The angular spacing of features in the diffrac...   \n",
       "..                                                 ...   \n",
       "195  The three moment theorem is used to calculate ...   \n",
       "196  The throttling process is a steady flow of a f...   \n",
       "197  The excess base metal will often liquefy, beco...   \n",
       "198  Mass is an inertial property that determines a...   \n",
       "199  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                     E answer  \n",
       "0    MOND is a theory that eliminates the observed ...      D  \n",
       "1    Dynamic scaling refers to the evolution of sel...      A  \n",
       "2    The triskeles symbol is a representation of th...      A  \n",
       "3    Regularizing the mass-energy of an electron wi...      C  \n",
       "4    The angular spacing of features in the diffrac...      D  \n",
       "..                                                 ...    ...  \n",
       "195  The three moment theorem is used to derive the...      C  \n",
       "196  The throttling process is a steady adiabatic f...      B  \n",
       "197  The excess base metal will often evaporate, be...      B  \n",
       "198  Mass is a property that determines the size of...      D  \n",
       "199  Arthur Eddington showed that two of Einstein's...      C  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/viktor/Documents/kaggle/kaggle_llm/work_dirs/reproduce-mgoksu-deotte/test_data/train_context_0.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
