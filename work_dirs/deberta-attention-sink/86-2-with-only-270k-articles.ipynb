{"cells":[{"cell_type":"markdown","metadata":{},"source":["I previously shared a [notebook](url) (see the discussion [here](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/441128)) that found a cluster of relevant Wikipedia STEM articles, resulting in around 270K STEM articles for which the resulting dataset is released [here.](https://www.kaggle.com/datasets/mbanaei/stem-wiki-cohere-no-emb)\n","\n","However, due to issues with WikiExtractor, there're cases in which some numbers or even paragraphs are missing from the final Wiki parsing. Therefore,  for the same set of  articles, I used Wiki API to gather the articles' contexts (see discussion [here](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/442483)), for which the resulting dataset is released [here](https://www.kaggle.com/datasets/mbanaei/all-paraphs-parsed-expanded).\n","\n","In order to show that the found articles cover not only the train dataset articles but also a majority of LB gold articles, I release this notebook that uses a simple retrieval model (without any prior indexing) together with a model that is trained only on the RACE dataset. (not fine-tuned on any competition-similar dataset).\n","\n","The main design choices for the notebook are:\n","- Using a simple TF-IDF to retrieve contexts from both datasets for every given question.\n","- Although the majority of high-performing public models use DeBERTa-V3 to do the inference in their pipeline, I used a LongFormer Large model, which enables us to have a much longer prefix context given limited GPU memory. More specifically, as opposed to many public notebooks, there's no splitting to sentence level, and the whole paragraph is retrieved and passed to the classifier as a context (the main reason that we don't get OOM and also have relatively fast inference is that in LongFormer full attention is not computed as opposed to standard models like BERT).\n","- I use a fall-back model (based on a public notebook that uses an openbook approach and performs 81.5 on LB) that is used for prediction when there's low confidence in the main model's output for the top choice.\n","\n","P.S: Although the model's performance is relatively good compared to other public notebooks, many design choices can be revised to improve both inference time and performance. (e.g., currently, context retrieval seems to be the inference bottleneck as no prior indexing is used)."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:41:10.47071Z","iopub.status.busy":"2023-08-29T13:41:10.470251Z","iopub.status.idle":"2023-08-29T13:41:46.496147Z","shell.execute_reply":"2023-08-29T13:41:46.494943Z","shell.execute_reply.started":"2023-08-29T13:41:10.470675Z"},"trusted":true},"outputs":[],"source":["# !cp /kaggle/input/datasets-wheel/datasets-2.14.4-py3-none-any.whl /kaggle/working\n","# !pip install  /kaggle/working/datasets-2.14.4-py3-none-any.whl\n","# !cp /kaggle/input/backup-806/util_openbook.py ."]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-08-29T13:41:52.418247Z","iopub.status.busy":"2023-08-29T13:41:52.41787Z","iopub.status.idle":"2023-08-29T13:43:54.355399Z","shell.execute_reply":"2023-08-29T13:43:54.354189Z","shell.execute_reply.started":"2023-08-29T13:41:52.418215Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# # installing offline dependencies\n","# !pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","# !cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n","# !pip install -U /kaggle/working/sentence-transformers\n","# !pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n","\n","# !pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n","# !pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n","# !pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["RUN_ON_KAGGLE = False\n","DEBUG = False\n","\n","VAL_SIZE = 100\n","\n","# file_for_local_cv = \"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-llm-science-exam/test.csv\"\n","# file_for_local_cv = \"/home/viktor/Documents/kaggle/kaggle_llm/data/kaggle-llm-science-exam/train.csv\"\n","# file_for_local_cv = \"/home/viktor/Documents/kaggle/kaggle_llm/data/data_dumps/more_questions/more_questions_raw_questions_wiki_sci_3_shuffled.csv\"\n","\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-08-29T13:44:53.234278Z","iopub.status.busy":"2023-08-29T13:44:53.233905Z","iopub.status.idle":"2023-08-29T13:55:59.072609Z","shell.execute_reply":"2023-08-29T13:55:59.071407Z","shell.execute_reply.started":"2023-08-29T13:44:53.234248Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n","CUDA SETUP: Detected CUDA version 121\n","CUDA SETUP: Loading binary /home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"]},{"name":"stderr","output_type":"stream","text":["/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/viktor/miniconda3/envs/torch-env did not contain libcudart.so as expected! Searching further paths...\n","  warn(msg)\n","/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n","  warn(msg)\n","/home/viktor/miniconda3/envs/torch-env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n","  warn(msg)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1379fa4b8cc445f3988d67cc1071bcc7","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b488218b983a459bbdc13901b2dba599","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8337cce4d1e5428ea0ae78f2856a5fd2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/28 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ff0ce4b4d054a85941183d7503b2180","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1905 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0189f0497ec14ad99321b7a9ba48e335","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1905 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62b685b846ae43859e633663fc24d0ff","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/5584 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df3baab66598415f8f00a81c263a9c80","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ecf92e5b1da4d8aa74ccc436376edac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["54"]},"execution_count":4,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["from util_openbook import get_contexts\n","import pickle\n","\n","get_contexts(RUN_ON_KAGGLE, VAL_SIZE, file_for_local_cv)\n","\n","import gc\n","gc.collect()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
